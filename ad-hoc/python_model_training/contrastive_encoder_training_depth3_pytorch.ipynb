{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from project_utils import ModelSaveAndLogHandler\n",
    "from config import models_folder, output_data_folder\n",
    "from config import n_mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = n_mels\n",
    "CANDIDATE_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mobile net\n",
    "# model = models.mobilenet_v2(pretrained=False)\n",
    "# summary(model, input_size=(3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mobile net classifier\n",
    "# model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             864\n",
      "       BatchNorm2d-2           [-1, 32, 64, 64]              64\n",
      "             ReLU6-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]             288\n",
      "       BatchNorm2d-5           [-1, 32, 64, 64]              64\n",
      "             ReLU6-6           [-1, 32, 64, 64]               0\n",
      "            Conv2d-7           [-1, 16, 64, 64]             512\n",
      "       BatchNorm2d-8           [-1, 16, 64, 64]              32\n",
      "  InvertedResidual-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 96, 64, 64]           1,536\n",
      "      BatchNorm2d-11           [-1, 96, 64, 64]             192\n",
      "            ReLU6-12           [-1, 96, 64, 64]               0\n",
      "           Conv2d-13           [-1, 96, 32, 32]             864\n",
      "      BatchNorm2d-14           [-1, 96, 32, 32]             192\n",
      "            ReLU6-15           [-1, 96, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 32, 32]             288\n",
      "            ReLU6-21          [-1, 144, 32, 32]               0\n",
      "           Conv2d-22          [-1, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 32, 32]             288\n",
      "            ReLU6-24          [-1, 144, 32, 32]               0\n",
      "           Conv2d-25           [-1, 24, 32, 32]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-27           [-1, 24, 32, 32]               0\n",
      "           Conv2d-28          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 32, 32]             288\n",
      "            ReLU6-30          [-1, 144, 32, 32]               0\n",
      "           Conv2d-31          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 16, 16]             288\n",
      "            ReLU6-33          [-1, 144, 16, 16]               0\n",
      "           Conv2d-34           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-36           [-1, 32, 16, 16]               0\n",
      "           Conv2d-37          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 16, 16]             384\n",
      "            ReLU6-39          [-1, 192, 16, 16]               0\n",
      "           Conv2d-40          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 16, 16]             384\n",
      "            ReLU6-42          [-1, 192, 16, 16]               0\n",
      "           Conv2d-43           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-45           [-1, 32, 16, 16]               0\n",
      "           Conv2d-46          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 16, 16]             384\n",
      "            ReLU6-48          [-1, 192, 16, 16]               0\n",
      "           Conv2d-49          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 16, 16]             384\n",
      "            ReLU6-51          [-1, 192, 16, 16]               0\n",
      "           Conv2d-52           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 16, 16]             384\n",
      "            ReLU6-57          [-1, 192, 16, 16]               0\n",
      "           Conv2d-58            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-59            [-1, 192, 8, 8]             384\n",
      "            ReLU6-60            [-1, 192, 8, 8]               0\n",
      "           Conv2d-61             [-1, 64, 8, 8]          12,288\n",
      "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-63             [-1, 64, 8, 8]               0\n",
      "           Conv2d-64            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-65            [-1, 384, 8, 8]             768\n",
      "            ReLU6-66            [-1, 384, 8, 8]               0\n",
      "           Conv2d-67            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-68            [-1, 384, 8, 8]             768\n",
      "            ReLU6-69            [-1, 384, 8, 8]               0\n",
      "           Conv2d-70             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-71             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-72             [-1, 64, 8, 8]               0\n",
      "           Conv2d-73            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-74            [-1, 384, 8, 8]             768\n",
      "            ReLU6-75            [-1, 384, 8, 8]               0\n",
      "           Conv2d-76            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-77            [-1, 384, 8, 8]             768\n",
      "            ReLU6-78            [-1, 384, 8, 8]               0\n",
      "           Conv2d-79             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-81             [-1, 64, 8, 8]               0\n",
      "           Conv2d-82            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-83            [-1, 384, 8, 8]             768\n",
      "            ReLU6-84            [-1, 384, 8, 8]               0\n",
      "           Conv2d-85            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-86            [-1, 384, 8, 8]             768\n",
      "            ReLU6-87            [-1, 384, 8, 8]               0\n",
      "           Conv2d-88             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-90             [-1, 64, 8, 8]               0\n",
      "           Conv2d-91            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-92            [-1, 384, 8, 8]             768\n",
      "            ReLU6-93            [-1, 384, 8, 8]               0\n",
      "           Conv2d-94            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-95            [-1, 384, 8, 8]             768\n",
      "            ReLU6-96            [-1, 384, 8, 8]               0\n",
      "           Conv2d-97             [-1, 96, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 96, 8, 8]             192\n",
      " InvertedResidual-99             [-1, 96, 8, 8]               0\n",
      "          Conv2d-100            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-101            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-102            [-1, 576, 8, 8]               0\n",
      "          Conv2d-103            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-104            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-105            [-1, 576, 8, 8]               0\n",
      "          Conv2d-106             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-107             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-108             [-1, 96, 8, 8]               0\n",
      "          Conv2d-109            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-110            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-111            [-1, 576, 8, 8]               0\n",
      "          Conv2d-112            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-113            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-114            [-1, 576, 8, 8]               0\n",
      "          Conv2d-115             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-116             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-117             [-1, 96, 8, 8]               0\n",
      "          Conv2d-118            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-119            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-120            [-1, 576, 8, 8]               0\n",
      "          Conv2d-121            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-123            [-1, 576, 4, 4]               0\n",
      "          Conv2d-124            [-1, 160, 4, 4]          92,160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-125            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-126            [-1, 160, 4, 4]               0\n",
      "          Conv2d-127            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-129            [-1, 960, 4, 4]               0\n",
      "          Conv2d-130            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-132            [-1, 960, 4, 4]               0\n",
      "          Conv2d-133            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-135            [-1, 160, 4, 4]               0\n",
      "          Conv2d-136            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-138            [-1, 960, 4, 4]               0\n",
      "          Conv2d-139            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-141            [-1, 960, 4, 4]               0\n",
      "          Conv2d-142            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-144            [-1, 160, 4, 4]               0\n",
      "          Conv2d-145            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-147            [-1, 960, 4, 4]               0\n",
      "          Conv2d-148            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-150            [-1, 960, 4, 4]               0\n",
      "          Conv2d-151            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-153            [-1, 320, 4, 4]               0\n",
      "          Conv2d-154           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-156           [-1, 1280, 4, 4]               0\n",
      "          Linear-157                  [-1, 512]         655,872\n",
      "     MobileNetV2-158                  [-1, 512]               0\n",
      "================================================================\n",
      "Total params: 2,879,744\n",
      "Trainable params: 2,879,744\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 49.92\n",
      "Params size (MB): 10.99\n",
      "Estimated Total Size (MB): 61.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class EncoderNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderNet, self).__init__()\n",
    "        self.encoder = models.mobilenet_v2(pretrained=False)   # base model (transfer learning)\n",
    "        self.encoder.classifier = nn.Sequential(\n",
    "            nn.Linear(1280, 512),   # encoding layer, mobile_netV2 output: 1280 \n",
    "        )      \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)  \n",
    "        \n",
    "summary(EncoderNet(), input_size=(3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             864\n",
      "       BatchNorm2d-2           [-1, 32, 64, 64]              64\n",
      "             ReLU6-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]             288\n",
      "       BatchNorm2d-5           [-1, 32, 64, 64]              64\n",
      "             ReLU6-6           [-1, 32, 64, 64]               0\n",
      "            Conv2d-7           [-1, 16, 64, 64]             512\n",
      "       BatchNorm2d-8           [-1, 16, 64, 64]              32\n",
      "  InvertedResidual-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 96, 64, 64]           1,536\n",
      "      BatchNorm2d-11           [-1, 96, 64, 64]             192\n",
      "            ReLU6-12           [-1, 96, 64, 64]               0\n",
      "           Conv2d-13           [-1, 96, 32, 32]             864\n",
      "      BatchNorm2d-14           [-1, 96, 32, 32]             192\n",
      "            ReLU6-15           [-1, 96, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 32, 32]             288\n",
      "            ReLU6-21          [-1, 144, 32, 32]               0\n",
      "           Conv2d-22          [-1, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 32, 32]             288\n",
      "            ReLU6-24          [-1, 144, 32, 32]               0\n",
      "           Conv2d-25           [-1, 24, 32, 32]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-27           [-1, 24, 32, 32]               0\n",
      "           Conv2d-28          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 32, 32]             288\n",
      "            ReLU6-30          [-1, 144, 32, 32]               0\n",
      "           Conv2d-31          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 16, 16]             288\n",
      "            ReLU6-33          [-1, 144, 16, 16]               0\n",
      "           Conv2d-34           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-36           [-1, 32, 16, 16]               0\n",
      "           Conv2d-37          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 16, 16]             384\n",
      "            ReLU6-39          [-1, 192, 16, 16]               0\n",
      "           Conv2d-40          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 16, 16]             384\n",
      "            ReLU6-42          [-1, 192, 16, 16]               0\n",
      "           Conv2d-43           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-45           [-1, 32, 16, 16]               0\n",
      "           Conv2d-46          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 16, 16]             384\n",
      "            ReLU6-48          [-1, 192, 16, 16]               0\n",
      "           Conv2d-49          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 16, 16]             384\n",
      "            ReLU6-51          [-1, 192, 16, 16]               0\n",
      "           Conv2d-52           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 16, 16]             384\n",
      "            ReLU6-57          [-1, 192, 16, 16]               0\n",
      "           Conv2d-58            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-59            [-1, 192, 8, 8]             384\n",
      "            ReLU6-60            [-1, 192, 8, 8]               0\n",
      "           Conv2d-61             [-1, 64, 8, 8]          12,288\n",
      "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-63             [-1, 64, 8, 8]               0\n",
      "           Conv2d-64            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-65            [-1, 384, 8, 8]             768\n",
      "            ReLU6-66            [-1, 384, 8, 8]               0\n",
      "           Conv2d-67            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-68            [-1, 384, 8, 8]             768\n",
      "            ReLU6-69            [-1, 384, 8, 8]               0\n",
      "           Conv2d-70             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-71             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-72             [-1, 64, 8, 8]               0\n",
      "           Conv2d-73            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-74            [-1, 384, 8, 8]             768\n",
      "            ReLU6-75            [-1, 384, 8, 8]               0\n",
      "           Conv2d-76            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-77            [-1, 384, 8, 8]             768\n",
      "            ReLU6-78            [-1, 384, 8, 8]               0\n",
      "           Conv2d-79             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-81             [-1, 64, 8, 8]               0\n",
      "           Conv2d-82            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-83            [-1, 384, 8, 8]             768\n",
      "            ReLU6-84            [-1, 384, 8, 8]               0\n",
      "           Conv2d-85            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-86            [-1, 384, 8, 8]             768\n",
      "            ReLU6-87            [-1, 384, 8, 8]               0\n",
      "           Conv2d-88             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-90             [-1, 64, 8, 8]               0\n",
      "           Conv2d-91            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-92            [-1, 384, 8, 8]             768\n",
      "            ReLU6-93            [-1, 384, 8, 8]               0\n",
      "           Conv2d-94            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-95            [-1, 384, 8, 8]             768\n",
      "            ReLU6-96            [-1, 384, 8, 8]               0\n",
      "           Conv2d-97             [-1, 96, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 96, 8, 8]             192\n",
      " InvertedResidual-99             [-1, 96, 8, 8]               0\n",
      "          Conv2d-100            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-101            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-102            [-1, 576, 8, 8]               0\n",
      "          Conv2d-103            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-104            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-105            [-1, 576, 8, 8]               0\n",
      "          Conv2d-106             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-107             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-108             [-1, 96, 8, 8]               0\n",
      "          Conv2d-109            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-110            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-111            [-1, 576, 8, 8]               0\n",
      "          Conv2d-112            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-113            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-114            [-1, 576, 8, 8]               0\n",
      "          Conv2d-115             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-116             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-117             [-1, 96, 8, 8]               0\n",
      "          Conv2d-118            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-119            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-120            [-1, 576, 8, 8]               0\n",
      "          Conv2d-121            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-123            [-1, 576, 4, 4]               0\n",
      "          Conv2d-124            [-1, 160, 4, 4]          92,160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-125            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-126            [-1, 160, 4, 4]               0\n",
      "          Conv2d-127            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-129            [-1, 960, 4, 4]               0\n",
      "          Conv2d-130            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-132            [-1, 960, 4, 4]               0\n",
      "          Conv2d-133            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-135            [-1, 160, 4, 4]               0\n",
      "          Conv2d-136            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-138            [-1, 960, 4, 4]               0\n",
      "          Conv2d-139            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-141            [-1, 960, 4, 4]               0\n",
      "          Conv2d-142            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-144            [-1, 160, 4, 4]               0\n",
      "          Conv2d-145            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-147            [-1, 960, 4, 4]               0\n",
      "          Conv2d-148            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-150            [-1, 960, 4, 4]               0\n",
      "          Conv2d-151            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-153            [-1, 320, 4, 4]               0\n",
      "          Conv2d-154           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-156           [-1, 1280, 4, 4]               0\n",
      "          Linear-157                  [-1, 512]         655,872\n",
      "     MobileNetV2-158                  [-1, 512]               0\n",
      "      EncoderNet-159                  [-1, 512]               0\n",
      "        Identity-160                  [-1, 512]               0\n",
      "          Conv2d-161           [-1, 32, 64, 64]             864\n",
      "     BatchNorm2d-162           [-1, 32, 64, 64]              64\n",
      "           ReLU6-163           [-1, 32, 64, 64]               0\n",
      "          Conv2d-164           [-1, 32, 64, 64]             288\n",
      "     BatchNorm2d-165           [-1, 32, 64, 64]              64\n",
      "           ReLU6-166           [-1, 32, 64, 64]               0\n",
      "          Conv2d-167           [-1, 16, 64, 64]             512\n",
      "     BatchNorm2d-168           [-1, 16, 64, 64]              32\n",
      "InvertedResidual-169           [-1, 16, 64, 64]               0\n",
      "          Conv2d-170           [-1, 96, 64, 64]           1,536\n",
      "     BatchNorm2d-171           [-1, 96, 64, 64]             192\n",
      "           ReLU6-172           [-1, 96, 64, 64]               0\n",
      "          Conv2d-173           [-1, 96, 32, 32]             864\n",
      "     BatchNorm2d-174           [-1, 96, 32, 32]             192\n",
      "           ReLU6-175           [-1, 96, 32, 32]               0\n",
      "          Conv2d-176           [-1, 24, 32, 32]           2,304\n",
      "     BatchNorm2d-177           [-1, 24, 32, 32]              48\n",
      "InvertedResidual-178           [-1, 24, 32, 32]               0\n",
      "          Conv2d-179          [-1, 144, 32, 32]           3,456\n",
      "     BatchNorm2d-180          [-1, 144, 32, 32]             288\n",
      "           ReLU6-181          [-1, 144, 32, 32]               0\n",
      "          Conv2d-182          [-1, 144, 32, 32]           1,296\n",
      "     BatchNorm2d-183          [-1, 144, 32, 32]             288\n",
      "           ReLU6-184          [-1, 144, 32, 32]               0\n",
      "          Conv2d-185           [-1, 24, 32, 32]           3,456\n",
      "     BatchNorm2d-186           [-1, 24, 32, 32]              48\n",
      "InvertedResidual-187           [-1, 24, 32, 32]               0\n",
      "          Conv2d-188          [-1, 144, 32, 32]           3,456\n",
      "     BatchNorm2d-189          [-1, 144, 32, 32]             288\n",
      "           ReLU6-190          [-1, 144, 32, 32]               0\n",
      "          Conv2d-191          [-1, 144, 16, 16]           1,296\n",
      "     BatchNorm2d-192          [-1, 144, 16, 16]             288\n",
      "           ReLU6-193          [-1, 144, 16, 16]               0\n",
      "          Conv2d-194           [-1, 32, 16, 16]           4,608\n",
      "     BatchNorm2d-195           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-196           [-1, 32, 16, 16]               0\n",
      "          Conv2d-197          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-198          [-1, 192, 16, 16]             384\n",
      "           ReLU6-199          [-1, 192, 16, 16]               0\n",
      "          Conv2d-200          [-1, 192, 16, 16]           1,728\n",
      "     BatchNorm2d-201          [-1, 192, 16, 16]             384\n",
      "           ReLU6-202          [-1, 192, 16, 16]               0\n",
      "          Conv2d-203           [-1, 32, 16, 16]           6,144\n",
      "     BatchNorm2d-204           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-205           [-1, 32, 16, 16]               0\n",
      "          Conv2d-206          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-207          [-1, 192, 16, 16]             384\n",
      "           ReLU6-208          [-1, 192, 16, 16]               0\n",
      "          Conv2d-209          [-1, 192, 16, 16]           1,728\n",
      "     BatchNorm2d-210          [-1, 192, 16, 16]             384\n",
      "           ReLU6-211          [-1, 192, 16, 16]               0\n",
      "          Conv2d-212           [-1, 32, 16, 16]           6,144\n",
      "     BatchNorm2d-213           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-214           [-1, 32, 16, 16]               0\n",
      "          Conv2d-215          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-216          [-1, 192, 16, 16]             384\n",
      "           ReLU6-217          [-1, 192, 16, 16]               0\n",
      "          Conv2d-218            [-1, 192, 8, 8]           1,728\n",
      "     BatchNorm2d-219            [-1, 192, 8, 8]             384\n",
      "           ReLU6-220            [-1, 192, 8, 8]               0\n",
      "          Conv2d-221             [-1, 64, 8, 8]          12,288\n",
      "     BatchNorm2d-222             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-223             [-1, 64, 8, 8]               0\n",
      "          Conv2d-224            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-225            [-1, 384, 8, 8]             768\n",
      "           ReLU6-226            [-1, 384, 8, 8]               0\n",
      "          Conv2d-227            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-228            [-1, 384, 8, 8]             768\n",
      "           ReLU6-229            [-1, 384, 8, 8]               0\n",
      "          Conv2d-230             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-231             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-232             [-1, 64, 8, 8]               0\n",
      "          Conv2d-233            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-234            [-1, 384, 8, 8]             768\n",
      "           ReLU6-235            [-1, 384, 8, 8]               0\n",
      "          Conv2d-236            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-237            [-1, 384, 8, 8]             768\n",
      "           ReLU6-238            [-1, 384, 8, 8]               0\n",
      "          Conv2d-239             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-240             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-241             [-1, 64, 8, 8]               0\n",
      "          Conv2d-242            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-243            [-1, 384, 8, 8]             768\n",
      "           ReLU6-244            [-1, 384, 8, 8]               0\n",
      "          Conv2d-245            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-246            [-1, 384, 8, 8]             768\n",
      "           ReLU6-247            [-1, 384, 8, 8]               0\n",
      "          Conv2d-248             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-249             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-250             [-1, 64, 8, 8]               0\n",
      "          Conv2d-251            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-252            [-1, 384, 8, 8]             768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ReLU6-253            [-1, 384, 8, 8]               0\n",
      "          Conv2d-254            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-255            [-1, 384, 8, 8]             768\n",
      "           ReLU6-256            [-1, 384, 8, 8]               0\n",
      "          Conv2d-257             [-1, 96, 8, 8]          36,864\n",
      "     BatchNorm2d-258             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-259             [-1, 96, 8, 8]               0\n",
      "          Conv2d-260            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-261            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-262            [-1, 576, 8, 8]               0\n",
      "          Conv2d-263            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-264            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-265            [-1, 576, 8, 8]               0\n",
      "          Conv2d-266             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-267             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-268             [-1, 96, 8, 8]               0\n",
      "          Conv2d-269            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-270            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-271            [-1, 576, 8, 8]               0\n",
      "          Conv2d-272            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-273            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-274            [-1, 576, 8, 8]               0\n",
      "          Conv2d-275             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-276             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-277             [-1, 96, 8, 8]               0\n",
      "          Conv2d-278            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-279            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-280            [-1, 576, 8, 8]               0\n",
      "          Conv2d-281            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-282            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-283            [-1, 576, 4, 4]               0\n",
      "          Conv2d-284            [-1, 160, 4, 4]          92,160\n",
      "     BatchNorm2d-285            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-286            [-1, 160, 4, 4]               0\n",
      "          Conv2d-287            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-288            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-289            [-1, 960, 4, 4]               0\n",
      "          Conv2d-290            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-291            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-292            [-1, 960, 4, 4]               0\n",
      "          Conv2d-293            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-294            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-295            [-1, 160, 4, 4]               0\n",
      "          Conv2d-296            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-297            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-298            [-1, 960, 4, 4]               0\n",
      "          Conv2d-299            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-300            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-301            [-1, 960, 4, 4]               0\n",
      "          Conv2d-302            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-303            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-304            [-1, 160, 4, 4]               0\n",
      "          Conv2d-305            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-306            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-307            [-1, 960, 4, 4]               0\n",
      "          Conv2d-308            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-309            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-310            [-1, 960, 4, 4]               0\n",
      "          Conv2d-311            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-312            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-313            [-1, 320, 4, 4]               0\n",
      "          Conv2d-314           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-315           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-316           [-1, 1280, 4, 4]               0\n",
      "          Linear-317                  [-1, 512]         655,872\n",
      "     MobileNetV2-318                  [-1, 512]               0\n",
      "      EncoderNet-319                  [-1, 512]               0\n",
      "        Identity-320                  [-1, 512]               0\n",
      "================================================================\n",
      "Total params: 5,759,488\n",
      "Trainable params: 5,759,488\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.12\n",
      "Forward/backward pass size (MB): 99.85\n",
      "Params size (MB): 21.97\n",
      "Estimated Total Size (MB): 122.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class MultiSiameseEncoderNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiSiameseEncoderNet, self).__init__()\n",
    "        self.encoder = EncoderNet()\n",
    "        self.encoding_projection = nn.Sequential(\n",
    "#             nn.Tanh(),\n",
    "#             nn.Linear(512, 512),   # projection layer\n",
    "#             nn.Tanh(),\n",
    "# #             nn.ReLU(),\n",
    "#             nn.Linear(512, 512),   # projection layer\n",
    "            nn.Identity(),\n",
    "        )\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.encoding_projection(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, input_imgs):\n",
    "        # cosine sim of query img against each batch img\n",
    "        query_img_encoding = self.encode(input_imgs[0])   # 1st img is the query img\n",
    "        cosine_sims = []\n",
    "        for i in range(1, len(input_imgs)):   # batch imgs\n",
    "            batch_img_encoding = self.encode(input_imgs[i])\n",
    "            cosine_sims.append(F.cosine_similarity(query_img_encoding, batch_img_encoding))\n",
    "        return torch.stack(cosine_sims, dim=1)   # concat cosine sims\n",
    "    \n",
    "summary(MultiSiameseEncoderNet(), input_size=(CANDIDATE_SIZE+1, 3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    \n",
    "    def __init__(self, spectrogram_samples_files, candidate_size, batch_size, num_batches, num_sub_samples, img_height):\n",
    "        self.spectrogram_samples_files = spectrogram_samples_files   # list of filepaths\n",
    "        self.candidate_size = candidate_size   # 1 positive, n-1 negatives\n",
    "        self.batch_size = batch_size   # batch size\n",
    "        self.num_batches = num_batches   # num batches per epoch\n",
    "        self.num_sub_samples = num_sub_samples   # num sub-samples per epoch\n",
    "        self.img_height = img_height   # height of square img to be generated in the batches\n",
    "        self.sub_samples = []   # list of RGB converted spectrograms\n",
    "    \n",
    "    def generate_batches(self):\n",
    "        while True:\n",
    "            self.create_sub_samples()\n",
    "            # batches per epoch\n",
    "            for _ in range(self.num_batches):\n",
    "                # create batch\n",
    "                labels = []\n",
    "                query_and_candidate_imgs = [[] for _ in range(self.candidate_size + 1)]\n",
    "                for _ in range(self.batch_size):\n",
    "                    sample_spectrograms_indices = random.sample(range(self.num_sub_samples), self.candidate_size)   # sample candidates\n",
    "                    pos_idx = sample_spectrograms_indices[0]   # positive sample\n",
    "                    # Generate query image\n",
    "                    query_img = self.get_sliding_img_slice_from_spectrogram(self.sub_samples[pos_idx])\n",
    "                    # Generate batch images\n",
    "                    random.shuffle(sample_spectrograms_indices)\n",
    "                    candidate_imgs = [self.get_sliding_img_slice_from_spectrogram(self.sub_samples[idx]) for idx in sample_spectrograms_indices]\n",
    "                    # get class label / idx of positive sample\n",
    "                    pos_candidate_idx = sample_spectrograms_indices.index(pos_idx)   \n",
    "                    labels.append(pos_candidate_idx)\n",
    "                    # Normalize input imgs\n",
    "                    for i, img in enumerate([query_img, *candidate_imgs]):\n",
    "                        img = img / np.amax(np.absolute(img))   # normalize to range [-1, 1]\n",
    "                        query_and_candidate_imgs[i].append(img)\n",
    "                # Convert to tensor\n",
    "                labels = torch.tensor(labels)\n",
    "                input_imgs = torch.tensor(query_and_candidate_imgs)\n",
    "                yield (input_imgs, labels)\n",
    "    \n",
    "    def create_sub_samples(self):\n",
    "        self.sub_samples = []   # reset\n",
    "        files = random.sample(self.spectrogram_samples_files, self.num_sub_samples)   # sampling without replacement\n",
    "        for file in files:\n",
    "#             print(file)\n",
    "            spectrogram = np.load(file)\n",
    "            assert spectrogram.shape[0] == self.img_height, \"Input spectrogram height does not match img height\"\n",
    "            self.sub_samples.append(spectrogram)\n",
    "    \n",
    "    @classmethod\n",
    "    def get_sliding_img_slice_from_spectrogram(cls, spectrogram, depth=3, sliding_ratio=2):\n",
    "        ### Combine multiple sliding greyscale img slices into an n-depth image\n",
    "        height = spectrogram.shape[0]\n",
    "        slide_step = height//sliding_ratio\n",
    "        img_slice = np.zeros((depth,height,height))   # initialize empty img (pytorch style)\n",
    "        # Get random start idx\n",
    "        slice_start = random.randint(0, spectrogram.shape[1] - (slide_step*(depth+1)) - 1)\n",
    "        for i in range(depth):\n",
    "            img_slice[i,:,:] = spectrogram[:, slice_start:slice_start+height]   # get slice (pytorch style)\n",
    "            slice_start += slide_step   # slide\n",
    "        img_slice = img_slice.astype(\"float32\")\n",
    "        return img_slice\n",
    "    \n",
    "    @classmethod\n",
    "    def spectrogram_to_RGB(cls, spectrogram):\n",
    "        assert len(spectrogram.shape) == 2, \"Spectrogram input should be a 2D array\"\n",
    "        spectrogram_rgb = gray2rgb(spectrogram)\n",
    "        return spectrogram_rgb\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder = os.path.join(output_data_folder, \"training_dataset_full_spectrogram/vox1_dev_wav\")\n",
    "spectrogram_samples_files = [os.path.join(training_folder, file) for file in os.listdir(training_folder)]\n",
    "candidate_size = CANDIDATE_SIZE\n",
    "batch_size = 15\n",
    "num_batches = 1000 // batch_size\n",
    "# num_batches = 200 // batch_size\n",
    "# num_batches = 100\n",
    "num_sub_samples = 100\n",
    "# num_sub_samples = 20\n",
    "training_data_generator = DataGenerator(spectrogram_samples_files, candidate_size, batch_size, num_batches, num_sub_samples, IMG_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, num_batches, training_data_generator, log_handler):\n",
    "    since = time.time()\n",
    "\n",
    "#     best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    t1 = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        log_handler.print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        log_handler.print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            num_batch_modified = num_batches if phase == 'train' else num_batches // 20\n",
    "            for i, data in zip(range(num_batch_modified), training_data_generator.generate_batches()):               \n",
    "                input_imgs, labels = data\n",
    "                inputs = [img.to(device) for img in input_imgs]\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):   # gradient only for train\n",
    "                    outputs = model(inputs)   \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs[0].size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / (num_batch_modified * inputs[0].size(0))\n",
    "            epoch_acc = running_corrects.double() / (num_batch_modified * inputs[0].size(0))\n",
    "\n",
    "            log_handler.print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                log_handler.save_pytorch_model(model, \"best_model_{}.pt\".format(model.__class__.__name__))\n",
    "\n",
    "        # end of epoch\n",
    "        log_handler.print(\"Time taken is {} seconds\".format(int(time.time()-t1)))\n",
    "        t1 = time.time()\n",
    "        log_handler.print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    log_handler.print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    log_handler.print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Desktop\\projects\\speaker_recognition_voxceleb1\\output_data\\models\\contrastive_encoder\\2020-03-15_16-49-51\n",
      "Description: Candidates: 5, Encoding: 512, Projection: None\n",
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 1.5484 Acc: 0.2818\n",
      "val Loss: 1.4971 Acc: 0.3556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type MultiSiameseEncoderNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type EncoderNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL SAVED\n",
      "Time taken is 74 seconds\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 1.5119 Acc: 0.3182\n",
      "val Loss: 1.4195 Acc: 0.3333\n",
      "Time taken is 69 seconds\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 1.4709 Acc: 0.3253\n",
      "val Loss: 1.6923 Acc: 0.2222\n",
      "Time taken is 68 seconds\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 1.5144 Acc: 0.3192\n",
      "val Loss: 1.3970 Acc: 0.4000\n",
      "MODEL SAVED\n",
      "Time taken is 64 seconds\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 1.4832 Acc: 0.2990\n",
      "val Loss: 1.3275 Acc: 0.2889\n",
      "Time taken is 67 seconds\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 1.4318 Acc: 0.3616\n",
      "val Loss: 1.4670 Acc: 0.3778\n",
      "Time taken is 63 seconds\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 1.3592 Acc: 0.3889\n",
      "val Loss: 1.3101 Acc: 0.4444\n",
      "MODEL SAVED\n",
      "Time taken is 62 seconds\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 1.3239 Acc: 0.3818\n",
      "val Loss: 1.4206 Acc: 0.4000\n",
      "Time taken is 61 seconds\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 1.3736 Acc: 0.3737\n",
      "val Loss: 1.2816 Acc: 0.4667\n",
      "MODEL SAVED\n",
      "Time taken is 60 seconds\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 1.3842 Acc: 0.3576\n",
      "val Loss: 1.3881 Acc: 0.3333\n",
      "Time taken is 59 seconds\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 1.2989 Acc: 0.4131\n",
      "val Loss: 1.3374 Acc: 0.4222\n",
      "Time taken is 59 seconds\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 1.3441 Acc: 0.3838\n",
      "val Loss: 1.2442 Acc: 0.4889\n",
      "MODEL SAVED\n",
      "Time taken is 60 seconds\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 1.3969 Acc: 0.3586\n",
      "val Loss: 1.3345 Acc: 0.4889\n",
      "Time taken is 60 seconds\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 1.3283 Acc: 0.4232\n",
      "val Loss: 1.1895 Acc: 0.4889\n",
      "Time taken is 60 seconds\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 1.3094 Acc: 0.4010\n",
      "val Loss: 1.4623 Acc: 0.3778\n",
      "Time taken is 59 seconds\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 1.3261 Acc: 0.4253\n",
      "val Loss: 1.2867 Acc: 0.4444\n",
      "Time taken is 61 seconds\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 1.3167 Acc: 0.3848\n",
      "val Loss: 1.2711 Acc: 0.4444\n",
      "Time taken is 61 seconds\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 1.3191 Acc: 0.3808\n",
      "val Loss: 1.3992 Acc: 0.4000\n",
      "Time taken is 59 seconds\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 1.3406 Acc: 0.3758\n",
      "val Loss: 1.4085 Acc: 0.3778\n",
      "Time taken is 59 seconds\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 1.3390 Acc: 0.3778\n",
      "val Loss: 1.1825 Acc: 0.4667\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 1.3061 Acc: 0.3859\n",
      "val Loss: 1.2587 Acc: 0.5111\n",
      "MODEL SAVED\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 1.2857 Acc: 0.4192\n",
      "val Loss: 1.2613 Acc: 0.4667\n",
      "Time taken is 59 seconds\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 1.3427 Acc: 0.3687\n",
      "val Loss: 1.2877 Acc: 0.4667\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 1.3230 Acc: 0.4091\n",
      "val Loss: 1.2466 Acc: 0.4889\n",
      "Time taken is 59 seconds\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 1.3112 Acc: 0.4010\n",
      "val Loss: 1.0580 Acc: 0.6000\n",
      "MODEL SAVED\n",
      "Time taken is 57 seconds\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 1.3276 Acc: 0.4303\n",
      "val Loss: 1.2219 Acc: 0.4667\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 1.2852 Acc: 0.3727\n",
      "val Loss: 1.3293 Acc: 0.3778\n",
      "Time taken is 57 seconds\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 1.3422 Acc: 0.4040\n",
      "val Loss: 1.2458 Acc: 0.5556\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 1.3118 Acc: 0.4192\n",
      "val Loss: 1.3295 Acc: 0.4222\n",
      "Time taken is 57 seconds\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 1.3355 Acc: 0.3939\n",
      "val Loss: 1.3158 Acc: 0.3333\n",
      "Time taken is 59 seconds\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 1.3367 Acc: 0.3970\n",
      "val Loss: 1.3175 Acc: 0.5333\n",
      "Time taken is 59 seconds\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 1.3204 Acc: 0.3828\n",
      "val Loss: 1.3564 Acc: 0.2667\n",
      "Time taken is 59 seconds\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 1.3492 Acc: 0.4020\n",
      "val Loss: 1.2593 Acc: 0.4667\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 1.3498 Acc: 0.4010\n",
      "val Loss: 1.3960 Acc: 0.3111\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 1.3142 Acc: 0.3889\n",
      "val Loss: 1.2562 Acc: 0.4444\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 1.3117 Acc: 0.4081\n",
      "val Loss: 1.3339 Acc: 0.4444\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 1.3349 Acc: 0.4071\n",
      "val Loss: 1.2704 Acc: 0.4222\n",
      "Time taken is 59 seconds\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 1.3166 Acc: 0.4111\n",
      "val Loss: 1.2924 Acc: 0.4444\n",
      "Time taken is 59 seconds\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 1.3208 Acc: 0.4313\n",
      "val Loss: 1.2167 Acc: 0.4889\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 1.3426 Acc: 0.4283\n",
      "val Loss: 1.2810 Acc: 0.4222\n",
      "Time taken is 59 seconds\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 1.3492 Acc: 0.3636\n",
      "val Loss: 1.3275 Acc: 0.4889\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 1.3366 Acc: 0.4111\n",
      "val Loss: 1.1874 Acc: 0.5333\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 1.3571 Acc: 0.3879\n",
      "val Loss: 1.3509 Acc: 0.4444\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 1.3331 Acc: 0.3949\n",
      "val Loss: 1.3539 Acc: 0.4000\n",
      "Time taken is 59 seconds\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 1.3320 Acc: 0.4010\n",
      "val Loss: 1.3046 Acc: 0.2889\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 1.3384 Acc: 0.4081\n",
      "val Loss: 1.3345 Acc: 0.2889\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 1.3221 Acc: 0.3909\n",
      "val Loss: 1.3111 Acc: 0.5556\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 1.3415 Acc: 0.3919\n",
      "val Loss: 1.2708 Acc: 0.4667\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 1.3510 Acc: 0.3960\n",
      "val Loss: 1.4632 Acc: 0.4444\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 1.3164 Acc: 0.4202\n",
      "val Loss: 1.2663 Acc: 0.2889\n",
      "Time taken is 58 seconds\n",
      "\n",
      "Training complete in 50m 14s\n",
      "Best val Acc: 0.600000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiSiameseEncoderNet(\n",
       "  (encoder): EncoderNet(\n",
       "    (encoder): MobileNetV2(\n",
       "      (features): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (6): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (7): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (8): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (9): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (10): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (11): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "              (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (12): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (13): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (14): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "              (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (15): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (16): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (17): InvertedResidual(\n",
       "          (conv): Sequential(\n",
       "            (0): ConvBNReLU(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): ConvBNReLU(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (18): ConvBNReLU(\n",
       "          (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (classifier): Sequential(\n",
       "        (0): Linear(in_features=1280, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoding_projection): Sequential(\n",
       "    (0): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "model_ft = MultiSiameseEncoderNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr = 0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "\n",
    "\n",
    "### Train \n",
    "\n",
    "# Logger\n",
    "model_save_folder = os.path.join(models_folder, \"contrastive_encoder\")\n",
    "log_handler = ModelSaveAndLogHandler(model_save_folder, enable_model_saving=True, enable_logging=True)\n",
    "print(log_handler.folder)\n",
    "\n",
    "# Description\n",
    "log_handler.print(\"Description: Candidates: 5, Encoding: 512, Projection: None\")\n",
    "\n",
    "# Train\n",
    "train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, epochs, num_batches, training_data_generator, log_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_acc = 1 / CANDIDATE_SIZE\n",
    "random_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Overall\n",
    "* Contrastive classifier\n",
    "    * separate train and validate methods\n",
    "\n",
    "* (Done) Model saving / checkpointing\n",
    "* **Build binary classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
