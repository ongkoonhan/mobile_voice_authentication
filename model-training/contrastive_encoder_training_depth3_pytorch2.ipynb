{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from config import models_folder, output_data_folder\n",
    "from config import n_mels\n",
    "\n",
    "from model_definitions import SpectrogramEncoderNet, MultiSiameseContrastiveClassifierNet\n",
    "from project_utils import ModelSaveAndLogHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = n_mels\n",
    "CANDIDATE_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mobile net\n",
    "# model = models.mobilenet_v2(pretrained=False)\n",
    "# summary(model, input_size=(3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mobile net classifier\n",
    "# model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             864\n",
      "       BatchNorm2d-2           [-1, 32, 64, 64]              64\n",
      "             ReLU6-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]             288\n",
      "       BatchNorm2d-5           [-1, 32, 64, 64]              64\n",
      "             ReLU6-6           [-1, 32, 64, 64]               0\n",
      "            Conv2d-7           [-1, 16, 64, 64]             512\n",
      "       BatchNorm2d-8           [-1, 16, 64, 64]              32\n",
      "  InvertedResidual-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 96, 64, 64]           1,536\n",
      "      BatchNorm2d-11           [-1, 96, 64, 64]             192\n",
      "            ReLU6-12           [-1, 96, 64, 64]               0\n",
      "           Conv2d-13           [-1, 96, 32, 32]             864\n",
      "      BatchNorm2d-14           [-1, 96, 32, 32]             192\n",
      "            ReLU6-15           [-1, 96, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 32, 32]             288\n",
      "            ReLU6-21          [-1, 144, 32, 32]               0\n",
      "           Conv2d-22          [-1, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 32, 32]             288\n",
      "            ReLU6-24          [-1, 144, 32, 32]               0\n",
      "           Conv2d-25           [-1, 24, 32, 32]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-27           [-1, 24, 32, 32]               0\n",
      "           Conv2d-28          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 32, 32]             288\n",
      "            ReLU6-30          [-1, 144, 32, 32]               0\n",
      "           Conv2d-31          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 16, 16]             288\n",
      "            ReLU6-33          [-1, 144, 16, 16]               0\n",
      "           Conv2d-34           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-36           [-1, 32, 16, 16]               0\n",
      "           Conv2d-37          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 16, 16]             384\n",
      "            ReLU6-39          [-1, 192, 16, 16]               0\n",
      "           Conv2d-40          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 16, 16]             384\n",
      "            ReLU6-42          [-1, 192, 16, 16]               0\n",
      "           Conv2d-43           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-45           [-1, 32, 16, 16]               0\n",
      "           Conv2d-46          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 16, 16]             384\n",
      "            ReLU6-48          [-1, 192, 16, 16]               0\n",
      "           Conv2d-49          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 16, 16]             384\n",
      "            ReLU6-51          [-1, 192, 16, 16]               0\n",
      "           Conv2d-52           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 16, 16]             384\n",
      "            ReLU6-57          [-1, 192, 16, 16]               0\n",
      "           Conv2d-58            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-59            [-1, 192, 8, 8]             384\n",
      "            ReLU6-60            [-1, 192, 8, 8]               0\n",
      "           Conv2d-61             [-1, 64, 8, 8]          12,288\n",
      "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-63             [-1, 64, 8, 8]               0\n",
      "           Conv2d-64            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-65            [-1, 384, 8, 8]             768\n",
      "            ReLU6-66            [-1, 384, 8, 8]               0\n",
      "           Conv2d-67            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-68            [-1, 384, 8, 8]             768\n",
      "            ReLU6-69            [-1, 384, 8, 8]               0\n",
      "           Conv2d-70             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-71             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-72             [-1, 64, 8, 8]               0\n",
      "           Conv2d-73            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-74            [-1, 384, 8, 8]             768\n",
      "            ReLU6-75            [-1, 384, 8, 8]               0\n",
      "           Conv2d-76            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-77            [-1, 384, 8, 8]             768\n",
      "            ReLU6-78            [-1, 384, 8, 8]               0\n",
      "           Conv2d-79             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-81             [-1, 64, 8, 8]               0\n",
      "           Conv2d-82            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-83            [-1, 384, 8, 8]             768\n",
      "            ReLU6-84            [-1, 384, 8, 8]               0\n",
      "           Conv2d-85            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-86            [-1, 384, 8, 8]             768\n",
      "            ReLU6-87            [-1, 384, 8, 8]               0\n",
      "           Conv2d-88             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-90             [-1, 64, 8, 8]               0\n",
      "           Conv2d-91            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-92            [-1, 384, 8, 8]             768\n",
      "            ReLU6-93            [-1, 384, 8, 8]               0\n",
      "           Conv2d-94            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-95            [-1, 384, 8, 8]             768\n",
      "            ReLU6-96            [-1, 384, 8, 8]               0\n",
      "           Conv2d-97             [-1, 96, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 96, 8, 8]             192\n",
      " InvertedResidual-99             [-1, 96, 8, 8]               0\n",
      "          Conv2d-100            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-101            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-102            [-1, 576, 8, 8]               0\n",
      "          Conv2d-103            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-104            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-105            [-1, 576, 8, 8]               0\n",
      "          Conv2d-106             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-107             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-108             [-1, 96, 8, 8]               0\n",
      "          Conv2d-109            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-110            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-111            [-1, 576, 8, 8]               0\n",
      "          Conv2d-112            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-113            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-114            [-1, 576, 8, 8]               0\n",
      "          Conv2d-115             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-116             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-117             [-1, 96, 8, 8]               0\n",
      "          Conv2d-118            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-119            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-120            [-1, 576, 8, 8]               0\n",
      "          Conv2d-121            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-123            [-1, 576, 4, 4]               0\n",
      "          Conv2d-124            [-1, 160, 4, 4]          92,160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-125            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-126            [-1, 160, 4, 4]               0\n",
      "          Conv2d-127            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-129            [-1, 960, 4, 4]               0\n",
      "          Conv2d-130            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-132            [-1, 960, 4, 4]               0\n",
      "          Conv2d-133            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-135            [-1, 160, 4, 4]               0\n",
      "          Conv2d-136            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-138            [-1, 960, 4, 4]               0\n",
      "          Conv2d-139            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-141            [-1, 960, 4, 4]               0\n",
      "          Conv2d-142            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-144            [-1, 160, 4, 4]               0\n",
      "          Conv2d-145            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-147            [-1, 960, 4, 4]               0\n",
      "          Conv2d-148            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-150            [-1, 960, 4, 4]               0\n",
      "          Conv2d-151            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-153            [-1, 320, 4, 4]               0\n",
      "          Conv2d-154           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-156           [-1, 1280, 4, 4]               0\n",
      "          Linear-157                  [-1, 128]         163,968\n",
      "     MobileNetV2-158                  [-1, 128]               0\n",
      "================================================================\n",
      "Total params: 2,387,840\n",
      "Trainable params: 2,387,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 49.91\n",
      "Params size (MB): 9.11\n",
      "Estimated Total Size (MB): 59.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(SpectrogramEncoderNet(), input_size=(3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             864\n",
      "       BatchNorm2d-2           [-1, 32, 64, 64]              64\n",
      "             ReLU6-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]             288\n",
      "       BatchNorm2d-5           [-1, 32, 64, 64]              64\n",
      "             ReLU6-6           [-1, 32, 64, 64]               0\n",
      "            Conv2d-7           [-1, 16, 64, 64]             512\n",
      "       BatchNorm2d-8           [-1, 16, 64, 64]              32\n",
      "  InvertedResidual-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 96, 64, 64]           1,536\n",
      "      BatchNorm2d-11           [-1, 96, 64, 64]             192\n",
      "            ReLU6-12           [-1, 96, 64, 64]               0\n",
      "           Conv2d-13           [-1, 96, 32, 32]             864\n",
      "      BatchNorm2d-14           [-1, 96, 32, 32]             192\n",
      "            ReLU6-15           [-1, 96, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 32, 32]             288\n",
      "            ReLU6-21          [-1, 144, 32, 32]               0\n",
      "           Conv2d-22          [-1, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 32, 32]             288\n",
      "            ReLU6-24          [-1, 144, 32, 32]               0\n",
      "           Conv2d-25           [-1, 24, 32, 32]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-27           [-1, 24, 32, 32]               0\n",
      "           Conv2d-28          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 32, 32]             288\n",
      "            ReLU6-30          [-1, 144, 32, 32]               0\n",
      "           Conv2d-31          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 16, 16]             288\n",
      "            ReLU6-33          [-1, 144, 16, 16]               0\n",
      "           Conv2d-34           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-36           [-1, 32, 16, 16]               0\n",
      "           Conv2d-37          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 16, 16]             384\n",
      "            ReLU6-39          [-1, 192, 16, 16]               0\n",
      "           Conv2d-40          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 16, 16]             384\n",
      "            ReLU6-42          [-1, 192, 16, 16]               0\n",
      "           Conv2d-43           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-45           [-1, 32, 16, 16]               0\n",
      "           Conv2d-46          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 16, 16]             384\n",
      "            ReLU6-48          [-1, 192, 16, 16]               0\n",
      "           Conv2d-49          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 16, 16]             384\n",
      "            ReLU6-51          [-1, 192, 16, 16]               0\n",
      "           Conv2d-52           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 16, 16]             384\n",
      "            ReLU6-57          [-1, 192, 16, 16]               0\n",
      "           Conv2d-58            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-59            [-1, 192, 8, 8]             384\n",
      "            ReLU6-60            [-1, 192, 8, 8]               0\n",
      "           Conv2d-61             [-1, 64, 8, 8]          12,288\n",
      "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-63             [-1, 64, 8, 8]               0\n",
      "           Conv2d-64            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-65            [-1, 384, 8, 8]             768\n",
      "            ReLU6-66            [-1, 384, 8, 8]               0\n",
      "           Conv2d-67            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-68            [-1, 384, 8, 8]             768\n",
      "            ReLU6-69            [-1, 384, 8, 8]               0\n",
      "           Conv2d-70             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-71             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-72             [-1, 64, 8, 8]               0\n",
      "           Conv2d-73            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-74            [-1, 384, 8, 8]             768\n",
      "            ReLU6-75            [-1, 384, 8, 8]               0\n",
      "           Conv2d-76            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-77            [-1, 384, 8, 8]             768\n",
      "            ReLU6-78            [-1, 384, 8, 8]               0\n",
      "           Conv2d-79             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-81             [-1, 64, 8, 8]               0\n",
      "           Conv2d-82            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-83            [-1, 384, 8, 8]             768\n",
      "            ReLU6-84            [-1, 384, 8, 8]               0\n",
      "           Conv2d-85            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-86            [-1, 384, 8, 8]             768\n",
      "            ReLU6-87            [-1, 384, 8, 8]               0\n",
      "           Conv2d-88             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-90             [-1, 64, 8, 8]               0\n",
      "           Conv2d-91            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-92            [-1, 384, 8, 8]             768\n",
      "            ReLU6-93            [-1, 384, 8, 8]               0\n",
      "           Conv2d-94            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-95            [-1, 384, 8, 8]             768\n",
      "            ReLU6-96            [-1, 384, 8, 8]               0\n",
      "           Conv2d-97             [-1, 96, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 96, 8, 8]             192\n",
      " InvertedResidual-99             [-1, 96, 8, 8]               0\n",
      "          Conv2d-100            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-101            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-102            [-1, 576, 8, 8]               0\n",
      "          Conv2d-103            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-104            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-105            [-1, 576, 8, 8]               0\n",
      "          Conv2d-106             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-107             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-108             [-1, 96, 8, 8]               0\n",
      "          Conv2d-109            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-110            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-111            [-1, 576, 8, 8]               0\n",
      "          Conv2d-112            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-113            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-114            [-1, 576, 8, 8]               0\n",
      "          Conv2d-115             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-116             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-117             [-1, 96, 8, 8]               0\n",
      "          Conv2d-118            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-119            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-120            [-1, 576, 8, 8]               0\n",
      "          Conv2d-121            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-123            [-1, 576, 4, 4]               0\n",
      "          Conv2d-124            [-1, 160, 4, 4]          92,160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-125            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-126            [-1, 160, 4, 4]               0\n",
      "          Conv2d-127            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-129            [-1, 960, 4, 4]               0\n",
      "          Conv2d-130            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-132            [-1, 960, 4, 4]               0\n",
      "          Conv2d-133            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-135            [-1, 160, 4, 4]               0\n",
      "          Conv2d-136            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-138            [-1, 960, 4, 4]               0\n",
      "          Conv2d-139            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-141            [-1, 960, 4, 4]               0\n",
      "          Conv2d-142            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-144            [-1, 160, 4, 4]               0\n",
      "          Conv2d-145            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-147            [-1, 960, 4, 4]               0\n",
      "          Conv2d-148            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-150            [-1, 960, 4, 4]               0\n",
      "          Conv2d-151            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-153            [-1, 320, 4, 4]               0\n",
      "          Conv2d-154           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-156           [-1, 1280, 4, 4]               0\n",
      "          Linear-157                  [-1, 128]         163,968\n",
      "     MobileNetV2-158                  [-1, 128]               0\n",
      "SpectrogramEncoderNet-159                  [-1, 128]               0\n",
      "        Identity-160                  [-1, 128]               0\n",
      "          Conv2d-161           [-1, 32, 64, 64]             864\n",
      "     BatchNorm2d-162           [-1, 32, 64, 64]              64\n",
      "           ReLU6-163           [-1, 32, 64, 64]               0\n",
      "          Conv2d-164           [-1, 32, 64, 64]             288\n",
      "     BatchNorm2d-165           [-1, 32, 64, 64]              64\n",
      "           ReLU6-166           [-1, 32, 64, 64]               0\n",
      "          Conv2d-167           [-1, 16, 64, 64]             512\n",
      "     BatchNorm2d-168           [-1, 16, 64, 64]              32\n",
      "InvertedResidual-169           [-1, 16, 64, 64]               0\n",
      "          Conv2d-170           [-1, 96, 64, 64]           1,536\n",
      "     BatchNorm2d-171           [-1, 96, 64, 64]             192\n",
      "           ReLU6-172           [-1, 96, 64, 64]               0\n",
      "          Conv2d-173           [-1, 96, 32, 32]             864\n",
      "     BatchNorm2d-174           [-1, 96, 32, 32]             192\n",
      "           ReLU6-175           [-1, 96, 32, 32]               0\n",
      "          Conv2d-176           [-1, 24, 32, 32]           2,304\n",
      "     BatchNorm2d-177           [-1, 24, 32, 32]              48\n",
      "InvertedResidual-178           [-1, 24, 32, 32]               0\n",
      "          Conv2d-179          [-1, 144, 32, 32]           3,456\n",
      "     BatchNorm2d-180          [-1, 144, 32, 32]             288\n",
      "           ReLU6-181          [-1, 144, 32, 32]               0\n",
      "          Conv2d-182          [-1, 144, 32, 32]           1,296\n",
      "     BatchNorm2d-183          [-1, 144, 32, 32]             288\n",
      "           ReLU6-184          [-1, 144, 32, 32]               0\n",
      "          Conv2d-185           [-1, 24, 32, 32]           3,456\n",
      "     BatchNorm2d-186           [-1, 24, 32, 32]              48\n",
      "InvertedResidual-187           [-1, 24, 32, 32]               0\n",
      "          Conv2d-188          [-1, 144, 32, 32]           3,456\n",
      "     BatchNorm2d-189          [-1, 144, 32, 32]             288\n",
      "           ReLU6-190          [-1, 144, 32, 32]               0\n",
      "          Conv2d-191          [-1, 144, 16, 16]           1,296\n",
      "     BatchNorm2d-192          [-1, 144, 16, 16]             288\n",
      "           ReLU6-193          [-1, 144, 16, 16]               0\n",
      "          Conv2d-194           [-1, 32, 16, 16]           4,608\n",
      "     BatchNorm2d-195           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-196           [-1, 32, 16, 16]               0\n",
      "          Conv2d-197          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-198          [-1, 192, 16, 16]             384\n",
      "           ReLU6-199          [-1, 192, 16, 16]               0\n",
      "          Conv2d-200          [-1, 192, 16, 16]           1,728\n",
      "     BatchNorm2d-201          [-1, 192, 16, 16]             384\n",
      "           ReLU6-202          [-1, 192, 16, 16]               0\n",
      "          Conv2d-203           [-1, 32, 16, 16]           6,144\n",
      "     BatchNorm2d-204           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-205           [-1, 32, 16, 16]               0\n",
      "          Conv2d-206          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-207          [-1, 192, 16, 16]             384\n",
      "           ReLU6-208          [-1, 192, 16, 16]               0\n",
      "          Conv2d-209          [-1, 192, 16, 16]           1,728\n",
      "     BatchNorm2d-210          [-1, 192, 16, 16]             384\n",
      "           ReLU6-211          [-1, 192, 16, 16]               0\n",
      "          Conv2d-212           [-1, 32, 16, 16]           6,144\n",
      "     BatchNorm2d-213           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-214           [-1, 32, 16, 16]               0\n",
      "          Conv2d-215          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-216          [-1, 192, 16, 16]             384\n",
      "           ReLU6-217          [-1, 192, 16, 16]               0\n",
      "          Conv2d-218            [-1, 192, 8, 8]           1,728\n",
      "     BatchNorm2d-219            [-1, 192, 8, 8]             384\n",
      "           ReLU6-220            [-1, 192, 8, 8]               0\n",
      "          Conv2d-221             [-1, 64, 8, 8]          12,288\n",
      "     BatchNorm2d-222             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-223             [-1, 64, 8, 8]               0\n",
      "          Conv2d-224            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-225            [-1, 384, 8, 8]             768\n",
      "           ReLU6-226            [-1, 384, 8, 8]               0\n",
      "          Conv2d-227            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-228            [-1, 384, 8, 8]             768\n",
      "           ReLU6-229            [-1, 384, 8, 8]               0\n",
      "          Conv2d-230             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-231             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-232             [-1, 64, 8, 8]               0\n",
      "          Conv2d-233            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-234            [-1, 384, 8, 8]             768\n",
      "           ReLU6-235            [-1, 384, 8, 8]               0\n",
      "          Conv2d-236            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-237            [-1, 384, 8, 8]             768\n",
      "           ReLU6-238            [-1, 384, 8, 8]               0\n",
      "          Conv2d-239             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-240             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-241             [-1, 64, 8, 8]               0\n",
      "          Conv2d-242            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-243            [-1, 384, 8, 8]             768\n",
      "           ReLU6-244            [-1, 384, 8, 8]               0\n",
      "          Conv2d-245            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-246            [-1, 384, 8, 8]             768\n",
      "           ReLU6-247            [-1, 384, 8, 8]               0\n",
      "          Conv2d-248             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-249             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-250             [-1, 64, 8, 8]               0\n",
      "          Conv2d-251            [-1, 384, 8, 8]          24,576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-252            [-1, 384, 8, 8]             768\n",
      "           ReLU6-253            [-1, 384, 8, 8]               0\n",
      "          Conv2d-254            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-255            [-1, 384, 8, 8]             768\n",
      "           ReLU6-256            [-1, 384, 8, 8]               0\n",
      "          Conv2d-257             [-1, 96, 8, 8]          36,864\n",
      "     BatchNorm2d-258             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-259             [-1, 96, 8, 8]               0\n",
      "          Conv2d-260            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-261            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-262            [-1, 576, 8, 8]               0\n",
      "          Conv2d-263            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-264            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-265            [-1, 576, 8, 8]               0\n",
      "          Conv2d-266             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-267             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-268             [-1, 96, 8, 8]               0\n",
      "          Conv2d-269            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-270            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-271            [-1, 576, 8, 8]               0\n",
      "          Conv2d-272            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-273            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-274            [-1, 576, 8, 8]               0\n",
      "          Conv2d-275             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-276             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-277             [-1, 96, 8, 8]               0\n",
      "          Conv2d-278            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-279            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-280            [-1, 576, 8, 8]               0\n",
      "          Conv2d-281            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-282            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-283            [-1, 576, 4, 4]               0\n",
      "          Conv2d-284            [-1, 160, 4, 4]          92,160\n",
      "     BatchNorm2d-285            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-286            [-1, 160, 4, 4]               0\n",
      "          Conv2d-287            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-288            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-289            [-1, 960, 4, 4]               0\n",
      "          Conv2d-290            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-291            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-292            [-1, 960, 4, 4]               0\n",
      "          Conv2d-293            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-294            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-295            [-1, 160, 4, 4]               0\n",
      "          Conv2d-296            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-297            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-298            [-1, 960, 4, 4]               0\n",
      "          Conv2d-299            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-300            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-301            [-1, 960, 4, 4]               0\n",
      "          Conv2d-302            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-303            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-304            [-1, 160, 4, 4]               0\n",
      "          Conv2d-305            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-306            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-307            [-1, 960, 4, 4]               0\n",
      "          Conv2d-308            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-309            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-310            [-1, 960, 4, 4]               0\n",
      "          Conv2d-311            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-312            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-313            [-1, 320, 4, 4]               0\n",
      "          Conv2d-314           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-315           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-316           [-1, 1280, 4, 4]               0\n",
      "          Linear-317                  [-1, 128]         163,968\n",
      "     MobileNetV2-318                  [-1, 128]               0\n",
      "SpectrogramEncoderNet-319                  [-1, 128]               0\n",
      "        Identity-320                  [-1, 128]               0\n",
      "================================================================\n",
      "Total params: 4,775,680\n",
      "Trainable params: 4,775,680\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 99.83\n",
      "Params size (MB): 18.22\n",
      "Estimated Total Size (MB): 118.80\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(MultiSiameseContrastiveClassifierNet(), input_size=(CANDIDATE_SIZE+1, 3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    \n",
    "    def __init__(self, spectrogram_samples_files, candidate_size, batch_size, num_batches, num_sub_samples, img_height):\n",
    "        self.spectrogram_samples_files = spectrogram_samples_files   # list of filepaths\n",
    "        self.candidate_size = candidate_size   # 1 positive, n-1 negatives\n",
    "        self.batch_size = batch_size   # batch size\n",
    "        self.num_batches = num_batches   # num batches per epoch\n",
    "        self.num_sub_samples = num_sub_samples   # num sub-samples per epoch\n",
    "        self.img_height = img_height   # height of square img to be generated in the batches\n",
    "        self.sub_samples = []   # list of RGB converted spectrograms\n",
    "    \n",
    "    def generate_batches(self):\n",
    "        while True:\n",
    "            self.create_sub_samples()\n",
    "            # batches per epoch\n",
    "            for _ in range(self.num_batches):\n",
    "                # create batch\n",
    "                labels = []\n",
    "                query_and_candidate_imgs = [[] for _ in range(self.candidate_size + 1)]\n",
    "                for _ in range(self.batch_size):\n",
    "                    sample_spectrograms_indices = random.sample(range(self.num_sub_samples), self.candidate_size)   # sample candidates\n",
    "                    pos_idx = sample_spectrograms_indices[0]   # positive sample\n",
    "                    # Generate query image\n",
    "                    query_img = self.get_sliding_img_slice_from_spectrogram(self.sub_samples[pos_idx])\n",
    "                    # Generate batch images\n",
    "                    random.shuffle(sample_spectrograms_indices)\n",
    "                    candidate_imgs = [self.get_sliding_img_slice_from_spectrogram(self.sub_samples[idx]) for idx in sample_spectrograms_indices]\n",
    "                    # get class label / idx of positive sample\n",
    "                    pos_candidate_idx = sample_spectrograms_indices.index(pos_idx)   \n",
    "                    labels.append(pos_candidate_idx)\n",
    "                    # Normalize input imgs\n",
    "                    for i, img in enumerate([query_img, *candidate_imgs]):\n",
    "                        img = img / np.amax(np.absolute(img))   # normalize to range [-1, 1]\n",
    "                        query_and_candidate_imgs[i].append(img)\n",
    "                # Convert to tensor\n",
    "                labels = torch.tensor(labels)\n",
    "                input_imgs = torch.tensor(query_and_candidate_imgs)\n",
    "                yield (input_imgs, labels)\n",
    "    \n",
    "    def create_sub_samples(self):\n",
    "        self.sub_samples = []   # reset\n",
    "        files = random.sample(self.spectrogram_samples_files, self.num_sub_samples)   # sampling without replacement\n",
    "        for file in files:\n",
    "#             print(file)\n",
    "            spectrogram = np.load(file)\n",
    "            assert spectrogram.shape[0] == self.img_height, \"Input spectrogram height does not match img height\"\n",
    "            self.sub_samples.append(spectrogram)\n",
    "    \n",
    "    @classmethod\n",
    "    def get_sliding_img_slice_from_spectrogram(cls, spectrogram, depth=3, sliding_ratio=2):\n",
    "        ### Combine multiple sliding greyscale img slices into an n-depth image\n",
    "        height = spectrogram.shape[0]\n",
    "        slide_step = height//sliding_ratio\n",
    "        img_slice = np.zeros((depth,height,height))   # initialize empty img (pytorch style)\n",
    "        # Get random start idx\n",
    "        slice_start = random.randint(0, spectrogram.shape[1] - (slide_step*(depth+1)) - 1)\n",
    "        for i in range(depth):\n",
    "            img_slice[i,:,:] = spectrogram[:, slice_start:slice_start+height]   # get slice (pytorch style)\n",
    "            slice_start += slide_step   # slide\n",
    "        img_slice = img_slice.astype(\"float32\")\n",
    "        return img_slice\n",
    "    \n",
    "    @classmethod\n",
    "    def spectrogram_to_RGB(cls, spectrogram):\n",
    "        assert len(spectrogram.shape) == 2, \"Spectrogram input should be a 2D array\"\n",
    "        spectrogram_rgb = gray2rgb(spectrogram)\n",
    "        return spectrogram_rgb\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder = os.path.join(output_data_folder, \"training_dataset_full_spectrogram/vox1_dev_wav\")\n",
    "spectrogram_samples_files = [os.path.join(training_folder, file) for file in os.listdir(training_folder)]\n",
    "candidate_size = CANDIDATE_SIZE\n",
    "batch_size = 25\n",
    "num_batches = 2000 // batch_size\n",
    "# num_batches = 200 // batch_size\n",
    "num_sub_samples = 200\n",
    "# num_sub_samples = 20\n",
    "training_data_generator = DataGenerator(spectrogram_samples_files, candidate_size, batch_size, num_batches, num_sub_samples, IMG_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, num_batches, training_data_generator, log_handler):\n",
    "    since = time.time()\n",
    "\n",
    "#     best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    t1 = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        log_handler.print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        log_handler.print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            num_batch_modified = num_batches if phase == 'train' else (num_batches // 5) + 1\n",
    "            for i, data in zip(range(num_batch_modified), training_data_generator.generate_batches()):               \n",
    "                input_imgs, labels = data\n",
    "                inputs = [img.to(device) for img in input_imgs]\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):   # gradient only for train\n",
    "                    outputs = model(inputs)   \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs[0].size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / (num_batch_modified * inputs[0].size(0))\n",
    "            epoch_acc = running_corrects.double() / (num_batch_modified * inputs[0].size(0))\n",
    "\n",
    "            log_handler.print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                log_handler.save_pytorch_model(model, \"best_model_{}.pt\".format(model.__class__.__name__))\n",
    "\n",
    "        # end of epoch\n",
    "        log_handler.print(\"Time taken is {} seconds\".format(int(time.time()-t1)))\n",
    "        t1 = time.time()\n",
    "        log_handler.print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    log_handler.print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    log_handler.print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Desktop\\projects\\speaker_recognition_voxceleb1\\output_data\\models\\contrastive_encoder\\2020-03-18_02-09-45\n",
      "Description: Candidates: 3, Encoding: 128, Projection: None\n",
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 1.0478 Acc: 0.4345\n",
      "val Loss: 1.0125 Acc: 0.4682\n",
      "MODEL SAVED\n",
      "Time taken is 105 seconds\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 1.0325 Acc: 0.4505\n",
      "val Loss: 1.0229 Acc: 0.4612\n",
      "Time taken is 108 seconds\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 1.0457 Acc: 0.4470\n",
      "val Loss: 1.0336 Acc: 0.4329\n",
      "Time taken is 96 seconds\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 1.0252 Acc: 0.4585\n",
      "val Loss: 1.0205 Acc: 0.4494\n",
      "Time taken is 109 seconds\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 1.0158 Acc: 0.4810\n",
      "val Loss: 0.9932 Acc: 0.4824\n",
      "MODEL SAVED\n",
      "Time taken is 106 seconds\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 1.0002 Acc: 0.4675\n",
      "val Loss: 0.9954 Acc: 0.4871\n",
      "MODEL SAVED\n",
      "Time taken is 99 seconds\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 1.0086 Acc: 0.4750\n",
      "val Loss: 1.0012 Acc: 0.4306\n",
      "Time taken is 104 seconds\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.9833 Acc: 0.4930\n",
      "val Loss: 0.9434 Acc: 0.5365\n",
      "MODEL SAVED\n",
      "Time taken is 105 seconds\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.9801 Acc: 0.4975\n",
      "val Loss: 1.0245 Acc: 0.4635\n",
      "Time taken is 99 seconds\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.9911 Acc: 0.4860\n",
      "val Loss: 0.9749 Acc: 0.5106\n",
      "Time taken is 108 seconds\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.9955 Acc: 0.4755\n",
      "val Loss: 0.9755 Acc: 0.4941\n",
      "Time taken is 109 seconds\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 1.0025 Acc: 0.4690\n",
      "val Loss: 0.9491 Acc: 0.5647\n",
      "MODEL SAVED\n",
      "Time taken is 98 seconds\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.9666 Acc: 0.5150\n",
      "val Loss: 0.9749 Acc: 0.5294\n",
      "Time taken is 104 seconds\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.9970 Acc: 0.4685\n",
      "val Loss: 0.9638 Acc: 0.5271\n",
      "Time taken is 109 seconds\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.9725 Acc: 0.5095\n",
      "val Loss: 1.0119 Acc: 0.4659\n",
      "Time taken is 100 seconds\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.9832 Acc: 0.5065\n",
      "val Loss: 0.9683 Acc: 0.5035\n",
      "Time taken is 100 seconds\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.9977 Acc: 0.4820\n",
      "val Loss: 0.9526 Acc: 0.5106\n",
      "Time taken is 104 seconds\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.9777 Acc: 0.4900\n",
      "val Loss: 0.9776 Acc: 0.4729\n",
      "Time taken is 107 seconds\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.9725 Acc: 0.5145\n",
      "val Loss: 0.9620 Acc: 0.4941\n",
      "Time taken is 108 seconds\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.9632 Acc: 0.5150\n",
      "val Loss: 0.9935 Acc: 0.4447\n",
      "Time taken is 99 seconds\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.9775 Acc: 0.4980\n",
      "val Loss: 0.9652 Acc: 0.4965\n",
      "Time taken is 104 seconds\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.9688 Acc: 0.5005\n",
      "val Loss: 0.9704 Acc: 0.4776\n",
      "Time taken is 104 seconds\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.9781 Acc: 0.4965\n",
      "val Loss: 0.9572 Acc: 0.5035\n",
      "Time taken is 102 seconds\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3410\n",
      "val Loss: nan Acc: 0.3224\n",
      "Time taken is 109 seconds\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3255\n",
      "val Loss: nan Acc: 0.2941\n",
      "Time taken is 108 seconds\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3380\n",
      "val Loss: nan Acc: 0.3341\n",
      "Time taken is 100 seconds\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3220\n",
      "val Loss: nan Acc: 0.3294\n",
      "Time taken is 107 seconds\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3400\n",
      "val Loss: nan Acc: 0.2941\n",
      "Time taken is 105 seconds\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3630\n",
      "val Loss: nan Acc: 0.3271\n",
      "Time taken is 99 seconds\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3295\n",
      "val Loss: nan Acc: 0.3529\n",
      "Time taken is 108 seconds\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3475\n",
      "val Loss: nan Acc: 0.3576\n",
      "Time taken is 102 seconds\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3450\n",
      "val Loss: nan Acc: 0.3435\n",
      "Time taken is 105 seconds\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3375\n",
      "val Loss: nan Acc: 0.3153\n",
      "Time taken is 106 seconds\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3195\n",
      "val Loss: nan Acc: 0.3412\n",
      "Time taken is 100 seconds\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3070\n",
      "val Loss: nan Acc: 0.3341\n",
      "Time taken is 105 seconds\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3280\n",
      "val Loss: nan Acc: 0.3529\n",
      "Time taken is 100 seconds\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3180\n",
      "val Loss: nan Acc: 0.3529\n",
      "Time taken is 98 seconds\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3435\n",
      "val Loss: nan Acc: 0.3694\n",
      "Time taken is 105 seconds\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3575\n",
      "val Loss: nan Acc: 0.3153\n",
      "Time taken is 107 seconds\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3090\n",
      "val Loss: nan Acc: 0.3247\n",
      "Time taken is 105 seconds\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3650\n",
      "val Loss: nan Acc: 0.2988\n",
      "Time taken is 106 seconds\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3165\n",
      "val Loss: nan Acc: 0.3341\n",
      "Time taken is 107 seconds\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3320\n",
      "val Loss: nan Acc: 0.3294\n",
      "Time taken is 98 seconds\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3305\n",
      "val Loss: nan Acc: 0.3600\n",
      "Time taken is 106 seconds\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3375\n",
      "val Loss: nan Acc: 0.3059\n",
      "Time taken is 104 seconds\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3220\n",
      "val Loss: nan Acc: 0.3506\n",
      "Time taken is 102 seconds\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3180\n",
      "val Loss: nan Acc: 0.3341\n",
      "Time taken is 100 seconds\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3350\n",
      "val Loss: nan Acc: 0.3718\n",
      "Time taken is 103 seconds\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3300\n",
      "val Loss: nan Acc: 0.3106\n",
      "Time taken is 97 seconds\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: nan Acc: 0.3505\n",
      "val Loss: nan Acc: 0.3459\n",
      "Time taken is 101 seconds\n",
      "\n",
      "Training complete in 86m 50s\n",
      "Best val Acc: 0.564706\n"
     ]
    }
   ],
   "source": [
    "### Train\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "model_ft = MultiSiameseContrastiveClassifierNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr = 0.0001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "\n",
    "\n",
    "### Train \n",
    "\n",
    "# Logger\n",
    "model_save_folder = os.path.join(models_folder, \"contrastive_encoder\")\n",
    "log_handler = ModelSaveAndLogHandler(model_save_folder, enable_model_saving=True, enable_logging=True)   # init\n",
    "model_def_src_file_path = os.path.join(r\"D:\\Desktop\\projects\\speaker_recognition_voxceleb1\\scripts\", \"model_definitions.py\")\n",
    "log_handler.save_model_definition_file(model_def_src_file_path)   # copy model def file\n",
    "print(log_handler.folder)\n",
    "\n",
    "# Description\n",
    "log_handler.print(\"Description: Candidates: 3, Encoding: 128, Projection: None\")\n",
    "\n",
    "# Train\n",
    "train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, epochs, num_batches, training_data_generator, log_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_acc = 1 / CANDIDATE_SIZE\n",
    "random_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Overall\n",
    "* Contrastive classifier\n",
    "    * separate train and validate methods\n",
    "\n",
    "* (Done) Model saving / checkpointing\n",
    "* **Build binary classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
