{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from config import models_folder, output_data_folder\n",
    "from config import n_mels\n",
    "\n",
    "from model_definitions import SpectrogramEncoderNet, MultiSiameseContrastiveClassifierNet\n",
    "from data_generators import ContrastiveDataGenerator, BaseDataGenerator\n",
    "from project_utils import ModelSaveAndLogHandler, load_module_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = n_mels\n",
    "CANDIDATE_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mobile net\n",
    "# model = models.mobilenet_v2(pretrained=False)\n",
    "# # Dense net\n",
    "# model = models.densenet121(pretrained=False)\n",
    "# summary(model, input_size=(3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mobile net classifier\n",
    "# model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             864\n",
      "       BatchNorm2d-2           [-1, 32, 64, 64]              64\n",
      "             ReLU6-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]             288\n",
      "       BatchNorm2d-5           [-1, 32, 64, 64]              64\n",
      "             ReLU6-6           [-1, 32, 64, 64]               0\n",
      "            Conv2d-7           [-1, 16, 64, 64]             512\n",
      "       BatchNorm2d-8           [-1, 16, 64, 64]              32\n",
      "  InvertedResidual-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 96, 64, 64]           1,536\n",
      "      BatchNorm2d-11           [-1, 96, 64, 64]             192\n",
      "            ReLU6-12           [-1, 96, 64, 64]               0\n",
      "           Conv2d-13           [-1, 96, 32, 32]             864\n",
      "      BatchNorm2d-14           [-1, 96, 32, 32]             192\n",
      "            ReLU6-15           [-1, 96, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 32, 32]             288\n",
      "            ReLU6-21          [-1, 144, 32, 32]               0\n",
      "           Conv2d-22          [-1, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 32, 32]             288\n",
      "            ReLU6-24          [-1, 144, 32, 32]               0\n",
      "           Conv2d-25           [-1, 24, 32, 32]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-27           [-1, 24, 32, 32]               0\n",
      "           Conv2d-28          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 32, 32]             288\n",
      "            ReLU6-30          [-1, 144, 32, 32]               0\n",
      "           Conv2d-31          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 16, 16]             288\n",
      "            ReLU6-33          [-1, 144, 16, 16]               0\n",
      "           Conv2d-34           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-36           [-1, 32, 16, 16]               0\n",
      "           Conv2d-37          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 16, 16]             384\n",
      "            ReLU6-39          [-1, 192, 16, 16]               0\n",
      "           Conv2d-40          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 16, 16]             384\n",
      "            ReLU6-42          [-1, 192, 16, 16]               0\n",
      "           Conv2d-43           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-45           [-1, 32, 16, 16]               0\n",
      "           Conv2d-46          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 16, 16]             384\n",
      "            ReLU6-48          [-1, 192, 16, 16]               0\n",
      "           Conv2d-49          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 16, 16]             384\n",
      "            ReLU6-51          [-1, 192, 16, 16]               0\n",
      "           Conv2d-52           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 16, 16]             384\n",
      "            ReLU6-57          [-1, 192, 16, 16]               0\n",
      "           Conv2d-58            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-59            [-1, 192, 8, 8]             384\n",
      "            ReLU6-60            [-1, 192, 8, 8]               0\n",
      "           Conv2d-61             [-1, 64, 8, 8]          12,288\n",
      "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-63             [-1, 64, 8, 8]               0\n",
      "           Conv2d-64            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-65            [-1, 384, 8, 8]             768\n",
      "            ReLU6-66            [-1, 384, 8, 8]               0\n",
      "           Conv2d-67            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-68            [-1, 384, 8, 8]             768\n",
      "            ReLU6-69            [-1, 384, 8, 8]               0\n",
      "           Conv2d-70             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-71             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-72             [-1, 64, 8, 8]               0\n",
      "           Conv2d-73            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-74            [-1, 384, 8, 8]             768\n",
      "            ReLU6-75            [-1, 384, 8, 8]               0\n",
      "           Conv2d-76            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-77            [-1, 384, 8, 8]             768\n",
      "            ReLU6-78            [-1, 384, 8, 8]               0\n",
      "           Conv2d-79             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-81             [-1, 64, 8, 8]               0\n",
      "           Conv2d-82            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-83            [-1, 384, 8, 8]             768\n",
      "            ReLU6-84            [-1, 384, 8, 8]               0\n",
      "           Conv2d-85            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-86            [-1, 384, 8, 8]             768\n",
      "            ReLU6-87            [-1, 384, 8, 8]               0\n",
      "           Conv2d-88             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-90             [-1, 64, 8, 8]               0\n",
      "           Conv2d-91            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-92            [-1, 384, 8, 8]             768\n",
      "            ReLU6-93            [-1, 384, 8, 8]               0\n",
      "           Conv2d-94            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-95            [-1, 384, 8, 8]             768\n",
      "            ReLU6-96            [-1, 384, 8, 8]               0\n",
      "           Conv2d-97             [-1, 96, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 96, 8, 8]             192\n",
      " InvertedResidual-99             [-1, 96, 8, 8]               0\n",
      "          Conv2d-100            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-101            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-102            [-1, 576, 8, 8]               0\n",
      "          Conv2d-103            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-104            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-105            [-1, 576, 8, 8]               0\n",
      "          Conv2d-106             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-107             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-108             [-1, 96, 8, 8]               0\n",
      "          Conv2d-109            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-110            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-111            [-1, 576, 8, 8]               0\n",
      "          Conv2d-112            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-113            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-114            [-1, 576, 8, 8]               0\n",
      "          Conv2d-115             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-116             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-117             [-1, 96, 8, 8]               0\n",
      "          Conv2d-118            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-119            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-120            [-1, 576, 8, 8]               0\n",
      "          Conv2d-121            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-123            [-1, 576, 4, 4]               0\n",
      "          Conv2d-124            [-1, 160, 4, 4]          92,160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-125            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-126            [-1, 160, 4, 4]               0\n",
      "          Conv2d-127            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-129            [-1, 960, 4, 4]               0\n",
      "          Conv2d-130            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-132            [-1, 960, 4, 4]               0\n",
      "          Conv2d-133            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-135            [-1, 160, 4, 4]               0\n",
      "          Conv2d-136            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-138            [-1, 960, 4, 4]               0\n",
      "          Conv2d-139            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-141            [-1, 960, 4, 4]               0\n",
      "          Conv2d-142            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-144            [-1, 160, 4, 4]               0\n",
      "          Conv2d-145            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-147            [-1, 960, 4, 4]               0\n",
      "          Conv2d-148            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-150            [-1, 960, 4, 4]               0\n",
      "          Conv2d-151            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-153            [-1, 320, 4, 4]               0\n",
      "          Conv2d-154           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-156           [-1, 1280, 4, 4]               0\n",
      "          Linear-157                  [-1, 128]         163,968\n",
      "     MobileNetV2-158                  [-1, 128]               0\n",
      "================================================================\n",
      "Total params: 2,387,840\n",
      "Trainable params: 2,387,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 49.91\n",
      "Params size (MB): 9.11\n",
      "Estimated Total Size (MB): 59.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(SpectrogramEncoderNet(), input_size=(3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             864\n",
      "       BatchNorm2d-2           [-1, 32, 64, 64]              64\n",
      "             ReLU6-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]             288\n",
      "       BatchNorm2d-5           [-1, 32, 64, 64]              64\n",
      "             ReLU6-6           [-1, 32, 64, 64]               0\n",
      "            Conv2d-7           [-1, 16, 64, 64]             512\n",
      "       BatchNorm2d-8           [-1, 16, 64, 64]              32\n",
      "  InvertedResidual-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 96, 64, 64]           1,536\n",
      "      BatchNorm2d-11           [-1, 96, 64, 64]             192\n",
      "            ReLU6-12           [-1, 96, 64, 64]               0\n",
      "           Conv2d-13           [-1, 96, 32, 32]             864\n",
      "      BatchNorm2d-14           [-1, 96, 32, 32]             192\n",
      "            ReLU6-15           [-1, 96, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 32, 32]             288\n",
      "            ReLU6-21          [-1, 144, 32, 32]               0\n",
      "           Conv2d-22          [-1, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 32, 32]             288\n",
      "            ReLU6-24          [-1, 144, 32, 32]               0\n",
      "           Conv2d-25           [-1, 24, 32, 32]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-27           [-1, 24, 32, 32]               0\n",
      "           Conv2d-28          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 32, 32]             288\n",
      "            ReLU6-30          [-1, 144, 32, 32]               0\n",
      "           Conv2d-31          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 16, 16]             288\n",
      "            ReLU6-33          [-1, 144, 16, 16]               0\n",
      "           Conv2d-34           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-36           [-1, 32, 16, 16]               0\n",
      "           Conv2d-37          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 16, 16]             384\n",
      "            ReLU6-39          [-1, 192, 16, 16]               0\n",
      "           Conv2d-40          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 16, 16]             384\n",
      "            ReLU6-42          [-1, 192, 16, 16]               0\n",
      "           Conv2d-43           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-45           [-1, 32, 16, 16]               0\n",
      "           Conv2d-46          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 16, 16]             384\n",
      "            ReLU6-48          [-1, 192, 16, 16]               0\n",
      "           Conv2d-49          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 16, 16]             384\n",
      "            ReLU6-51          [-1, 192, 16, 16]               0\n",
      "           Conv2d-52           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 16, 16]             384\n",
      "            ReLU6-57          [-1, 192, 16, 16]               0\n",
      "           Conv2d-58            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-59            [-1, 192, 8, 8]             384\n",
      "            ReLU6-60            [-1, 192, 8, 8]               0\n",
      "           Conv2d-61             [-1, 64, 8, 8]          12,288\n",
      "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-63             [-1, 64, 8, 8]               0\n",
      "           Conv2d-64            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-65            [-1, 384, 8, 8]             768\n",
      "            ReLU6-66            [-1, 384, 8, 8]               0\n",
      "           Conv2d-67            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-68            [-1, 384, 8, 8]             768\n",
      "            ReLU6-69            [-1, 384, 8, 8]               0\n",
      "           Conv2d-70             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-71             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-72             [-1, 64, 8, 8]               0\n",
      "           Conv2d-73            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-74            [-1, 384, 8, 8]             768\n",
      "            ReLU6-75            [-1, 384, 8, 8]               0\n",
      "           Conv2d-76            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-77            [-1, 384, 8, 8]             768\n",
      "            ReLU6-78            [-1, 384, 8, 8]               0\n",
      "           Conv2d-79             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-81             [-1, 64, 8, 8]               0\n",
      "           Conv2d-82            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-83            [-1, 384, 8, 8]             768\n",
      "            ReLU6-84            [-1, 384, 8, 8]               0\n",
      "           Conv2d-85            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-86            [-1, 384, 8, 8]             768\n",
      "            ReLU6-87            [-1, 384, 8, 8]               0\n",
      "           Conv2d-88             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-90             [-1, 64, 8, 8]               0\n",
      "           Conv2d-91            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-92            [-1, 384, 8, 8]             768\n",
      "            ReLU6-93            [-1, 384, 8, 8]               0\n",
      "           Conv2d-94            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-95            [-1, 384, 8, 8]             768\n",
      "            ReLU6-96            [-1, 384, 8, 8]               0\n",
      "           Conv2d-97             [-1, 96, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 96, 8, 8]             192\n",
      " InvertedResidual-99             [-1, 96, 8, 8]               0\n",
      "          Conv2d-100            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-101            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-102            [-1, 576, 8, 8]               0\n",
      "          Conv2d-103            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-104            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-105            [-1, 576, 8, 8]               0\n",
      "          Conv2d-106             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-107             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-108             [-1, 96, 8, 8]               0\n",
      "          Conv2d-109            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-110            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-111            [-1, 576, 8, 8]               0\n",
      "          Conv2d-112            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-113            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-114            [-1, 576, 8, 8]               0\n",
      "          Conv2d-115             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-116             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-117             [-1, 96, 8, 8]               0\n",
      "          Conv2d-118            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-119            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-120            [-1, 576, 8, 8]               0\n",
      "          Conv2d-121            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-123            [-1, 576, 4, 4]               0\n",
      "          Conv2d-124            [-1, 160, 4, 4]          92,160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-125            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-126            [-1, 160, 4, 4]               0\n",
      "          Conv2d-127            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-129            [-1, 960, 4, 4]               0\n",
      "          Conv2d-130            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-132            [-1, 960, 4, 4]               0\n",
      "          Conv2d-133            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-135            [-1, 160, 4, 4]               0\n",
      "          Conv2d-136            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-138            [-1, 960, 4, 4]               0\n",
      "          Conv2d-139            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-141            [-1, 960, 4, 4]               0\n",
      "          Conv2d-142            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-144            [-1, 160, 4, 4]               0\n",
      "          Conv2d-145            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-147            [-1, 960, 4, 4]               0\n",
      "          Conv2d-148            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-150            [-1, 960, 4, 4]               0\n",
      "          Conv2d-151            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-153            [-1, 320, 4, 4]               0\n",
      "          Conv2d-154           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-156           [-1, 1280, 4, 4]               0\n",
      "          Linear-157                  [-1, 128]         163,968\n",
      "     MobileNetV2-158                  [-1, 128]               0\n",
      "SpectrogramEncoderNet-159                  [-1, 128]               0\n",
      "        Identity-160                  [-1, 128]               0\n",
      "          Conv2d-161           [-1, 32, 64, 64]             864\n",
      "     BatchNorm2d-162           [-1, 32, 64, 64]              64\n",
      "           ReLU6-163           [-1, 32, 64, 64]               0\n",
      "          Conv2d-164           [-1, 32, 64, 64]             288\n",
      "     BatchNorm2d-165           [-1, 32, 64, 64]              64\n",
      "           ReLU6-166           [-1, 32, 64, 64]               0\n",
      "          Conv2d-167           [-1, 16, 64, 64]             512\n",
      "     BatchNorm2d-168           [-1, 16, 64, 64]              32\n",
      "InvertedResidual-169           [-1, 16, 64, 64]               0\n",
      "          Conv2d-170           [-1, 96, 64, 64]           1,536\n",
      "     BatchNorm2d-171           [-1, 96, 64, 64]             192\n",
      "           ReLU6-172           [-1, 96, 64, 64]               0\n",
      "          Conv2d-173           [-1, 96, 32, 32]             864\n",
      "     BatchNorm2d-174           [-1, 96, 32, 32]             192\n",
      "           ReLU6-175           [-1, 96, 32, 32]               0\n",
      "          Conv2d-176           [-1, 24, 32, 32]           2,304\n",
      "     BatchNorm2d-177           [-1, 24, 32, 32]              48\n",
      "InvertedResidual-178           [-1, 24, 32, 32]               0\n",
      "          Conv2d-179          [-1, 144, 32, 32]           3,456\n",
      "     BatchNorm2d-180          [-1, 144, 32, 32]             288\n",
      "           ReLU6-181          [-1, 144, 32, 32]               0\n",
      "          Conv2d-182          [-1, 144, 32, 32]           1,296\n",
      "     BatchNorm2d-183          [-1, 144, 32, 32]             288\n",
      "           ReLU6-184          [-1, 144, 32, 32]               0\n",
      "          Conv2d-185           [-1, 24, 32, 32]           3,456\n",
      "     BatchNorm2d-186           [-1, 24, 32, 32]              48\n",
      "InvertedResidual-187           [-1, 24, 32, 32]               0\n",
      "          Conv2d-188          [-1, 144, 32, 32]           3,456\n",
      "     BatchNorm2d-189          [-1, 144, 32, 32]             288\n",
      "           ReLU6-190          [-1, 144, 32, 32]               0\n",
      "          Conv2d-191          [-1, 144, 16, 16]           1,296\n",
      "     BatchNorm2d-192          [-1, 144, 16, 16]             288\n",
      "           ReLU6-193          [-1, 144, 16, 16]               0\n",
      "          Conv2d-194           [-1, 32, 16, 16]           4,608\n",
      "     BatchNorm2d-195           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-196           [-1, 32, 16, 16]               0\n",
      "          Conv2d-197          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-198          [-1, 192, 16, 16]             384\n",
      "           ReLU6-199          [-1, 192, 16, 16]               0\n",
      "          Conv2d-200          [-1, 192, 16, 16]           1,728\n",
      "     BatchNorm2d-201          [-1, 192, 16, 16]             384\n",
      "           ReLU6-202          [-1, 192, 16, 16]               0\n",
      "          Conv2d-203           [-1, 32, 16, 16]           6,144\n",
      "     BatchNorm2d-204           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-205           [-1, 32, 16, 16]               0\n",
      "          Conv2d-206          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-207          [-1, 192, 16, 16]             384\n",
      "           ReLU6-208          [-1, 192, 16, 16]               0\n",
      "          Conv2d-209          [-1, 192, 16, 16]           1,728\n",
      "     BatchNorm2d-210          [-1, 192, 16, 16]             384\n",
      "           ReLU6-211          [-1, 192, 16, 16]               0\n",
      "          Conv2d-212           [-1, 32, 16, 16]           6,144\n",
      "     BatchNorm2d-213           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-214           [-1, 32, 16, 16]               0\n",
      "          Conv2d-215          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-216          [-1, 192, 16, 16]             384\n",
      "           ReLU6-217          [-1, 192, 16, 16]               0\n",
      "          Conv2d-218            [-1, 192, 8, 8]           1,728\n",
      "     BatchNorm2d-219            [-1, 192, 8, 8]             384\n",
      "           ReLU6-220            [-1, 192, 8, 8]               0\n",
      "          Conv2d-221             [-1, 64, 8, 8]          12,288\n",
      "     BatchNorm2d-222             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-223             [-1, 64, 8, 8]               0\n",
      "          Conv2d-224            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-225            [-1, 384, 8, 8]             768\n",
      "           ReLU6-226            [-1, 384, 8, 8]               0\n",
      "          Conv2d-227            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-228            [-1, 384, 8, 8]             768\n",
      "           ReLU6-229            [-1, 384, 8, 8]               0\n",
      "          Conv2d-230             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-231             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-232             [-1, 64, 8, 8]               0\n",
      "          Conv2d-233            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-234            [-1, 384, 8, 8]             768\n",
      "           ReLU6-235            [-1, 384, 8, 8]               0\n",
      "          Conv2d-236            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-237            [-1, 384, 8, 8]             768\n",
      "           ReLU6-238            [-1, 384, 8, 8]               0\n",
      "          Conv2d-239             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-240             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-241             [-1, 64, 8, 8]               0\n",
      "          Conv2d-242            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-243            [-1, 384, 8, 8]             768\n",
      "           ReLU6-244            [-1, 384, 8, 8]               0\n",
      "          Conv2d-245            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-246            [-1, 384, 8, 8]             768\n",
      "           ReLU6-247            [-1, 384, 8, 8]               0\n",
      "          Conv2d-248             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-249             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-250             [-1, 64, 8, 8]               0\n",
      "          Conv2d-251            [-1, 384, 8, 8]          24,576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-252            [-1, 384, 8, 8]             768\n",
      "           ReLU6-253            [-1, 384, 8, 8]               0\n",
      "          Conv2d-254            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-255            [-1, 384, 8, 8]             768\n",
      "           ReLU6-256            [-1, 384, 8, 8]               0\n",
      "          Conv2d-257             [-1, 96, 8, 8]          36,864\n",
      "     BatchNorm2d-258             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-259             [-1, 96, 8, 8]               0\n",
      "          Conv2d-260            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-261            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-262            [-1, 576, 8, 8]               0\n",
      "          Conv2d-263            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-264            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-265            [-1, 576, 8, 8]               0\n",
      "          Conv2d-266             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-267             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-268             [-1, 96, 8, 8]               0\n",
      "          Conv2d-269            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-270            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-271            [-1, 576, 8, 8]               0\n",
      "          Conv2d-272            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-273            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-274            [-1, 576, 8, 8]               0\n",
      "          Conv2d-275             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-276             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-277             [-1, 96, 8, 8]               0\n",
      "          Conv2d-278            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-279            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-280            [-1, 576, 8, 8]               0\n",
      "          Conv2d-281            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-282            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-283            [-1, 576, 4, 4]               0\n",
      "          Conv2d-284            [-1, 160, 4, 4]          92,160\n",
      "     BatchNorm2d-285            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-286            [-1, 160, 4, 4]               0\n",
      "          Conv2d-287            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-288            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-289            [-1, 960, 4, 4]               0\n",
      "          Conv2d-290            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-291            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-292            [-1, 960, 4, 4]               0\n",
      "          Conv2d-293            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-294            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-295            [-1, 160, 4, 4]               0\n",
      "          Conv2d-296            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-297            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-298            [-1, 960, 4, 4]               0\n",
      "          Conv2d-299            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-300            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-301            [-1, 960, 4, 4]               0\n",
      "          Conv2d-302            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-303            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-304            [-1, 160, 4, 4]               0\n",
      "          Conv2d-305            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-306            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-307            [-1, 960, 4, 4]               0\n",
      "          Conv2d-308            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-309            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-310            [-1, 960, 4, 4]               0\n",
      "          Conv2d-311            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-312            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-313            [-1, 320, 4, 4]               0\n",
      "          Conv2d-314           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-315           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-316           [-1, 1280, 4, 4]               0\n",
      "          Linear-317                  [-1, 128]         163,968\n",
      "     MobileNetV2-318                  [-1, 128]               0\n",
      "SpectrogramEncoderNet-319                  [-1, 128]               0\n",
      "        Identity-320                  [-1, 128]               0\n",
      "================================================================\n",
      "Total params: 4,775,680\n",
      "Trainable params: 4,775,680\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.12\n",
      "Forward/backward pass size (MB): 99.83\n",
      "Params size (MB): 18.22\n",
      "Estimated Total Size (MB): 119.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(MultiSiameseContrastiveClassifierNet(), input_size=(CANDIDATE_SIZE+1, 3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training data\n",
    "training_folder = os.path.join(output_data_folder, \"training_dataset_full_spectrogram/vox1_dev_wav\")\n",
    "spectrogram_samples_files = [os.path.join(training_folder, file) for file in os.listdir(training_folder)]\n",
    "candidate_size = CANDIDATE_SIZE\n",
    "batch_size = 15   # mobilenet_v2\n",
    "# batch_size = 6   # densenet121\n",
    "num_batches = 2000 // batch_size\n",
    "# num_batches = 60 // batch_size\n",
    "num_sub_samples = 200\n",
    "# num_sub_samples = 70\n",
    "training_data_generator = ContrastiveDataGenerator(spectrogram_samples_files, candidate_size, batch_size, num_batches, num_sub_samples, IMG_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validation data\n",
    "validation_set_file = os.path.join(output_data_folder, \"validation_sets\", \"contrastive_validation_set.pickle\")\n",
    "with open(validation_set_file, 'rb') as f:\n",
    "    validation_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intra_class_variance_reduction(contrastive_model, contrastive_sub_samples, log_handler):   \n",
    "    num_classes = 5\n",
    "    samples_per_class = 10\n",
    "    \n",
    "    # prep for training\n",
    "    criterion = nn.MSELoss(reduction='mean')\n",
    "#     criterion = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    # train\n",
    "    total_loss = 0.0\n",
    "    spectrogram_sub_samples = random.sample(contrastive_sub_samples, num_classes)  # sample classes\n",
    "    for spectrogram in spectrogram_sub_samples:   # treat one spectrogram/user as one class\n",
    "        input_imgs = [BaseDataGenerator.get_sliding_img_slice_from_spectrogram(spectrogram) for _ in range(samples_per_class)]\n",
    "        input_imgs = torch.tensor(input_imgs)\n",
    "        inputs = input_imgs.to(device)  \n",
    "        \n",
    "        encoded_outputs = contrastive_model.encoder(inputs)\n",
    "        mean = torch.mean(encoded_outputs, dim=0)   # get mean encoding vector of this class\n",
    "        mean = mean.repeat(samples_per_class, 1)   # mean vector\n",
    "        loss = criterion(encoded_outputs, mean)   # MSE against mean (variance)\n",
    "        total_loss += loss\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, training_data_generator, validation_data, log_handler):\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    # intra class variance reduction \n",
    "#     run_variance_reduction_on_epoch = [*range(1, num_epochs)]\n",
    "    run_variance_reduction_on_epoch = [*range(0, num_epochs)]   # continue training\n",
    "#     run_variance_reduction_on_epoch = [*range(1, num_epochs, 2)]   # alternate\n",
    "    variance_reduction_frequency = 2   # every n batches\n",
    "    loss_variance_scale = 0.20\n",
    "\n",
    "    t1 = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        log_handler.print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        log_handler.print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            \n",
    "            # intra class variance reduction\n",
    "            run_variance_reduction = phase == 'train' and epoch in run_variance_reduction_on_epoch\n",
    "            if run_variance_reduction: log_handler.print(\"-- variance reduction\")\n",
    "            \n",
    "            # Main training (contrastive training)\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Iterate over data.\n",
    "            batches_used = 0\n",
    "            data_generator = training_data_generator.generate_batches() if phase == 'train' else validation_data\n",
    "            for data in data_generator:\n",
    "                batches_used += 1                \n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):   # gradient only for train\n",
    "                    \n",
    "                    # intra class variance reduction\n",
    "                    loss_var = None\n",
    "                    if batches_used % variance_reduction_frequency == 0 and run_variance_reduction:\n",
    "                        loss_var = intra_class_variance_reduction(model, training_data_generator.sub_samples, log_handler)\n",
    "                        loss_var *= loss_variance_scale\n",
    "                        loss_var.backward()\n",
    "                    \n",
    "                    # Main training (contrastive training)\n",
    "                    input_imgs, labels = data\n",
    "                    inputs = [img.to(device) for img in input_imgs]\n",
    "                    labels = labels.to(device)\n",
    "                    \n",
    "                    outputs = model(inputs)      \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                if loss_var is not None: loss += loss_var   # Overall loss with variance reduction\n",
    "                running_loss += loss.item() * inputs[0].size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            epoch_loss = running_loss / (batches_used * inputs[0].size(0))\n",
    "            epoch_acc = running_corrects.double() / (batches_used * inputs[0].size(0))\n",
    "            log_handler.print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc and epoch > 0:\n",
    "                best_acc = epoch_acc\n",
    "                log_handler.save_pytorch_model(model, \"best_model_{}.pt\".format(model.__class__.__name__))\n",
    "                example = [torch.rand(1, 3, IMG_HEIGHT, IMG_HEIGHT), torch.rand(1, 3, IMG_HEIGHT, IMG_HEIGHT)]\n",
    "                log_handler.save_pytorch_model_as_torchscript(model, \"mobile_model.pt\", (example,))\n",
    "\n",
    "        # end of epoch\n",
    "        log_handler.print(\"Time taken is {} seconds\".format(int(time.time()-t1)))\n",
    "        t1 = time.time()\n",
    "        log_handler.print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    log_handler.print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    log_handler.print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from contrastive training\n",
    "def load_contrastive_encoder_model():\n",
    "    encoder_model_folder = os.path.join(models_folder, \"contrastive_encoder\", \"good_models\", \"2020-04-08_02-34-53\")\n",
    "    module_file = os.path.join(encoder_model_folder, \"model_definitions.py\")\n",
    "    module_name = \"MultiSiameseContrastiveClassifierNet\"\n",
    "    module = load_module_from_file(module_file, module_name)\n",
    "    # load model\n",
    "    model = module.MultiSiameseContrastiveClassifierNet()\n",
    "    state_dict_file = os.path.join(encoder_model_folder, \"best_model_MultiSiameseContrastiveClassifierNet.pt\")\n",
    "    model.load_state_dict(torch.load(state_dict_file, map_location=\"cpu\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Desktop\\projects\\speaker_recognition_voxceleb1\\output_data\\models\\contrastive_encoder\\2020-04-08_10-00-20\n",
      "Description: Candidates: 5, Encoding: 128, Projection: None\n",
      "Base Model: mobileNetV2\n",
      "With Intra Class Variance Reduction\n",
      "Continued from 2020-04-08_02-34-53\n",
      "Epoch 0/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1767 Acc: 0.5714\n",
      "val Loss: 1.1705 Acc: 0.5754\n",
      "Time taken is 252 seconds\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1712 Acc: 0.5855\n",
      "val Loss: 1.1573 Acc: 0.5985\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 236 seconds\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1814 Acc: 0.5559\n",
      "val Loss: 1.1625 Acc: 0.6105\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 219 seconds\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1807 Acc: 0.5779\n",
      "val Loss: 1.1798 Acc: 0.5865\n",
      "Time taken is 226 seconds\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1636 Acc: 0.5739\n",
      "val Loss: 1.1675 Acc: 0.5995\n",
      "Time taken is 252 seconds\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1759 Acc: 0.5684\n",
      "val Loss: 1.1605 Acc: 0.5925\n",
      "Time taken is 222 seconds\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1685 Acc: 0.5860\n",
      "val Loss: 1.1626 Acc: 0.6040\n",
      "Time taken is 224 seconds\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1832 Acc: 0.5789\n",
      "val Loss: 1.1760 Acc: 0.6251\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 259 seconds\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1721 Acc: 0.5689\n",
      "val Loss: 1.1633 Acc: 0.6140\n",
      "Time taken is 226 seconds\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1484 Acc: 0.6070\n",
      "val Loss: 1.1536 Acc: 0.6180\n",
      "Time taken is 227 seconds\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1702 Acc: 0.5895\n",
      "val Loss: 1.1486 Acc: 0.6371\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 258 seconds\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1588 Acc: 0.5945\n",
      "val Loss: 1.1603 Acc: 0.6130\n",
      "Time taken is 239 seconds\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1757 Acc: 0.5674\n",
      "val Loss: 1.1753 Acc: 0.6120\n",
      "Time taken is 218 seconds\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1533 Acc: 0.6095\n",
      "val Loss: 1.1942 Acc: 0.6135\n",
      "Time taken is 227 seconds\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1758 Acc: 0.5744\n",
      "val Loss: 1.1601 Acc: 0.6050\n",
      "Time taken is 253 seconds\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1765 Acc: 0.5749\n",
      "val Loss: 1.1513 Acc: 0.6105\n",
      "Time taken is 225 seconds\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1642 Acc: 0.5900\n",
      "val Loss: 1.1619 Acc: 0.6160\n",
      "Time taken is 223 seconds\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1652 Acc: 0.5985\n",
      "val Loss: 1.1446 Acc: 0.6306\n",
      "Time taken is 245 seconds\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1652 Acc: 0.6040\n",
      "val Loss: 1.1573 Acc: 0.6251\n",
      "Time taken is 222 seconds\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1688 Acc: 0.5875\n",
      "val Loss: 1.1592 Acc: 0.6135\n",
      "Time taken is 257 seconds\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1640 Acc: 0.5865\n",
      "val Loss: 1.1547 Acc: 0.5980\n",
      "Time taken is 227 seconds\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1753 Acc: 0.5940\n",
      "val Loss: 1.1449 Acc: 0.6311\n",
      "Time taken is 223 seconds\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1627 Acc: 0.6180\n",
      "val Loss: 1.1484 Acc: 0.6231\n",
      "Time taken is 262 seconds\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1521 Acc: 0.6110\n",
      "val Loss: 1.1423 Acc: 0.6321\n",
      "Time taken is 229 seconds\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1637 Acc: 0.5970\n",
      "val Loss: 1.1500 Acc: 0.6301\n",
      "Time taken is 230 seconds\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1566 Acc: 0.5860\n",
      "val Loss: 1.1506 Acc: 0.6105\n",
      "Time taken is 258 seconds\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1454 Acc: 0.6211\n",
      "val Loss: 1.1487 Acc: 0.6411\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 233 seconds\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1567 Acc: 0.6105\n",
      "val Loss: 1.1395 Acc: 0.6331\n",
      "Time taken is 212 seconds\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1523 Acc: 0.6246\n",
      "val Loss: 1.1451 Acc: 0.6241\n",
      "Time taken is 245 seconds\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.1532 Acc: 0.6321\n",
      "val Loss: 1.1591 Acc: 0.6311\n",
      "Time taken is 253 seconds\n",
      "\n",
      "Training complete in 118m 20s\n",
      "Best val Acc: 0.641103\n"
     ]
    }
   ],
   "source": [
    "### Train\n",
    "\n",
    "# epochs = 70\n",
    "# epochs = 50\n",
    "epochs = 30\n",
    "\n",
    "# model_ft = MultiSiameseContrastiveClassifierNet().to(device)\n",
    "model_ft = load_contrastive_encoder_model().to(device)   # continue training\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr = 0.0001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# learning_rate_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "learning_rate_scheduler = lr_scheduler.CyclicLR(optimizer_ft, base_lr=0.0001, max_lr=0.001, cycle_momentum=False)   # 0.001 seems better\n",
    "\n",
    "\n",
    "### Train \n",
    "\n",
    "# Logger\n",
    "model_save_folder = os.path.join(models_folder, \"contrastive_encoder\")\n",
    "log_handler = ModelSaveAndLogHandler(model_save_folder, enable_model_saving=True, enable_logging=True)   # init\n",
    "model_def_src_file_path = os.path.join(r\"D:\\Desktop\\projects\\speaker_recognition_voxceleb1\\scripts\", \"model_definitions.py\")\n",
    "log_handler.save_model_definition_file(model_def_src_file_path)   # copy model def file\n",
    "print(log_handler.folder)\n",
    "\n",
    "# Description\n",
    "log_handler.print(\"Description: Candidates: 5, Encoding: 128, Projection: None\")\n",
    "log_handler.print(\"Base Model: mobileNetV2\")\n",
    "# log_handler.print(\"Base Model: densenet121\")\n",
    "log_handler.print(\"With Intra Class Variance Reduction\")\n",
    "log_handler.print(\"Continued from 2020-04-08_02-34-53\")\n",
    "\n",
    "# Train\n",
    "# train_model(model_ft, criterion, optimizer_ft, learning_rate_scheduler, epochs, num_batches, training_data_generator, log_handler)\n",
    "train_model(model_ft, criterion, optimizer_ft, learning_rate_scheduler, epochs, training_data_generator, validation_data, log_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_acc = 1 / CANDIDATE_SIZE\n",
    "random_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Overall\n",
    "* Contrastive classifier\n",
    "    * separate train and validate methods\n",
    "\n",
    "* (Done) Model saving / checkpointing\n",
    "* **Build binary classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
