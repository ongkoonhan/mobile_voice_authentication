{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from config import models_folder, output_data_folder\n",
    "from config import n_mels\n",
    "\n",
    "from model_definitions import SpectrogramEncoderNet, MultiSiameseContrastiveClassifierNet\n",
    "from data_generators import ContrastiveDataGenerator\n",
    "from project_utils import ModelSaveAndLogHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = n_mels\n",
    "CANDIDATE_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mobile net\n",
    "# model = models.mobilenet_v2(pretrained=False)\n",
    "# # Dense net\n",
    "# model = models.densenet121(pretrained=False)\n",
    "# summary(model, input_size=(3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mobile net classifier\n",
    "# model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "              ReLU-3           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
      "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
      "              ReLU-6           [-1, 64, 32, 32]               0\n",
      "            Conv2d-7          [-1, 128, 32, 32]           8,192\n",
      "       BatchNorm2d-8          [-1, 128, 32, 32]             256\n",
      "              ReLU-9          [-1, 128, 32, 32]               0\n",
      "           Conv2d-10           [-1, 32, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 96, 32, 32]             192\n",
      "             ReLU-12           [-1, 96, 32, 32]               0\n",
      "           Conv2d-13          [-1, 128, 32, 32]          12,288\n",
      "      BatchNorm2d-14          [-1, 128, 32, 32]             256\n",
      "             ReLU-15          [-1, 128, 32, 32]               0\n",
      "           Conv2d-16           [-1, 32, 32, 32]          36,864\n",
      "      BatchNorm2d-17          [-1, 128, 32, 32]             256\n",
      "             ReLU-18          [-1, 128, 32, 32]               0\n",
      "           Conv2d-19          [-1, 128, 32, 32]          16,384\n",
      "      BatchNorm2d-20          [-1, 128, 32, 32]             256\n",
      "             ReLU-21          [-1, 128, 32, 32]               0\n",
      "           Conv2d-22           [-1, 32, 32, 32]          36,864\n",
      "      BatchNorm2d-23          [-1, 160, 32, 32]             320\n",
      "             ReLU-24          [-1, 160, 32, 32]               0\n",
      "           Conv2d-25          [-1, 128, 32, 32]          20,480\n",
      "      BatchNorm2d-26          [-1, 128, 32, 32]             256\n",
      "             ReLU-27          [-1, 128, 32, 32]               0\n",
      "           Conv2d-28           [-1, 32, 32, 32]          36,864\n",
      "      BatchNorm2d-29          [-1, 192, 32, 32]             384\n",
      "             ReLU-30          [-1, 192, 32, 32]               0\n",
      "           Conv2d-31          [-1, 128, 32, 32]          24,576\n",
      "      BatchNorm2d-32          [-1, 128, 32, 32]             256\n",
      "             ReLU-33          [-1, 128, 32, 32]               0\n",
      "           Conv2d-34           [-1, 32, 32, 32]          36,864\n",
      "      BatchNorm2d-35          [-1, 224, 32, 32]             448\n",
      "             ReLU-36          [-1, 224, 32, 32]               0\n",
      "           Conv2d-37          [-1, 128, 32, 32]          28,672\n",
      "      BatchNorm2d-38          [-1, 128, 32, 32]             256\n",
      "             ReLU-39          [-1, 128, 32, 32]               0\n",
      "           Conv2d-40           [-1, 32, 32, 32]          36,864\n",
      "      _DenseBlock-41          [-1, 256, 32, 32]               0\n",
      "      BatchNorm2d-42          [-1, 256, 32, 32]             512\n",
      "             ReLU-43          [-1, 256, 32, 32]               0\n",
      "           Conv2d-44          [-1, 128, 32, 32]          32,768\n",
      "        AvgPool2d-45          [-1, 128, 16, 16]               0\n",
      "      BatchNorm2d-46          [-1, 128, 16, 16]             256\n",
      "             ReLU-47          [-1, 128, 16, 16]               0\n",
      "           Conv2d-48          [-1, 128, 16, 16]          16,384\n",
      "      BatchNorm2d-49          [-1, 128, 16, 16]             256\n",
      "             ReLU-50          [-1, 128, 16, 16]               0\n",
      "           Conv2d-51           [-1, 32, 16, 16]          36,864\n",
      "      BatchNorm2d-52          [-1, 160, 16, 16]             320\n",
      "             ReLU-53          [-1, 160, 16, 16]               0\n",
      "           Conv2d-54          [-1, 128, 16, 16]          20,480\n",
      "      BatchNorm2d-55          [-1, 128, 16, 16]             256\n",
      "             ReLU-56          [-1, 128, 16, 16]               0\n",
      "           Conv2d-57           [-1, 32, 16, 16]          36,864\n",
      "      BatchNorm2d-58          [-1, 192, 16, 16]             384\n",
      "             ReLU-59          [-1, 192, 16, 16]               0\n",
      "           Conv2d-60          [-1, 128, 16, 16]          24,576\n",
      "      BatchNorm2d-61          [-1, 128, 16, 16]             256\n",
      "             ReLU-62          [-1, 128, 16, 16]               0\n",
      "           Conv2d-63           [-1, 32, 16, 16]          36,864\n",
      "      BatchNorm2d-64          [-1, 224, 16, 16]             448\n",
      "             ReLU-65          [-1, 224, 16, 16]               0\n",
      "           Conv2d-66          [-1, 128, 16, 16]          28,672\n",
      "      BatchNorm2d-67          [-1, 128, 16, 16]             256\n",
      "             ReLU-68          [-1, 128, 16, 16]               0\n",
      "           Conv2d-69           [-1, 32, 16, 16]          36,864\n",
      "      BatchNorm2d-70          [-1, 256, 16, 16]             512\n",
      "             ReLU-71          [-1, 256, 16, 16]               0\n",
      "           Conv2d-72          [-1, 128, 16, 16]          32,768\n",
      "      BatchNorm2d-73          [-1, 128, 16, 16]             256\n",
      "             ReLU-74          [-1, 128, 16, 16]               0\n",
      "           Conv2d-75           [-1, 32, 16, 16]          36,864\n",
      "      BatchNorm2d-76          [-1, 288, 16, 16]             576\n",
      "             ReLU-77          [-1, 288, 16, 16]               0\n",
      "           Conv2d-78          [-1, 128, 16, 16]          36,864\n",
      "      BatchNorm2d-79          [-1, 128, 16, 16]             256\n",
      "             ReLU-80          [-1, 128, 16, 16]               0\n",
      "           Conv2d-81           [-1, 32, 16, 16]          36,864\n",
      "      BatchNorm2d-82          [-1, 320, 16, 16]             640\n",
      "             ReLU-83          [-1, 320, 16, 16]               0\n",
      "           Conv2d-84          [-1, 128, 16, 16]          40,960\n",
      "      BatchNorm2d-85          [-1, 128, 16, 16]             256\n",
      "             ReLU-86          [-1, 128, 16, 16]               0\n",
      "           Conv2d-87           [-1, 32, 16, 16]          36,864\n",
      "      BatchNorm2d-88          [-1, 352, 16, 16]             704\n",
      "             ReLU-89          [-1, 352, 16, 16]               0\n",
      "           Conv2d-90          [-1, 128, 16, 16]          45,056\n",
      "      BatchNorm2d-91          [-1, 128, 16, 16]             256\n",
      "             ReLU-92          [-1, 128, 16, 16]               0\n",
      "           Conv2d-93           [-1, 32, 16, 16]          36,864\n",
      "      BatchNorm2d-94          [-1, 384, 16, 16]             768\n",
      "             ReLU-95          [-1, 384, 16, 16]               0\n",
      "           Conv2d-96          [-1, 128, 16, 16]          49,152\n",
      "      BatchNorm2d-97          [-1, 128, 16, 16]             256\n",
      "             ReLU-98          [-1, 128, 16, 16]               0\n",
      "           Conv2d-99           [-1, 32, 16, 16]          36,864\n",
      "     BatchNorm2d-100          [-1, 416, 16, 16]             832\n",
      "            ReLU-101          [-1, 416, 16, 16]               0\n",
      "          Conv2d-102          [-1, 128, 16, 16]          53,248\n",
      "     BatchNorm2d-103          [-1, 128, 16, 16]             256\n",
      "            ReLU-104          [-1, 128, 16, 16]               0\n",
      "          Conv2d-105           [-1, 32, 16, 16]          36,864\n",
      "     BatchNorm2d-106          [-1, 448, 16, 16]             896\n",
      "            ReLU-107          [-1, 448, 16, 16]               0\n",
      "          Conv2d-108          [-1, 128, 16, 16]          57,344\n",
      "     BatchNorm2d-109          [-1, 128, 16, 16]             256\n",
      "            ReLU-110          [-1, 128, 16, 16]               0\n",
      "          Conv2d-111           [-1, 32, 16, 16]          36,864\n",
      "     BatchNorm2d-112          [-1, 480, 16, 16]             960\n",
      "            ReLU-113          [-1, 480, 16, 16]               0\n",
      "          Conv2d-114          [-1, 128, 16, 16]          61,440\n",
      "     BatchNorm2d-115          [-1, 128, 16, 16]             256\n",
      "            ReLU-116          [-1, 128, 16, 16]               0\n",
      "          Conv2d-117           [-1, 32, 16, 16]          36,864\n",
      "     _DenseBlock-118          [-1, 512, 16, 16]               0\n",
      "     BatchNorm2d-119          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-120          [-1, 512, 16, 16]               0\n",
      "          Conv2d-121          [-1, 256, 16, 16]         131,072\n",
      "       AvgPool2d-122            [-1, 256, 8, 8]               0\n",
      "     BatchNorm2d-123            [-1, 256, 8, 8]             512\n",
      "            ReLU-124            [-1, 256, 8, 8]               0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Conv2d-125            [-1, 128, 8, 8]          32,768\n",
      "     BatchNorm2d-126            [-1, 128, 8, 8]             256\n",
      "            ReLU-127            [-1, 128, 8, 8]               0\n",
      "          Conv2d-128             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-129            [-1, 288, 8, 8]             576\n",
      "            ReLU-130            [-1, 288, 8, 8]               0\n",
      "          Conv2d-131            [-1, 128, 8, 8]          36,864\n",
      "     BatchNorm2d-132            [-1, 128, 8, 8]             256\n",
      "            ReLU-133            [-1, 128, 8, 8]               0\n",
      "          Conv2d-134             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-135            [-1, 320, 8, 8]             640\n",
      "            ReLU-136            [-1, 320, 8, 8]               0\n",
      "          Conv2d-137            [-1, 128, 8, 8]          40,960\n",
      "     BatchNorm2d-138            [-1, 128, 8, 8]             256\n",
      "            ReLU-139            [-1, 128, 8, 8]               0\n",
      "          Conv2d-140             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-141            [-1, 352, 8, 8]             704\n",
      "            ReLU-142            [-1, 352, 8, 8]               0\n",
      "          Conv2d-143            [-1, 128, 8, 8]          45,056\n",
      "     BatchNorm2d-144            [-1, 128, 8, 8]             256\n",
      "            ReLU-145            [-1, 128, 8, 8]               0\n",
      "          Conv2d-146             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-147            [-1, 384, 8, 8]             768\n",
      "            ReLU-148            [-1, 384, 8, 8]               0\n",
      "          Conv2d-149            [-1, 128, 8, 8]          49,152\n",
      "     BatchNorm2d-150            [-1, 128, 8, 8]             256\n",
      "            ReLU-151            [-1, 128, 8, 8]               0\n",
      "          Conv2d-152             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-153            [-1, 416, 8, 8]             832\n",
      "            ReLU-154            [-1, 416, 8, 8]               0\n",
      "          Conv2d-155            [-1, 128, 8, 8]          53,248\n",
      "     BatchNorm2d-156            [-1, 128, 8, 8]             256\n",
      "            ReLU-157            [-1, 128, 8, 8]               0\n",
      "          Conv2d-158             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-159            [-1, 448, 8, 8]             896\n",
      "            ReLU-160            [-1, 448, 8, 8]               0\n",
      "          Conv2d-161            [-1, 128, 8, 8]          57,344\n",
      "     BatchNorm2d-162            [-1, 128, 8, 8]             256\n",
      "            ReLU-163            [-1, 128, 8, 8]               0\n",
      "          Conv2d-164             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-165            [-1, 480, 8, 8]             960\n",
      "            ReLU-166            [-1, 480, 8, 8]               0\n",
      "          Conv2d-167            [-1, 128, 8, 8]          61,440\n",
      "     BatchNorm2d-168            [-1, 128, 8, 8]             256\n",
      "            ReLU-169            [-1, 128, 8, 8]               0\n",
      "          Conv2d-170             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-171            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-172            [-1, 512, 8, 8]               0\n",
      "          Conv2d-173            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-174            [-1, 128, 8, 8]             256\n",
      "            ReLU-175            [-1, 128, 8, 8]               0\n",
      "          Conv2d-176             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-177            [-1, 544, 8, 8]           1,088\n",
      "            ReLU-178            [-1, 544, 8, 8]               0\n",
      "          Conv2d-179            [-1, 128, 8, 8]          69,632\n",
      "     BatchNorm2d-180            [-1, 128, 8, 8]             256\n",
      "            ReLU-181            [-1, 128, 8, 8]               0\n",
      "          Conv2d-182             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-183            [-1, 576, 8, 8]           1,152\n",
      "            ReLU-184            [-1, 576, 8, 8]               0\n",
      "          Conv2d-185            [-1, 128, 8, 8]          73,728\n",
      "     BatchNorm2d-186            [-1, 128, 8, 8]             256\n",
      "            ReLU-187            [-1, 128, 8, 8]               0\n",
      "          Conv2d-188             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-189            [-1, 608, 8, 8]           1,216\n",
      "            ReLU-190            [-1, 608, 8, 8]               0\n",
      "          Conv2d-191            [-1, 128, 8, 8]          77,824\n",
      "     BatchNorm2d-192            [-1, 128, 8, 8]             256\n",
      "            ReLU-193            [-1, 128, 8, 8]               0\n",
      "          Conv2d-194             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-195            [-1, 640, 8, 8]           1,280\n",
      "            ReLU-196            [-1, 640, 8, 8]               0\n",
      "          Conv2d-197            [-1, 128, 8, 8]          81,920\n",
      "     BatchNorm2d-198            [-1, 128, 8, 8]             256\n",
      "            ReLU-199            [-1, 128, 8, 8]               0\n",
      "          Conv2d-200             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-201            [-1, 672, 8, 8]           1,344\n",
      "            ReLU-202            [-1, 672, 8, 8]               0\n",
      "          Conv2d-203            [-1, 128, 8, 8]          86,016\n",
      "     BatchNorm2d-204            [-1, 128, 8, 8]             256\n",
      "            ReLU-205            [-1, 128, 8, 8]               0\n",
      "          Conv2d-206             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-207            [-1, 704, 8, 8]           1,408\n",
      "            ReLU-208            [-1, 704, 8, 8]               0\n",
      "          Conv2d-209            [-1, 128, 8, 8]          90,112\n",
      "     BatchNorm2d-210            [-1, 128, 8, 8]             256\n",
      "            ReLU-211            [-1, 128, 8, 8]               0\n",
      "          Conv2d-212             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-213            [-1, 736, 8, 8]           1,472\n",
      "            ReLU-214            [-1, 736, 8, 8]               0\n",
      "          Conv2d-215            [-1, 128, 8, 8]          94,208\n",
      "     BatchNorm2d-216            [-1, 128, 8, 8]             256\n",
      "            ReLU-217            [-1, 128, 8, 8]               0\n",
      "          Conv2d-218             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-219            [-1, 768, 8, 8]           1,536\n",
      "            ReLU-220            [-1, 768, 8, 8]               0\n",
      "          Conv2d-221            [-1, 128, 8, 8]          98,304\n",
      "     BatchNorm2d-222            [-1, 128, 8, 8]             256\n",
      "            ReLU-223            [-1, 128, 8, 8]               0\n",
      "          Conv2d-224             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-225            [-1, 800, 8, 8]           1,600\n",
      "            ReLU-226            [-1, 800, 8, 8]               0\n",
      "          Conv2d-227            [-1, 128, 8, 8]         102,400\n",
      "     BatchNorm2d-228            [-1, 128, 8, 8]             256\n",
      "            ReLU-229            [-1, 128, 8, 8]               0\n",
      "          Conv2d-230             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-231            [-1, 832, 8, 8]           1,664\n",
      "            ReLU-232            [-1, 832, 8, 8]               0\n",
      "          Conv2d-233            [-1, 128, 8, 8]         106,496\n",
      "     BatchNorm2d-234            [-1, 128, 8, 8]             256\n",
      "            ReLU-235            [-1, 128, 8, 8]               0\n",
      "          Conv2d-236             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-237            [-1, 864, 8, 8]           1,728\n",
      "            ReLU-238            [-1, 864, 8, 8]               0\n",
      "          Conv2d-239            [-1, 128, 8, 8]         110,592\n",
      "     BatchNorm2d-240            [-1, 128, 8, 8]             256\n",
      "            ReLU-241            [-1, 128, 8, 8]               0\n",
      "          Conv2d-242             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-243            [-1, 896, 8, 8]           1,792\n",
      "            ReLU-244            [-1, 896, 8, 8]               0\n",
      "          Conv2d-245            [-1, 128, 8, 8]         114,688\n",
      "     BatchNorm2d-246            [-1, 128, 8, 8]             256\n",
      "            ReLU-247            [-1, 128, 8, 8]               0\n",
      "          Conv2d-248             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-249            [-1, 928, 8, 8]           1,856\n",
      "            ReLU-250            [-1, 928, 8, 8]               0\n",
      "          Conv2d-251            [-1, 128, 8, 8]         118,784\n",
      "     BatchNorm2d-252            [-1, 128, 8, 8]             256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ReLU-253            [-1, 128, 8, 8]               0\n",
      "          Conv2d-254             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-255            [-1, 960, 8, 8]           1,920\n",
      "            ReLU-256            [-1, 960, 8, 8]               0\n",
      "          Conv2d-257            [-1, 128, 8, 8]         122,880\n",
      "     BatchNorm2d-258            [-1, 128, 8, 8]             256\n",
      "            ReLU-259            [-1, 128, 8, 8]               0\n",
      "          Conv2d-260             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-261            [-1, 992, 8, 8]           1,984\n",
      "            ReLU-262            [-1, 992, 8, 8]               0\n",
      "          Conv2d-263            [-1, 128, 8, 8]         126,976\n",
      "     BatchNorm2d-264            [-1, 128, 8, 8]             256\n",
      "            ReLU-265            [-1, 128, 8, 8]               0\n",
      "          Conv2d-266             [-1, 32, 8, 8]          36,864\n",
      "     _DenseBlock-267           [-1, 1024, 8, 8]               0\n",
      "     BatchNorm2d-268           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-269           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-270            [-1, 512, 8, 8]         524,288\n",
      "       AvgPool2d-271            [-1, 512, 4, 4]               0\n",
      "     BatchNorm2d-272            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-273            [-1, 512, 4, 4]               0\n",
      "          Conv2d-274            [-1, 128, 4, 4]          65,536\n",
      "     BatchNorm2d-275            [-1, 128, 4, 4]             256\n",
      "            ReLU-276            [-1, 128, 4, 4]               0\n",
      "          Conv2d-277             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-278            [-1, 544, 4, 4]           1,088\n",
      "            ReLU-279            [-1, 544, 4, 4]               0\n",
      "          Conv2d-280            [-1, 128, 4, 4]          69,632\n",
      "     BatchNorm2d-281            [-1, 128, 4, 4]             256\n",
      "            ReLU-282            [-1, 128, 4, 4]               0\n",
      "          Conv2d-283             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-284            [-1, 576, 4, 4]           1,152\n",
      "            ReLU-285            [-1, 576, 4, 4]               0\n",
      "          Conv2d-286            [-1, 128, 4, 4]          73,728\n",
      "     BatchNorm2d-287            [-1, 128, 4, 4]             256\n",
      "            ReLU-288            [-1, 128, 4, 4]               0\n",
      "          Conv2d-289             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-290            [-1, 608, 4, 4]           1,216\n",
      "            ReLU-291            [-1, 608, 4, 4]               0\n",
      "          Conv2d-292            [-1, 128, 4, 4]          77,824\n",
      "     BatchNorm2d-293            [-1, 128, 4, 4]             256\n",
      "            ReLU-294            [-1, 128, 4, 4]               0\n",
      "          Conv2d-295             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-296            [-1, 640, 4, 4]           1,280\n",
      "            ReLU-297            [-1, 640, 4, 4]               0\n",
      "          Conv2d-298            [-1, 128, 4, 4]          81,920\n",
      "     BatchNorm2d-299            [-1, 128, 4, 4]             256\n",
      "            ReLU-300            [-1, 128, 4, 4]               0\n",
      "          Conv2d-301             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-302            [-1, 672, 4, 4]           1,344\n",
      "            ReLU-303            [-1, 672, 4, 4]               0\n",
      "          Conv2d-304            [-1, 128, 4, 4]          86,016\n",
      "     BatchNorm2d-305            [-1, 128, 4, 4]             256\n",
      "            ReLU-306            [-1, 128, 4, 4]               0\n",
      "          Conv2d-307             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-308            [-1, 704, 4, 4]           1,408\n",
      "            ReLU-309            [-1, 704, 4, 4]               0\n",
      "          Conv2d-310            [-1, 128, 4, 4]          90,112\n",
      "     BatchNorm2d-311            [-1, 128, 4, 4]             256\n",
      "            ReLU-312            [-1, 128, 4, 4]               0\n",
      "          Conv2d-313             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-314            [-1, 736, 4, 4]           1,472\n",
      "            ReLU-315            [-1, 736, 4, 4]               0\n",
      "          Conv2d-316            [-1, 128, 4, 4]          94,208\n",
      "     BatchNorm2d-317            [-1, 128, 4, 4]             256\n",
      "            ReLU-318            [-1, 128, 4, 4]               0\n",
      "          Conv2d-319             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-320            [-1, 768, 4, 4]           1,536\n",
      "            ReLU-321            [-1, 768, 4, 4]               0\n",
      "          Conv2d-322            [-1, 128, 4, 4]          98,304\n",
      "     BatchNorm2d-323            [-1, 128, 4, 4]             256\n",
      "            ReLU-324            [-1, 128, 4, 4]               0\n",
      "          Conv2d-325             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-326            [-1, 800, 4, 4]           1,600\n",
      "            ReLU-327            [-1, 800, 4, 4]               0\n",
      "          Conv2d-328            [-1, 128, 4, 4]         102,400\n",
      "     BatchNorm2d-329            [-1, 128, 4, 4]             256\n",
      "            ReLU-330            [-1, 128, 4, 4]               0\n",
      "          Conv2d-331             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-332            [-1, 832, 4, 4]           1,664\n",
      "            ReLU-333            [-1, 832, 4, 4]               0\n",
      "          Conv2d-334            [-1, 128, 4, 4]         106,496\n",
      "     BatchNorm2d-335            [-1, 128, 4, 4]             256\n",
      "            ReLU-336            [-1, 128, 4, 4]               0\n",
      "          Conv2d-337             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-338            [-1, 864, 4, 4]           1,728\n",
      "            ReLU-339            [-1, 864, 4, 4]               0\n",
      "          Conv2d-340            [-1, 128, 4, 4]         110,592\n",
      "     BatchNorm2d-341            [-1, 128, 4, 4]             256\n",
      "            ReLU-342            [-1, 128, 4, 4]               0\n",
      "          Conv2d-343             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-344            [-1, 896, 4, 4]           1,792\n",
      "            ReLU-345            [-1, 896, 4, 4]               0\n",
      "          Conv2d-346            [-1, 128, 4, 4]         114,688\n",
      "     BatchNorm2d-347            [-1, 128, 4, 4]             256\n",
      "            ReLU-348            [-1, 128, 4, 4]               0\n",
      "          Conv2d-349             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-350            [-1, 928, 4, 4]           1,856\n",
      "            ReLU-351            [-1, 928, 4, 4]               0\n",
      "          Conv2d-352            [-1, 128, 4, 4]         118,784\n",
      "     BatchNorm2d-353            [-1, 128, 4, 4]             256\n",
      "            ReLU-354            [-1, 128, 4, 4]               0\n",
      "          Conv2d-355             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-356            [-1, 960, 4, 4]           1,920\n",
      "            ReLU-357            [-1, 960, 4, 4]               0\n",
      "          Conv2d-358            [-1, 128, 4, 4]         122,880\n",
      "     BatchNorm2d-359            [-1, 128, 4, 4]             256\n",
      "            ReLU-360            [-1, 128, 4, 4]               0\n",
      "          Conv2d-361             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-362            [-1, 992, 4, 4]           1,984\n",
      "            ReLU-363            [-1, 992, 4, 4]               0\n",
      "          Conv2d-364            [-1, 128, 4, 4]         126,976\n",
      "     BatchNorm2d-365            [-1, 128, 4, 4]             256\n",
      "            ReLU-366            [-1, 128, 4, 4]               0\n",
      "          Conv2d-367             [-1, 32, 4, 4]          36,864\n",
      "     _DenseBlock-368           [-1, 1024, 4, 4]               0\n",
      "     BatchNorm2d-369           [-1, 1024, 4, 4]           2,048\n",
      "          Linear-370                  [-1, 128]         131,200\n",
      "        DenseNet-371                  [-1, 128]               0\n",
      "================================================================\n",
      "Total params: 7,085,056\n",
      "Trainable params: 7,085,056\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 99.69\n",
      "Params size (MB): 27.03\n",
      "Estimated Total Size (MB): 126.90\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(SpectrogramEncoderNet(), input_size=(3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "              ReLU-3           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
      "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
      "              ReLU-6           [-1, 64, 32, 32]               0\n",
      "            Conv2d-7          [-1, 128, 32, 32]           8,192\n",
      "       BatchNorm2d-8          [-1, 128, 32, 32]             256\n",
      "              ReLU-9          [-1, 128, 32, 32]               0\n",
      "           Conv2d-10           [-1, 32, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 96, 32, 32]             192\n",
      "             ReLU-12           [-1, 96, 32, 32]               0\n",
      "           Conv2d-13          [-1, 128, 32, 32]          12,288\n",
      "      BatchNorm2d-14          [-1, 128, 32, 32]             256\n",
      "             ReLU-15          [-1, 128, 32, 32]               0\n",
      "           Conv2d-16           [-1, 32, 32, 32]          36,864\n",
      "      BatchNorm2d-17          [-1, 128, 32, 32]             256\n",
      "             ReLU-18          [-1, 128, 32, 32]               0\n",
      "           Conv2d-19          [-1, 128, 32, 32]          16,384\n",
      "      BatchNorm2d-20          [-1, 128, 32, 32]             256\n",
      "             ReLU-21          [-1, 128, 32, 32]               0\n",
      "           Conv2d-22           [-1, 32, 32, 32]          36,864\n",
      "      BatchNorm2d-23          [-1, 160, 32, 32]             320\n",
      "             ReLU-24          [-1, 160, 32, 32]               0\n",
      "           Conv2d-25          [-1, 128, 32, 32]          20,480\n",
      "      BatchNorm2d-26          [-1, 128, 32, 32]             256\n",
      "             ReLU-27          [-1, 128, 32, 32]               0\n",
      "           Conv2d-28           [-1, 32, 32, 32]          36,864\n",
      "      BatchNorm2d-29          [-1, 192, 32, 32]             384\n",
      "             ReLU-30          [-1, 192, 32, 32]               0\n",
      "           Conv2d-31          [-1, 128, 32, 32]          24,576\n",
      "      BatchNorm2d-32          [-1, 128, 32, 32]             256\n",
      "             ReLU-33          [-1, 128, 32, 32]               0\n",
      "           Conv2d-34           [-1, 32, 32, 32]          36,864\n",
      "      BatchNorm2d-35          [-1, 224, 32, 32]             448\n",
      "             ReLU-36          [-1, 224, 32, 32]               0\n",
      "           Conv2d-37          [-1, 128, 32, 32]          28,672\n",
      "      BatchNorm2d-38          [-1, 128, 32, 32]             256\n",
      "             ReLU-39          [-1, 128, 32, 32]               0\n",
      "           Conv2d-40           [-1, 32, 32, 32]          36,864\n",
      "      _DenseBlock-41          [-1, 256, 32, 32]               0\n",
      "      BatchNorm2d-42          [-1, 256, 32, 32]             512\n",
      "             ReLU-43          [-1, 256, 32, 32]               0\n",
      "           Conv2d-44          [-1, 128, 32, 32]          32,768\n",
      "        AvgPool2d-45          [-1, 128, 16, 16]               0\n",
      "      BatchNorm2d-46          [-1, 128, 16, 16]             256\n",
      "             ReLU-47          [-1, 128, 16, 16]               0\n",
      "           Conv2d-48          [-1, 128, 16, 16]          16,384\n",
      "      BatchNorm2d-49          [-1, 128, 16, 16]             256\n",
      "             ReLU-50          [-1, 128, 16, 16]               0\n",
      "           Conv2d-51           [-1, 32, 16, 16]          36,864\n",
      "      BatchNorm2d-52          [-1, 160, 16, 16]             320\n",
      "             ReLU-53          [-1, 160, 16, 16]               0\n",
      "           Conv2d-54          [-1, 128, 16, 16]          20,480\n",
      "      BatchNorm2d-55          [-1, 128, 16, 16]             256\n",
      "             ReLU-56          [-1, 128, 16, 16]               0\n",
      "           Conv2d-57           [-1, 32, 16, 16]          36,864\n",
      "      BatchNorm2d-58          [-1, 192, 16, 16]             384\n",
      "             ReLU-59          [-1, 192, 16, 16]               0\n",
      "           Conv2d-60          [-1, 128, 16, 16]          24,576\n",
      "      BatchNorm2d-61          [-1, 128, 16, 16]             256\n",
      "             ReLU-62          [-1, 128, 16, 16]               0\n",
      "           Conv2d-63           [-1, 32, 16, 16]          36,864\n",
      "      BatchNorm2d-64          [-1, 224, 16, 16]             448\n",
      "             ReLU-65          [-1, 224, 16, 16]               0\n",
      "           Conv2d-66          [-1, 128, 16, 16]          28,672\n",
      "      BatchNorm2d-67          [-1, 128, 16, 16]             256\n",
      "             ReLU-68          [-1, 128, 16, 16]               0\n",
      "           Conv2d-69           [-1, 32, 16, 16]          36,864\n",
      "      BatchNorm2d-70          [-1, 256, 16, 16]             512\n",
      "             ReLU-71          [-1, 256, 16, 16]               0\n",
      "           Conv2d-72          [-1, 128, 16, 16]          32,768\n",
      "      BatchNorm2d-73          [-1, 128, 16, 16]             256\n",
      "             ReLU-74          [-1, 128, 16, 16]               0\n",
      "           Conv2d-75           [-1, 32, 16, 16]          36,864\n",
      "      BatchNorm2d-76          [-1, 288, 16, 16]             576\n",
      "             ReLU-77          [-1, 288, 16, 16]               0\n",
      "           Conv2d-78          [-1, 128, 16, 16]          36,864\n",
      "      BatchNorm2d-79          [-1, 128, 16, 16]             256\n",
      "             ReLU-80          [-1, 128, 16, 16]               0\n",
      "           Conv2d-81           [-1, 32, 16, 16]          36,864\n",
      "      BatchNorm2d-82          [-1, 320, 16, 16]             640\n",
      "             ReLU-83          [-1, 320, 16, 16]               0\n",
      "           Conv2d-84          [-1, 128, 16, 16]          40,960\n",
      "      BatchNorm2d-85          [-1, 128, 16, 16]             256\n",
      "             ReLU-86          [-1, 128, 16, 16]               0\n",
      "           Conv2d-87           [-1, 32, 16, 16]          36,864\n",
      "      BatchNorm2d-88          [-1, 352, 16, 16]             704\n",
      "             ReLU-89          [-1, 352, 16, 16]               0\n",
      "           Conv2d-90          [-1, 128, 16, 16]          45,056\n",
      "      BatchNorm2d-91          [-1, 128, 16, 16]             256\n",
      "             ReLU-92          [-1, 128, 16, 16]               0\n",
      "           Conv2d-93           [-1, 32, 16, 16]          36,864\n",
      "      BatchNorm2d-94          [-1, 384, 16, 16]             768\n",
      "             ReLU-95          [-1, 384, 16, 16]               0\n",
      "           Conv2d-96          [-1, 128, 16, 16]          49,152\n",
      "      BatchNorm2d-97          [-1, 128, 16, 16]             256\n",
      "             ReLU-98          [-1, 128, 16, 16]               0\n",
      "           Conv2d-99           [-1, 32, 16, 16]          36,864\n",
      "     BatchNorm2d-100          [-1, 416, 16, 16]             832\n",
      "            ReLU-101          [-1, 416, 16, 16]               0\n",
      "          Conv2d-102          [-1, 128, 16, 16]          53,248\n",
      "     BatchNorm2d-103          [-1, 128, 16, 16]             256\n",
      "            ReLU-104          [-1, 128, 16, 16]               0\n",
      "          Conv2d-105           [-1, 32, 16, 16]          36,864\n",
      "     BatchNorm2d-106          [-1, 448, 16, 16]             896\n",
      "            ReLU-107          [-1, 448, 16, 16]               0\n",
      "          Conv2d-108          [-1, 128, 16, 16]          57,344\n",
      "     BatchNorm2d-109          [-1, 128, 16, 16]             256\n",
      "            ReLU-110          [-1, 128, 16, 16]               0\n",
      "          Conv2d-111           [-1, 32, 16, 16]          36,864\n",
      "     BatchNorm2d-112          [-1, 480, 16, 16]             960\n",
      "            ReLU-113          [-1, 480, 16, 16]               0\n",
      "          Conv2d-114          [-1, 128, 16, 16]          61,440\n",
      "     BatchNorm2d-115          [-1, 128, 16, 16]             256\n",
      "            ReLU-116          [-1, 128, 16, 16]               0\n",
      "          Conv2d-117           [-1, 32, 16, 16]          36,864\n",
      "     _DenseBlock-118          [-1, 512, 16, 16]               0\n",
      "     BatchNorm2d-119          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-120          [-1, 512, 16, 16]               0\n",
      "          Conv2d-121          [-1, 256, 16, 16]         131,072\n",
      "       AvgPool2d-122            [-1, 256, 8, 8]               0\n",
      "     BatchNorm2d-123            [-1, 256, 8, 8]             512\n",
      "            ReLU-124            [-1, 256, 8, 8]               0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Conv2d-125            [-1, 128, 8, 8]          32,768\n",
      "     BatchNorm2d-126            [-1, 128, 8, 8]             256\n",
      "            ReLU-127            [-1, 128, 8, 8]               0\n",
      "          Conv2d-128             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-129            [-1, 288, 8, 8]             576\n",
      "            ReLU-130            [-1, 288, 8, 8]               0\n",
      "          Conv2d-131            [-1, 128, 8, 8]          36,864\n",
      "     BatchNorm2d-132            [-1, 128, 8, 8]             256\n",
      "            ReLU-133            [-1, 128, 8, 8]               0\n",
      "          Conv2d-134             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-135            [-1, 320, 8, 8]             640\n",
      "            ReLU-136            [-1, 320, 8, 8]               0\n",
      "          Conv2d-137            [-1, 128, 8, 8]          40,960\n",
      "     BatchNorm2d-138            [-1, 128, 8, 8]             256\n",
      "            ReLU-139            [-1, 128, 8, 8]               0\n",
      "          Conv2d-140             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-141            [-1, 352, 8, 8]             704\n",
      "            ReLU-142            [-1, 352, 8, 8]               0\n",
      "          Conv2d-143            [-1, 128, 8, 8]          45,056\n",
      "     BatchNorm2d-144            [-1, 128, 8, 8]             256\n",
      "            ReLU-145            [-1, 128, 8, 8]               0\n",
      "          Conv2d-146             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-147            [-1, 384, 8, 8]             768\n",
      "            ReLU-148            [-1, 384, 8, 8]               0\n",
      "          Conv2d-149            [-1, 128, 8, 8]          49,152\n",
      "     BatchNorm2d-150            [-1, 128, 8, 8]             256\n",
      "            ReLU-151            [-1, 128, 8, 8]               0\n",
      "          Conv2d-152             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-153            [-1, 416, 8, 8]             832\n",
      "            ReLU-154            [-1, 416, 8, 8]               0\n",
      "          Conv2d-155            [-1, 128, 8, 8]          53,248\n",
      "     BatchNorm2d-156            [-1, 128, 8, 8]             256\n",
      "            ReLU-157            [-1, 128, 8, 8]               0\n",
      "          Conv2d-158             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-159            [-1, 448, 8, 8]             896\n",
      "            ReLU-160            [-1, 448, 8, 8]               0\n",
      "          Conv2d-161            [-1, 128, 8, 8]          57,344\n",
      "     BatchNorm2d-162            [-1, 128, 8, 8]             256\n",
      "            ReLU-163            [-1, 128, 8, 8]               0\n",
      "          Conv2d-164             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-165            [-1, 480, 8, 8]             960\n",
      "            ReLU-166            [-1, 480, 8, 8]               0\n",
      "          Conv2d-167            [-1, 128, 8, 8]          61,440\n",
      "     BatchNorm2d-168            [-1, 128, 8, 8]             256\n",
      "            ReLU-169            [-1, 128, 8, 8]               0\n",
      "          Conv2d-170             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-171            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-172            [-1, 512, 8, 8]               0\n",
      "          Conv2d-173            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-174            [-1, 128, 8, 8]             256\n",
      "            ReLU-175            [-1, 128, 8, 8]               0\n",
      "          Conv2d-176             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-177            [-1, 544, 8, 8]           1,088\n",
      "            ReLU-178            [-1, 544, 8, 8]               0\n",
      "          Conv2d-179            [-1, 128, 8, 8]          69,632\n",
      "     BatchNorm2d-180            [-1, 128, 8, 8]             256\n",
      "            ReLU-181            [-1, 128, 8, 8]               0\n",
      "          Conv2d-182             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-183            [-1, 576, 8, 8]           1,152\n",
      "            ReLU-184            [-1, 576, 8, 8]               0\n",
      "          Conv2d-185            [-1, 128, 8, 8]          73,728\n",
      "     BatchNorm2d-186            [-1, 128, 8, 8]             256\n",
      "            ReLU-187            [-1, 128, 8, 8]               0\n",
      "          Conv2d-188             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-189            [-1, 608, 8, 8]           1,216\n",
      "            ReLU-190            [-1, 608, 8, 8]               0\n",
      "          Conv2d-191            [-1, 128, 8, 8]          77,824\n",
      "     BatchNorm2d-192            [-1, 128, 8, 8]             256\n",
      "            ReLU-193            [-1, 128, 8, 8]               0\n",
      "          Conv2d-194             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-195            [-1, 640, 8, 8]           1,280\n",
      "            ReLU-196            [-1, 640, 8, 8]               0\n",
      "          Conv2d-197            [-1, 128, 8, 8]          81,920\n",
      "     BatchNorm2d-198            [-1, 128, 8, 8]             256\n",
      "            ReLU-199            [-1, 128, 8, 8]               0\n",
      "          Conv2d-200             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-201            [-1, 672, 8, 8]           1,344\n",
      "            ReLU-202            [-1, 672, 8, 8]               0\n",
      "          Conv2d-203            [-1, 128, 8, 8]          86,016\n",
      "     BatchNorm2d-204            [-1, 128, 8, 8]             256\n",
      "            ReLU-205            [-1, 128, 8, 8]               0\n",
      "          Conv2d-206             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-207            [-1, 704, 8, 8]           1,408\n",
      "            ReLU-208            [-1, 704, 8, 8]               0\n",
      "          Conv2d-209            [-1, 128, 8, 8]          90,112\n",
      "     BatchNorm2d-210            [-1, 128, 8, 8]             256\n",
      "            ReLU-211            [-1, 128, 8, 8]               0\n",
      "          Conv2d-212             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-213            [-1, 736, 8, 8]           1,472\n",
      "            ReLU-214            [-1, 736, 8, 8]               0\n",
      "          Conv2d-215            [-1, 128, 8, 8]          94,208\n",
      "     BatchNorm2d-216            [-1, 128, 8, 8]             256\n",
      "            ReLU-217            [-1, 128, 8, 8]               0\n",
      "          Conv2d-218             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-219            [-1, 768, 8, 8]           1,536\n",
      "            ReLU-220            [-1, 768, 8, 8]               0\n",
      "          Conv2d-221            [-1, 128, 8, 8]          98,304\n",
      "     BatchNorm2d-222            [-1, 128, 8, 8]             256\n",
      "            ReLU-223            [-1, 128, 8, 8]               0\n",
      "          Conv2d-224             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-225            [-1, 800, 8, 8]           1,600\n",
      "            ReLU-226            [-1, 800, 8, 8]               0\n",
      "          Conv2d-227            [-1, 128, 8, 8]         102,400\n",
      "     BatchNorm2d-228            [-1, 128, 8, 8]             256\n",
      "            ReLU-229            [-1, 128, 8, 8]               0\n",
      "          Conv2d-230             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-231            [-1, 832, 8, 8]           1,664\n",
      "            ReLU-232            [-1, 832, 8, 8]               0\n",
      "          Conv2d-233            [-1, 128, 8, 8]         106,496\n",
      "     BatchNorm2d-234            [-1, 128, 8, 8]             256\n",
      "            ReLU-235            [-1, 128, 8, 8]               0\n",
      "          Conv2d-236             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-237            [-1, 864, 8, 8]           1,728\n",
      "            ReLU-238            [-1, 864, 8, 8]               0\n",
      "          Conv2d-239            [-1, 128, 8, 8]         110,592\n",
      "     BatchNorm2d-240            [-1, 128, 8, 8]             256\n",
      "            ReLU-241            [-1, 128, 8, 8]               0\n",
      "          Conv2d-242             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-243            [-1, 896, 8, 8]           1,792\n",
      "            ReLU-244            [-1, 896, 8, 8]               0\n",
      "          Conv2d-245            [-1, 128, 8, 8]         114,688\n",
      "     BatchNorm2d-246            [-1, 128, 8, 8]             256\n",
      "            ReLU-247            [-1, 128, 8, 8]               0\n",
      "          Conv2d-248             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-249            [-1, 928, 8, 8]           1,856\n",
      "            ReLU-250            [-1, 928, 8, 8]               0\n",
      "          Conv2d-251            [-1, 128, 8, 8]         118,784\n",
      "     BatchNorm2d-252            [-1, 128, 8, 8]             256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ReLU-253            [-1, 128, 8, 8]               0\n",
      "          Conv2d-254             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-255            [-1, 960, 8, 8]           1,920\n",
      "            ReLU-256            [-1, 960, 8, 8]               0\n",
      "          Conv2d-257            [-1, 128, 8, 8]         122,880\n",
      "     BatchNorm2d-258            [-1, 128, 8, 8]             256\n",
      "            ReLU-259            [-1, 128, 8, 8]               0\n",
      "          Conv2d-260             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-261            [-1, 992, 8, 8]           1,984\n",
      "            ReLU-262            [-1, 992, 8, 8]               0\n",
      "          Conv2d-263            [-1, 128, 8, 8]         126,976\n",
      "     BatchNorm2d-264            [-1, 128, 8, 8]             256\n",
      "            ReLU-265            [-1, 128, 8, 8]               0\n",
      "          Conv2d-266             [-1, 32, 8, 8]          36,864\n",
      "     _DenseBlock-267           [-1, 1024, 8, 8]               0\n",
      "     BatchNorm2d-268           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-269           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-270            [-1, 512, 8, 8]         524,288\n",
      "       AvgPool2d-271            [-1, 512, 4, 4]               0\n",
      "     BatchNorm2d-272            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-273            [-1, 512, 4, 4]               0\n",
      "          Conv2d-274            [-1, 128, 4, 4]          65,536\n",
      "     BatchNorm2d-275            [-1, 128, 4, 4]             256\n",
      "            ReLU-276            [-1, 128, 4, 4]               0\n",
      "          Conv2d-277             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-278            [-1, 544, 4, 4]           1,088\n",
      "            ReLU-279            [-1, 544, 4, 4]               0\n",
      "          Conv2d-280            [-1, 128, 4, 4]          69,632\n",
      "     BatchNorm2d-281            [-1, 128, 4, 4]             256\n",
      "            ReLU-282            [-1, 128, 4, 4]               0\n",
      "          Conv2d-283             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-284            [-1, 576, 4, 4]           1,152\n",
      "            ReLU-285            [-1, 576, 4, 4]               0\n",
      "          Conv2d-286            [-1, 128, 4, 4]          73,728\n",
      "     BatchNorm2d-287            [-1, 128, 4, 4]             256\n",
      "            ReLU-288            [-1, 128, 4, 4]               0\n",
      "          Conv2d-289             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-290            [-1, 608, 4, 4]           1,216\n",
      "            ReLU-291            [-1, 608, 4, 4]               0\n",
      "          Conv2d-292            [-1, 128, 4, 4]          77,824\n",
      "     BatchNorm2d-293            [-1, 128, 4, 4]             256\n",
      "            ReLU-294            [-1, 128, 4, 4]               0\n",
      "          Conv2d-295             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-296            [-1, 640, 4, 4]           1,280\n",
      "            ReLU-297            [-1, 640, 4, 4]               0\n",
      "          Conv2d-298            [-1, 128, 4, 4]          81,920\n",
      "     BatchNorm2d-299            [-1, 128, 4, 4]             256\n",
      "            ReLU-300            [-1, 128, 4, 4]               0\n",
      "          Conv2d-301             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-302            [-1, 672, 4, 4]           1,344\n",
      "            ReLU-303            [-1, 672, 4, 4]               0\n",
      "          Conv2d-304            [-1, 128, 4, 4]          86,016\n",
      "     BatchNorm2d-305            [-1, 128, 4, 4]             256\n",
      "            ReLU-306            [-1, 128, 4, 4]               0\n",
      "          Conv2d-307             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-308            [-1, 704, 4, 4]           1,408\n",
      "            ReLU-309            [-1, 704, 4, 4]               0\n",
      "          Conv2d-310            [-1, 128, 4, 4]          90,112\n",
      "     BatchNorm2d-311            [-1, 128, 4, 4]             256\n",
      "            ReLU-312            [-1, 128, 4, 4]               0\n",
      "          Conv2d-313             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-314            [-1, 736, 4, 4]           1,472\n",
      "            ReLU-315            [-1, 736, 4, 4]               0\n",
      "          Conv2d-316            [-1, 128, 4, 4]          94,208\n",
      "     BatchNorm2d-317            [-1, 128, 4, 4]             256\n",
      "            ReLU-318            [-1, 128, 4, 4]               0\n",
      "          Conv2d-319             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-320            [-1, 768, 4, 4]           1,536\n",
      "            ReLU-321            [-1, 768, 4, 4]               0\n",
      "          Conv2d-322            [-1, 128, 4, 4]          98,304\n",
      "     BatchNorm2d-323            [-1, 128, 4, 4]             256\n",
      "            ReLU-324            [-1, 128, 4, 4]               0\n",
      "          Conv2d-325             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-326            [-1, 800, 4, 4]           1,600\n",
      "            ReLU-327            [-1, 800, 4, 4]               0\n",
      "          Conv2d-328            [-1, 128, 4, 4]         102,400\n",
      "     BatchNorm2d-329            [-1, 128, 4, 4]             256\n",
      "            ReLU-330            [-1, 128, 4, 4]               0\n",
      "          Conv2d-331             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-332            [-1, 832, 4, 4]           1,664\n",
      "            ReLU-333            [-1, 832, 4, 4]               0\n",
      "          Conv2d-334            [-1, 128, 4, 4]         106,496\n",
      "     BatchNorm2d-335            [-1, 128, 4, 4]             256\n",
      "            ReLU-336            [-1, 128, 4, 4]               0\n",
      "          Conv2d-337             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-338            [-1, 864, 4, 4]           1,728\n",
      "            ReLU-339            [-1, 864, 4, 4]               0\n",
      "          Conv2d-340            [-1, 128, 4, 4]         110,592\n",
      "     BatchNorm2d-341            [-1, 128, 4, 4]             256\n",
      "            ReLU-342            [-1, 128, 4, 4]               0\n",
      "          Conv2d-343             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-344            [-1, 896, 4, 4]           1,792\n",
      "            ReLU-345            [-1, 896, 4, 4]               0\n",
      "          Conv2d-346            [-1, 128, 4, 4]         114,688\n",
      "     BatchNorm2d-347            [-1, 128, 4, 4]             256\n",
      "            ReLU-348            [-1, 128, 4, 4]               0\n",
      "          Conv2d-349             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-350            [-1, 928, 4, 4]           1,856\n",
      "            ReLU-351            [-1, 928, 4, 4]               0\n",
      "          Conv2d-352            [-1, 128, 4, 4]         118,784\n",
      "     BatchNorm2d-353            [-1, 128, 4, 4]             256\n",
      "            ReLU-354            [-1, 128, 4, 4]               0\n",
      "          Conv2d-355             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-356            [-1, 960, 4, 4]           1,920\n",
      "            ReLU-357            [-1, 960, 4, 4]               0\n",
      "          Conv2d-358            [-1, 128, 4, 4]         122,880\n",
      "     BatchNorm2d-359            [-1, 128, 4, 4]             256\n",
      "            ReLU-360            [-1, 128, 4, 4]               0\n",
      "          Conv2d-361             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-362            [-1, 992, 4, 4]           1,984\n",
      "            ReLU-363            [-1, 992, 4, 4]               0\n",
      "          Conv2d-364            [-1, 128, 4, 4]         126,976\n",
      "     BatchNorm2d-365            [-1, 128, 4, 4]             256\n",
      "            ReLU-366            [-1, 128, 4, 4]               0\n",
      "          Conv2d-367             [-1, 32, 4, 4]          36,864\n",
      "     _DenseBlock-368           [-1, 1024, 4, 4]               0\n",
      "     BatchNorm2d-369           [-1, 1024, 4, 4]           2,048\n",
      "          Linear-370                  [-1, 128]         131,200\n",
      "        DenseNet-371                  [-1, 128]               0\n",
      "SpectrogramEncoderNet-372                  [-1, 128]               0\n",
      "        Identity-373                  [-1, 128]               0\n",
      "          Conv2d-374           [-1, 64, 64, 64]           9,408\n",
      "     BatchNorm2d-375           [-1, 64, 64, 64]             128\n",
      "            ReLU-376           [-1, 64, 64, 64]               0\n",
      "       MaxPool2d-377           [-1, 64, 32, 32]               0\n",
      "     BatchNorm2d-378           [-1, 64, 32, 32]             128\n",
      "            ReLU-379           [-1, 64, 32, 32]               0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Conv2d-380          [-1, 128, 32, 32]           8,192\n",
      "     BatchNorm2d-381          [-1, 128, 32, 32]             256\n",
      "            ReLU-382          [-1, 128, 32, 32]               0\n",
      "          Conv2d-383           [-1, 32, 32, 32]          36,864\n",
      "     BatchNorm2d-384           [-1, 96, 32, 32]             192\n",
      "            ReLU-385           [-1, 96, 32, 32]               0\n",
      "          Conv2d-386          [-1, 128, 32, 32]          12,288\n",
      "     BatchNorm2d-387          [-1, 128, 32, 32]             256\n",
      "            ReLU-388          [-1, 128, 32, 32]               0\n",
      "          Conv2d-389           [-1, 32, 32, 32]          36,864\n",
      "     BatchNorm2d-390          [-1, 128, 32, 32]             256\n",
      "            ReLU-391          [-1, 128, 32, 32]               0\n",
      "          Conv2d-392          [-1, 128, 32, 32]          16,384\n",
      "     BatchNorm2d-393          [-1, 128, 32, 32]             256\n",
      "            ReLU-394          [-1, 128, 32, 32]               0\n",
      "          Conv2d-395           [-1, 32, 32, 32]          36,864\n",
      "     BatchNorm2d-396          [-1, 160, 32, 32]             320\n",
      "            ReLU-397          [-1, 160, 32, 32]               0\n",
      "          Conv2d-398          [-1, 128, 32, 32]          20,480\n",
      "     BatchNorm2d-399          [-1, 128, 32, 32]             256\n",
      "            ReLU-400          [-1, 128, 32, 32]               0\n",
      "          Conv2d-401           [-1, 32, 32, 32]          36,864\n",
      "     BatchNorm2d-402          [-1, 192, 32, 32]             384\n",
      "            ReLU-403          [-1, 192, 32, 32]               0\n",
      "          Conv2d-404          [-1, 128, 32, 32]          24,576\n",
      "     BatchNorm2d-405          [-1, 128, 32, 32]             256\n",
      "            ReLU-406          [-1, 128, 32, 32]               0\n",
      "          Conv2d-407           [-1, 32, 32, 32]          36,864\n",
      "     BatchNorm2d-408          [-1, 224, 32, 32]             448\n",
      "            ReLU-409          [-1, 224, 32, 32]               0\n",
      "          Conv2d-410          [-1, 128, 32, 32]          28,672\n",
      "     BatchNorm2d-411          [-1, 128, 32, 32]             256\n",
      "            ReLU-412          [-1, 128, 32, 32]               0\n",
      "          Conv2d-413           [-1, 32, 32, 32]          36,864\n",
      "     _DenseBlock-414          [-1, 256, 32, 32]               0\n",
      "     BatchNorm2d-415          [-1, 256, 32, 32]             512\n",
      "            ReLU-416          [-1, 256, 32, 32]               0\n",
      "          Conv2d-417          [-1, 128, 32, 32]          32,768\n",
      "       AvgPool2d-418          [-1, 128, 16, 16]               0\n",
      "     BatchNorm2d-419          [-1, 128, 16, 16]             256\n",
      "            ReLU-420          [-1, 128, 16, 16]               0\n",
      "          Conv2d-421          [-1, 128, 16, 16]          16,384\n",
      "     BatchNorm2d-422          [-1, 128, 16, 16]             256\n",
      "            ReLU-423          [-1, 128, 16, 16]               0\n",
      "          Conv2d-424           [-1, 32, 16, 16]          36,864\n",
      "     BatchNorm2d-425          [-1, 160, 16, 16]             320\n",
      "            ReLU-426          [-1, 160, 16, 16]               0\n",
      "          Conv2d-427          [-1, 128, 16, 16]          20,480\n",
      "     BatchNorm2d-428          [-1, 128, 16, 16]             256\n",
      "            ReLU-429          [-1, 128, 16, 16]               0\n",
      "          Conv2d-430           [-1, 32, 16, 16]          36,864\n",
      "     BatchNorm2d-431          [-1, 192, 16, 16]             384\n",
      "            ReLU-432          [-1, 192, 16, 16]               0\n",
      "          Conv2d-433          [-1, 128, 16, 16]          24,576\n",
      "     BatchNorm2d-434          [-1, 128, 16, 16]             256\n",
      "            ReLU-435          [-1, 128, 16, 16]               0\n",
      "          Conv2d-436           [-1, 32, 16, 16]          36,864\n",
      "     BatchNorm2d-437          [-1, 224, 16, 16]             448\n",
      "            ReLU-438          [-1, 224, 16, 16]               0\n",
      "          Conv2d-439          [-1, 128, 16, 16]          28,672\n",
      "     BatchNorm2d-440          [-1, 128, 16, 16]             256\n",
      "            ReLU-441          [-1, 128, 16, 16]               0\n",
      "          Conv2d-442           [-1, 32, 16, 16]          36,864\n",
      "     BatchNorm2d-443          [-1, 256, 16, 16]             512\n",
      "            ReLU-444          [-1, 256, 16, 16]               0\n",
      "          Conv2d-445          [-1, 128, 16, 16]          32,768\n",
      "     BatchNorm2d-446          [-1, 128, 16, 16]             256\n",
      "            ReLU-447          [-1, 128, 16, 16]               0\n",
      "          Conv2d-448           [-1, 32, 16, 16]          36,864\n",
      "     BatchNorm2d-449          [-1, 288, 16, 16]             576\n",
      "            ReLU-450          [-1, 288, 16, 16]               0\n",
      "          Conv2d-451          [-1, 128, 16, 16]          36,864\n",
      "     BatchNorm2d-452          [-1, 128, 16, 16]             256\n",
      "            ReLU-453          [-1, 128, 16, 16]               0\n",
      "          Conv2d-454           [-1, 32, 16, 16]          36,864\n",
      "     BatchNorm2d-455          [-1, 320, 16, 16]             640\n",
      "            ReLU-456          [-1, 320, 16, 16]               0\n",
      "          Conv2d-457          [-1, 128, 16, 16]          40,960\n",
      "     BatchNorm2d-458          [-1, 128, 16, 16]             256\n",
      "            ReLU-459          [-1, 128, 16, 16]               0\n",
      "          Conv2d-460           [-1, 32, 16, 16]          36,864\n",
      "     BatchNorm2d-461          [-1, 352, 16, 16]             704\n",
      "            ReLU-462          [-1, 352, 16, 16]               0\n",
      "          Conv2d-463          [-1, 128, 16, 16]          45,056\n",
      "     BatchNorm2d-464          [-1, 128, 16, 16]             256\n",
      "            ReLU-465          [-1, 128, 16, 16]               0\n",
      "          Conv2d-466           [-1, 32, 16, 16]          36,864\n",
      "     BatchNorm2d-467          [-1, 384, 16, 16]             768\n",
      "            ReLU-468          [-1, 384, 16, 16]               0\n",
      "          Conv2d-469          [-1, 128, 16, 16]          49,152\n",
      "     BatchNorm2d-470          [-1, 128, 16, 16]             256\n",
      "            ReLU-471          [-1, 128, 16, 16]               0\n",
      "          Conv2d-472           [-1, 32, 16, 16]          36,864\n",
      "     BatchNorm2d-473          [-1, 416, 16, 16]             832\n",
      "            ReLU-474          [-1, 416, 16, 16]               0\n",
      "          Conv2d-475          [-1, 128, 16, 16]          53,248\n",
      "     BatchNorm2d-476          [-1, 128, 16, 16]             256\n",
      "            ReLU-477          [-1, 128, 16, 16]               0\n",
      "          Conv2d-478           [-1, 32, 16, 16]          36,864\n",
      "     BatchNorm2d-479          [-1, 448, 16, 16]             896\n",
      "            ReLU-480          [-1, 448, 16, 16]               0\n",
      "          Conv2d-481          [-1, 128, 16, 16]          57,344\n",
      "     BatchNorm2d-482          [-1, 128, 16, 16]             256\n",
      "            ReLU-483          [-1, 128, 16, 16]               0\n",
      "          Conv2d-484           [-1, 32, 16, 16]          36,864\n",
      "     BatchNorm2d-485          [-1, 480, 16, 16]             960\n",
      "            ReLU-486          [-1, 480, 16, 16]               0\n",
      "          Conv2d-487          [-1, 128, 16, 16]          61,440\n",
      "     BatchNorm2d-488          [-1, 128, 16, 16]             256\n",
      "            ReLU-489          [-1, 128, 16, 16]               0\n",
      "          Conv2d-490           [-1, 32, 16, 16]          36,864\n",
      "     _DenseBlock-491          [-1, 512, 16, 16]               0\n",
      "     BatchNorm2d-492          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-493          [-1, 512, 16, 16]               0\n",
      "          Conv2d-494          [-1, 256, 16, 16]         131,072\n",
      "       AvgPool2d-495            [-1, 256, 8, 8]               0\n",
      "     BatchNorm2d-496            [-1, 256, 8, 8]             512\n",
      "            ReLU-497            [-1, 256, 8, 8]               0\n",
      "          Conv2d-498            [-1, 128, 8, 8]          32,768\n",
      "     BatchNorm2d-499            [-1, 128, 8, 8]             256\n",
      "            ReLU-500            [-1, 128, 8, 8]               0\n",
      "          Conv2d-501             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-502            [-1, 288, 8, 8]             576\n",
      "            ReLU-503            [-1, 288, 8, 8]               0\n",
      "          Conv2d-504            [-1, 128, 8, 8]          36,864\n",
      "     BatchNorm2d-505            [-1, 128, 8, 8]             256\n",
      "            ReLU-506            [-1, 128, 8, 8]               0\n",
      "          Conv2d-507             [-1, 32, 8, 8]          36,864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-508            [-1, 320, 8, 8]             640\n",
      "            ReLU-509            [-1, 320, 8, 8]               0\n",
      "          Conv2d-510            [-1, 128, 8, 8]          40,960\n",
      "     BatchNorm2d-511            [-1, 128, 8, 8]             256\n",
      "            ReLU-512            [-1, 128, 8, 8]               0\n",
      "          Conv2d-513             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-514            [-1, 352, 8, 8]             704\n",
      "            ReLU-515            [-1, 352, 8, 8]               0\n",
      "          Conv2d-516            [-1, 128, 8, 8]          45,056\n",
      "     BatchNorm2d-517            [-1, 128, 8, 8]             256\n",
      "            ReLU-518            [-1, 128, 8, 8]               0\n",
      "          Conv2d-519             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-520            [-1, 384, 8, 8]             768\n",
      "            ReLU-521            [-1, 384, 8, 8]               0\n",
      "          Conv2d-522            [-1, 128, 8, 8]          49,152\n",
      "     BatchNorm2d-523            [-1, 128, 8, 8]             256\n",
      "            ReLU-524            [-1, 128, 8, 8]               0\n",
      "          Conv2d-525             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-526            [-1, 416, 8, 8]             832\n",
      "            ReLU-527            [-1, 416, 8, 8]               0\n",
      "          Conv2d-528            [-1, 128, 8, 8]          53,248\n",
      "     BatchNorm2d-529            [-1, 128, 8, 8]             256\n",
      "            ReLU-530            [-1, 128, 8, 8]               0\n",
      "          Conv2d-531             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-532            [-1, 448, 8, 8]             896\n",
      "            ReLU-533            [-1, 448, 8, 8]               0\n",
      "          Conv2d-534            [-1, 128, 8, 8]          57,344\n",
      "     BatchNorm2d-535            [-1, 128, 8, 8]             256\n",
      "            ReLU-536            [-1, 128, 8, 8]               0\n",
      "          Conv2d-537             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-538            [-1, 480, 8, 8]             960\n",
      "            ReLU-539            [-1, 480, 8, 8]               0\n",
      "          Conv2d-540            [-1, 128, 8, 8]          61,440\n",
      "     BatchNorm2d-541            [-1, 128, 8, 8]             256\n",
      "            ReLU-542            [-1, 128, 8, 8]               0\n",
      "          Conv2d-543             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-544            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-545            [-1, 512, 8, 8]               0\n",
      "          Conv2d-546            [-1, 128, 8, 8]          65,536\n",
      "     BatchNorm2d-547            [-1, 128, 8, 8]             256\n",
      "            ReLU-548            [-1, 128, 8, 8]               0\n",
      "          Conv2d-549             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-550            [-1, 544, 8, 8]           1,088\n",
      "            ReLU-551            [-1, 544, 8, 8]               0\n",
      "          Conv2d-552            [-1, 128, 8, 8]          69,632\n",
      "     BatchNorm2d-553            [-1, 128, 8, 8]             256\n",
      "            ReLU-554            [-1, 128, 8, 8]               0\n",
      "          Conv2d-555             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-556            [-1, 576, 8, 8]           1,152\n",
      "            ReLU-557            [-1, 576, 8, 8]               0\n",
      "          Conv2d-558            [-1, 128, 8, 8]          73,728\n",
      "     BatchNorm2d-559            [-1, 128, 8, 8]             256\n",
      "            ReLU-560            [-1, 128, 8, 8]               0\n",
      "          Conv2d-561             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-562            [-1, 608, 8, 8]           1,216\n",
      "            ReLU-563            [-1, 608, 8, 8]               0\n",
      "          Conv2d-564            [-1, 128, 8, 8]          77,824\n",
      "     BatchNorm2d-565            [-1, 128, 8, 8]             256\n",
      "            ReLU-566            [-1, 128, 8, 8]               0\n",
      "          Conv2d-567             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-568            [-1, 640, 8, 8]           1,280\n",
      "            ReLU-569            [-1, 640, 8, 8]               0\n",
      "          Conv2d-570            [-1, 128, 8, 8]          81,920\n",
      "     BatchNorm2d-571            [-1, 128, 8, 8]             256\n",
      "            ReLU-572            [-1, 128, 8, 8]               0\n",
      "          Conv2d-573             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-574            [-1, 672, 8, 8]           1,344\n",
      "            ReLU-575            [-1, 672, 8, 8]               0\n",
      "          Conv2d-576            [-1, 128, 8, 8]          86,016\n",
      "     BatchNorm2d-577            [-1, 128, 8, 8]             256\n",
      "            ReLU-578            [-1, 128, 8, 8]               0\n",
      "          Conv2d-579             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-580            [-1, 704, 8, 8]           1,408\n",
      "            ReLU-581            [-1, 704, 8, 8]               0\n",
      "          Conv2d-582            [-1, 128, 8, 8]          90,112\n",
      "     BatchNorm2d-583            [-1, 128, 8, 8]             256\n",
      "            ReLU-584            [-1, 128, 8, 8]               0\n",
      "          Conv2d-585             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-586            [-1, 736, 8, 8]           1,472\n",
      "            ReLU-587            [-1, 736, 8, 8]               0\n",
      "          Conv2d-588            [-1, 128, 8, 8]          94,208\n",
      "     BatchNorm2d-589            [-1, 128, 8, 8]             256\n",
      "            ReLU-590            [-1, 128, 8, 8]               0\n",
      "          Conv2d-591             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-592            [-1, 768, 8, 8]           1,536\n",
      "            ReLU-593            [-1, 768, 8, 8]               0\n",
      "          Conv2d-594            [-1, 128, 8, 8]          98,304\n",
      "     BatchNorm2d-595            [-1, 128, 8, 8]             256\n",
      "            ReLU-596            [-1, 128, 8, 8]               0\n",
      "          Conv2d-597             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-598            [-1, 800, 8, 8]           1,600\n",
      "            ReLU-599            [-1, 800, 8, 8]               0\n",
      "          Conv2d-600            [-1, 128, 8, 8]         102,400\n",
      "     BatchNorm2d-601            [-1, 128, 8, 8]             256\n",
      "            ReLU-602            [-1, 128, 8, 8]               0\n",
      "          Conv2d-603             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-604            [-1, 832, 8, 8]           1,664\n",
      "            ReLU-605            [-1, 832, 8, 8]               0\n",
      "          Conv2d-606            [-1, 128, 8, 8]         106,496\n",
      "     BatchNorm2d-607            [-1, 128, 8, 8]             256\n",
      "            ReLU-608            [-1, 128, 8, 8]               0\n",
      "          Conv2d-609             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-610            [-1, 864, 8, 8]           1,728\n",
      "            ReLU-611            [-1, 864, 8, 8]               0\n",
      "          Conv2d-612            [-1, 128, 8, 8]         110,592\n",
      "     BatchNorm2d-613            [-1, 128, 8, 8]             256\n",
      "            ReLU-614            [-1, 128, 8, 8]               0\n",
      "          Conv2d-615             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-616            [-1, 896, 8, 8]           1,792\n",
      "            ReLU-617            [-1, 896, 8, 8]               0\n",
      "          Conv2d-618            [-1, 128, 8, 8]         114,688\n",
      "     BatchNorm2d-619            [-1, 128, 8, 8]             256\n",
      "            ReLU-620            [-1, 128, 8, 8]               0\n",
      "          Conv2d-621             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-622            [-1, 928, 8, 8]           1,856\n",
      "            ReLU-623            [-1, 928, 8, 8]               0\n",
      "          Conv2d-624            [-1, 128, 8, 8]         118,784\n",
      "     BatchNorm2d-625            [-1, 128, 8, 8]             256\n",
      "            ReLU-626            [-1, 128, 8, 8]               0\n",
      "          Conv2d-627             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-628            [-1, 960, 8, 8]           1,920\n",
      "            ReLU-629            [-1, 960, 8, 8]               0\n",
      "          Conv2d-630            [-1, 128, 8, 8]         122,880\n",
      "     BatchNorm2d-631            [-1, 128, 8, 8]             256\n",
      "            ReLU-632            [-1, 128, 8, 8]               0\n",
      "          Conv2d-633             [-1, 32, 8, 8]          36,864\n",
      "     BatchNorm2d-634            [-1, 992, 8, 8]           1,984\n",
      "            ReLU-635            [-1, 992, 8, 8]               0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Conv2d-636            [-1, 128, 8, 8]         126,976\n",
      "     BatchNorm2d-637            [-1, 128, 8, 8]             256\n",
      "            ReLU-638            [-1, 128, 8, 8]               0\n",
      "          Conv2d-639             [-1, 32, 8, 8]          36,864\n",
      "     _DenseBlock-640           [-1, 1024, 8, 8]               0\n",
      "     BatchNorm2d-641           [-1, 1024, 8, 8]           2,048\n",
      "            ReLU-642           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-643            [-1, 512, 8, 8]         524,288\n",
      "       AvgPool2d-644            [-1, 512, 4, 4]               0\n",
      "     BatchNorm2d-645            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-646            [-1, 512, 4, 4]               0\n",
      "          Conv2d-647            [-1, 128, 4, 4]          65,536\n",
      "     BatchNorm2d-648            [-1, 128, 4, 4]             256\n",
      "            ReLU-649            [-1, 128, 4, 4]               0\n",
      "          Conv2d-650             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-651            [-1, 544, 4, 4]           1,088\n",
      "            ReLU-652            [-1, 544, 4, 4]               0\n",
      "          Conv2d-653            [-1, 128, 4, 4]          69,632\n",
      "     BatchNorm2d-654            [-1, 128, 4, 4]             256\n",
      "            ReLU-655            [-1, 128, 4, 4]               0\n",
      "          Conv2d-656             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-657            [-1, 576, 4, 4]           1,152\n",
      "            ReLU-658            [-1, 576, 4, 4]               0\n",
      "          Conv2d-659            [-1, 128, 4, 4]          73,728\n",
      "     BatchNorm2d-660            [-1, 128, 4, 4]             256\n",
      "            ReLU-661            [-1, 128, 4, 4]               0\n",
      "          Conv2d-662             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-663            [-1, 608, 4, 4]           1,216\n",
      "            ReLU-664            [-1, 608, 4, 4]               0\n",
      "          Conv2d-665            [-1, 128, 4, 4]          77,824\n",
      "     BatchNorm2d-666            [-1, 128, 4, 4]             256\n",
      "            ReLU-667            [-1, 128, 4, 4]               0\n",
      "          Conv2d-668             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-669            [-1, 640, 4, 4]           1,280\n",
      "            ReLU-670            [-1, 640, 4, 4]               0\n",
      "          Conv2d-671            [-1, 128, 4, 4]          81,920\n",
      "     BatchNorm2d-672            [-1, 128, 4, 4]             256\n",
      "            ReLU-673            [-1, 128, 4, 4]               0\n",
      "          Conv2d-674             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-675            [-1, 672, 4, 4]           1,344\n",
      "            ReLU-676            [-1, 672, 4, 4]               0\n",
      "          Conv2d-677            [-1, 128, 4, 4]          86,016\n",
      "     BatchNorm2d-678            [-1, 128, 4, 4]             256\n",
      "            ReLU-679            [-1, 128, 4, 4]               0\n",
      "          Conv2d-680             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-681            [-1, 704, 4, 4]           1,408\n",
      "            ReLU-682            [-1, 704, 4, 4]               0\n",
      "          Conv2d-683            [-1, 128, 4, 4]          90,112\n",
      "     BatchNorm2d-684            [-1, 128, 4, 4]             256\n",
      "            ReLU-685            [-1, 128, 4, 4]               0\n",
      "          Conv2d-686             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-687            [-1, 736, 4, 4]           1,472\n",
      "            ReLU-688            [-1, 736, 4, 4]               0\n",
      "          Conv2d-689            [-1, 128, 4, 4]          94,208\n",
      "     BatchNorm2d-690            [-1, 128, 4, 4]             256\n",
      "            ReLU-691            [-1, 128, 4, 4]               0\n",
      "          Conv2d-692             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-693            [-1, 768, 4, 4]           1,536\n",
      "            ReLU-694            [-1, 768, 4, 4]               0\n",
      "          Conv2d-695            [-1, 128, 4, 4]          98,304\n",
      "     BatchNorm2d-696            [-1, 128, 4, 4]             256\n",
      "            ReLU-697            [-1, 128, 4, 4]               0\n",
      "          Conv2d-698             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-699            [-1, 800, 4, 4]           1,600\n",
      "            ReLU-700            [-1, 800, 4, 4]               0\n",
      "          Conv2d-701            [-1, 128, 4, 4]         102,400\n",
      "     BatchNorm2d-702            [-1, 128, 4, 4]             256\n",
      "            ReLU-703            [-1, 128, 4, 4]               0\n",
      "          Conv2d-704             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-705            [-1, 832, 4, 4]           1,664\n",
      "            ReLU-706            [-1, 832, 4, 4]               0\n",
      "          Conv2d-707            [-1, 128, 4, 4]         106,496\n",
      "     BatchNorm2d-708            [-1, 128, 4, 4]             256\n",
      "            ReLU-709            [-1, 128, 4, 4]               0\n",
      "          Conv2d-710             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-711            [-1, 864, 4, 4]           1,728\n",
      "            ReLU-712            [-1, 864, 4, 4]               0\n",
      "          Conv2d-713            [-1, 128, 4, 4]         110,592\n",
      "     BatchNorm2d-714            [-1, 128, 4, 4]             256\n",
      "            ReLU-715            [-1, 128, 4, 4]               0\n",
      "          Conv2d-716             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-717            [-1, 896, 4, 4]           1,792\n",
      "            ReLU-718            [-1, 896, 4, 4]               0\n",
      "          Conv2d-719            [-1, 128, 4, 4]         114,688\n",
      "     BatchNorm2d-720            [-1, 128, 4, 4]             256\n",
      "            ReLU-721            [-1, 128, 4, 4]               0\n",
      "          Conv2d-722             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-723            [-1, 928, 4, 4]           1,856\n",
      "            ReLU-724            [-1, 928, 4, 4]               0\n",
      "          Conv2d-725            [-1, 128, 4, 4]         118,784\n",
      "     BatchNorm2d-726            [-1, 128, 4, 4]             256\n",
      "            ReLU-727            [-1, 128, 4, 4]               0\n",
      "          Conv2d-728             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-729            [-1, 960, 4, 4]           1,920\n",
      "            ReLU-730            [-1, 960, 4, 4]               0\n",
      "          Conv2d-731            [-1, 128, 4, 4]         122,880\n",
      "     BatchNorm2d-732            [-1, 128, 4, 4]             256\n",
      "            ReLU-733            [-1, 128, 4, 4]               0\n",
      "          Conv2d-734             [-1, 32, 4, 4]          36,864\n",
      "     BatchNorm2d-735            [-1, 992, 4, 4]           1,984\n",
      "            ReLU-736            [-1, 992, 4, 4]               0\n",
      "          Conv2d-737            [-1, 128, 4, 4]         126,976\n",
      "     BatchNorm2d-738            [-1, 128, 4, 4]             256\n",
      "            ReLU-739            [-1, 128, 4, 4]               0\n",
      "          Conv2d-740             [-1, 32, 4, 4]          36,864\n",
      "     _DenseBlock-741           [-1, 1024, 4, 4]               0\n",
      "     BatchNorm2d-742           [-1, 1024, 4, 4]           2,048\n",
      "          Linear-743                  [-1, 128]         131,200\n",
      "        DenseNet-744                  [-1, 128]               0\n",
      "SpectrogramEncoderNet-745                  [-1, 128]               0\n",
      "        Identity-746                  [-1, 128]               0\n",
      "================================================================\n",
      "Total params: 14,170,112\n",
      "Trainable params: 14,170,112\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.12\n",
      "Forward/backward pass size (MB): 199.38\n",
      "Params size (MB): 54.05\n",
      "Estimated Total Size (MB): 254.56\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(MultiSiameseContrastiveClassifierNet(), input_size=(CANDIDATE_SIZE+1, 3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training data\n",
    "training_folder = os.path.join(output_data_folder, \"training_dataset_full_spectrogram/vox1_dev_wav\")\n",
    "spectrogram_samples_files = [os.path.join(training_folder, file) for file in os.listdir(training_folder)]\n",
    "candidate_size = CANDIDATE_SIZE\n",
    "# batch_size = 15   # mobilenet_v2\n",
    "batch_size = 6   # densenet121\n",
    "num_batches = 2000 // batch_size\n",
    "num_sub_samples = 200\n",
    "training_data_generator = ContrastiveDataGenerator(spectrogram_samples_files, candidate_size, batch_size, num_batches, num_sub_samples, IMG_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validation data\n",
    "validation_set_file = os.path.join(output_data_folder, \"validation_sets\", \"contrastive_validation_set.pickle\")\n",
    "with open(validation_set_file, 'rb') as f:\n",
    "    validation_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, training_data_generator, validation_data, log_handler):\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    t1 = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        log_handler.print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        log_handler.print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            batches_used = 0\n",
    "            data_generator = training_data_generator.generate_batches() if phase == 'train' else validation_data\n",
    "            for data in data_generator:\n",
    "                batches_used += 1\n",
    "                input_imgs, labels = data\n",
    "                inputs = [img.to(device) for img in input_imgs]\n",
    "                labels = labels.to(device)               \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):   # gradient only for train\n",
    "                    outputs = model(inputs)      \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs[0].size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            epoch_loss = running_loss / (batches_used * inputs[0].size(0))\n",
    "            epoch_acc = running_corrects.double() / (batches_used * inputs[0].size(0))\n",
    "            log_handler.print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                log_handler.save_pytorch_model(model, \"best_model_{}.pt\".format(model.__class__.__name__))\n",
    "                example = [torch.rand(1, 3, IMG_HEIGHT, IMG_HEIGHT), torch.rand(1, 3, IMG_HEIGHT, IMG_HEIGHT)]\n",
    "                log_handler.save_pytorch_model_as_torchscript(model, \"mobile_model.pt\", (example,))\n",
    "\n",
    "        # end of epoch\n",
    "        log_handler.print(\"Time taken is {} seconds\".format(int(time.time()-t1)))\n",
    "        t1 = time.time()\n",
    "        log_handler.print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    log_handler.print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    log_handler.print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Desktop\\projects\\speaker_recognition_voxceleb1\\output_data\\models\\contrastive_encoder\\2020-04-06_19-42-12\n",
      "Description: Candidates: 5, Encoding: 128, Projection: None\n",
      "Base Model: densenet121\n",
      "Epoch 0/69\n",
      "----------\n",
      "train Loss: 1.5184 Acc: 0.3423\n",
      "val Loss: 1.3822 Acc: 0.4947\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 503 seconds\n",
      "\n",
      "Epoch 1/69\n",
      "----------\n",
      "train Loss: 1.4167 Acc: 0.4104\n",
      "val Loss: 1.2773 Acc: 0.5343\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 499 seconds\n",
      "\n",
      "Epoch 2/69\n",
      "----------\n",
      "train Loss: 1.3332 Acc: 0.4575\n",
      "val Loss: 1.2419 Acc: 0.5574\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 501 seconds\n",
      "\n",
      "Epoch 3/69\n",
      "----------\n",
      "train Loss: 1.3324 Acc: 0.4620\n",
      "val Loss: 1.2401 Acc: 0.5679\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 499 seconds\n",
      "\n",
      "Epoch 4/69\n",
      "----------\n",
      "train Loss: 1.3088 Acc: 0.4725\n",
      "val Loss: 1.2324 Acc: 0.5774\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 504 seconds\n",
      "\n",
      "Epoch 5/69\n",
      "----------\n",
      "train Loss: 1.3329 Acc: 0.4585\n",
      "val Loss: 1.2507 Acc: 0.5830\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 491 seconds\n",
      "\n",
      "Epoch 6/69\n",
      "----------\n",
      "train Loss: 1.2897 Acc: 0.4860\n",
      "val Loss: 1.2198 Acc: 0.5830\n",
      "Time taken is 483 seconds\n",
      "\n",
      "Epoch 7/69\n",
      "----------\n",
      "train Loss: 1.2746 Acc: 0.4915\n",
      "val Loss: 1.2099 Acc: 0.6120\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 482 seconds\n",
      "\n",
      "Epoch 8/69\n",
      "----------\n",
      "train Loss: 1.2518 Acc: 0.5025\n",
      "val Loss: 1.2110 Acc: 0.5789\n",
      "Time taken is 479 seconds\n",
      "\n",
      "Epoch 9/69\n",
      "----------\n",
      "train Loss: 1.2679 Acc: 0.4830\n",
      "val Loss: 1.1868 Acc: 0.5870\n",
      "Time taken is 478 seconds\n",
      "\n",
      "Epoch 10/69\n",
      "----------\n",
      "train Loss: 1.2572 Acc: 0.5045\n",
      "val Loss: 1.2079 Acc: 0.5604\n",
      "Time taken is 483 seconds\n",
      "\n",
      "Epoch 11/69\n",
      "----------\n",
      "train Loss: 1.2503 Acc: 0.4980\n",
      "val Loss: 1.2054 Acc: 0.5810\n",
      "Time taken is 476 seconds\n",
      "\n",
      "Epoch 12/69\n",
      "----------\n",
      "train Loss: 1.2478 Acc: 0.4875\n",
      "val Loss: 1.1998 Acc: 0.5794\n",
      "Time taken is 479 seconds\n",
      "\n",
      "Epoch 13/69\n",
      "----------\n",
      "train Loss: 1.2494 Acc: 0.4905\n",
      "val Loss: 1.2026 Acc: 0.5890\n",
      "Time taken is 478 seconds\n",
      "\n",
      "Epoch 14/69\n",
      "----------\n",
      "train Loss: 1.2546 Acc: 0.5170\n",
      "val Loss: 1.1934 Acc: 0.6025\n",
      "Time taken is 482 seconds\n",
      "\n",
      "Epoch 15/69\n",
      "----------\n",
      "train Loss: 1.2160 Acc: 0.5175\n",
      "val Loss: 1.1804 Acc: 0.5930\n",
      "Time taken is 476 seconds\n",
      "\n",
      "Epoch 16/69\n",
      "----------\n",
      "train Loss: 1.2243 Acc: 0.5225\n",
      "val Loss: 1.1713 Acc: 0.6120\n",
      "Time taken is 476 seconds\n",
      "\n",
      "Epoch 17/69\n",
      "----------\n",
      "train Loss: 1.2043 Acc: 0.5395\n",
      "val Loss: 1.1607 Acc: 0.6100\n",
      "Time taken is 477 seconds\n",
      "\n",
      "Epoch 18/69\n",
      "----------\n",
      "train Loss: 1.2115 Acc: 0.5215\n",
      "val Loss: 1.1607 Acc: 0.6180\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 485 seconds\n",
      "\n",
      "Epoch 19/69\n",
      "----------\n",
      "train Loss: 1.2334 Acc: 0.4980\n",
      "val Loss: 1.1659 Acc: 0.6085\n",
      "Time taken is 480 seconds\n",
      "\n",
      "Epoch 20/69\n",
      "----------\n",
      "train Loss: 1.2091 Acc: 0.5280\n",
      "val Loss: 1.1696 Acc: 0.6201\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 483 seconds\n",
      "\n",
      "Epoch 21/69\n",
      "----------\n",
      "train Loss: 1.2175 Acc: 0.5205\n",
      "val Loss: 1.1769 Acc: 0.6035\n",
      "Time taken is 488 seconds\n",
      "\n",
      "Epoch 22/69\n",
      "----------\n",
      "train Loss: 1.1897 Acc: 0.5280\n",
      "val Loss: 1.1534 Acc: 0.6216\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 482 seconds\n",
      "\n",
      "Epoch 23/69\n",
      "----------\n",
      "train Loss: 1.1825 Acc: 0.5410\n",
      "val Loss: 1.1579 Acc: 0.6316\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 487 seconds\n",
      "\n",
      "Epoch 24/69\n",
      "----------\n",
      "train Loss: 1.1902 Acc: 0.5536\n",
      "val Loss: 1.1545 Acc: 0.6321\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 490 seconds\n",
      "\n",
      "Epoch 25/69\n",
      "----------\n",
      "train Loss: 1.1788 Acc: 0.5581\n",
      "val Loss: 1.1595 Acc: 0.6231\n",
      "Time taken is 485 seconds\n",
      "\n",
      "Epoch 26/69\n",
      "----------\n",
      "train Loss: 1.1967 Acc: 0.5380\n",
      "val Loss: 1.1648 Acc: 0.6316\n",
      "Time taken is 484 seconds\n",
      "\n",
      "Epoch 27/69\n",
      "----------\n",
      "train Loss: 1.1754 Acc: 0.5450\n",
      "val Loss: 1.1472 Acc: 0.6291\n",
      "Time taken is 490 seconds\n",
      "\n",
      "Epoch 28/69\n",
      "----------\n",
      "train Loss: 1.1816 Acc: 0.5556\n",
      "val Loss: 1.1454 Acc: 0.6266\n",
      "Time taken is 492 seconds\n",
      "\n",
      "Epoch 29/69\n",
      "----------\n",
      "train Loss: 1.1955 Acc: 0.5626\n",
      "val Loss: 1.1606 Acc: 0.6040\n",
      "Time taken is 491 seconds\n",
      "\n",
      "Epoch 30/69\n",
      "----------\n",
      "train Loss: 1.1617 Acc: 0.5716\n",
      "val Loss: 1.1502 Acc: 0.6531\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 497 seconds\n",
      "\n",
      "Epoch 31/69\n",
      "----------\n",
      "train Loss: 1.1727 Acc: 0.5661\n",
      "val Loss: 1.1566 Acc: 0.6276\n",
      "Time taken is 493 seconds\n",
      "\n",
      "Epoch 32/69\n",
      "----------\n",
      "train Loss: 1.1873 Acc: 0.5445\n",
      "val Loss: 1.1764 Acc: 0.6291\n",
      "Time taken is 492 seconds\n",
      "\n",
      "Epoch 33/69\n",
      "----------\n",
      "train Loss: 1.1609 Acc: 0.5826\n",
      "val Loss: 1.1495 Acc: 0.6135\n",
      "Time taken is 494 seconds\n",
      "\n",
      "Epoch 34/69\n",
      "----------\n",
      "train Loss: 1.1597 Acc: 0.5856\n",
      "val Loss: 1.1436 Acc: 0.6386\n",
      "Time taken is 523 seconds\n",
      "\n",
      "Epoch 35/69\n",
      "----------\n",
      "train Loss: 1.1823 Acc: 0.5566\n",
      "val Loss: 1.1462 Acc: 0.6366\n",
      "Time taken is 528 seconds\n",
      "\n",
      "Epoch 36/69\n",
      "----------\n",
      "train Loss: 1.1699 Acc: 0.5736\n",
      "val Loss: 1.1543 Acc: 0.6291\n",
      "Time taken is 526 seconds\n",
      "\n",
      "Epoch 37/69\n",
      "----------\n",
      "train Loss: 1.1556 Acc: 0.5726\n",
      "val Loss: 1.1695 Acc: 0.6366\n",
      "Time taken is 548 seconds\n",
      "\n",
      "Epoch 38/69\n",
      "----------\n",
      "train Loss: 1.1675 Acc: 0.5696\n",
      "val Loss: 1.1421 Acc: 0.6516\n",
      "Time taken is 594 seconds\n",
      "\n",
      "Epoch 39/69\n",
      "----------\n",
      "train Loss: 1.1685 Acc: 0.5796\n",
      "val Loss: 1.1576 Acc: 0.6286\n",
      "Time taken is 587 seconds\n",
      "\n",
      "Epoch 40/69\n",
      "----------\n",
      "train Loss: 1.1567 Acc: 0.5751\n",
      "val Loss: 1.1575 Acc: 0.6145\n",
      "Time taken is 572 seconds\n",
      "\n",
      "Epoch 41/69\n",
      "----------\n",
      "train Loss: 1.1576 Acc: 0.5811\n",
      "val Loss: 1.1357 Acc: 0.6521\n",
      "Time taken is 561 seconds\n",
      "\n",
      "Epoch 42/69\n",
      "----------\n",
      "train Loss: 1.1632 Acc: 0.6031\n",
      "val Loss: 1.1357 Acc: 0.6386\n",
      "Time taken is 534 seconds\n",
      "\n",
      "Epoch 43/69\n",
      "----------\n",
      "train Loss: 1.1412 Acc: 0.5936\n",
      "val Loss: 1.1397 Acc: 0.6396\n",
      "Time taken is 495 seconds\n",
      "\n",
      "Epoch 44/69\n",
      "----------\n",
      "train Loss: 1.1524 Acc: 0.5991\n",
      "val Loss: 1.1386 Acc: 0.6576\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 504 seconds\n",
      "\n",
      "Epoch 45/69\n",
      "----------\n",
      "train Loss: 1.1545 Acc: 0.6006\n",
      "val Loss: 1.1255 Acc: 0.6637\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 503 seconds\n",
      "\n",
      "Epoch 46/69\n",
      "----------\n",
      "train Loss: 1.1240 Acc: 0.6281\n",
      "val Loss: 1.1440 Acc: 0.6501\n",
      "Time taken is 502 seconds\n",
      "\n",
      "Epoch 47/69\n",
      "----------\n",
      "train Loss: 1.1352 Acc: 0.6281\n",
      "val Loss: 1.1329 Acc: 0.6321\n",
      "Time taken is 506 seconds\n",
      "\n",
      "Epoch 48/69\n",
      "----------\n",
      "train Loss: 1.1427 Acc: 0.6181\n",
      "val Loss: 1.1350 Acc: 0.6536\n",
      "Time taken is 498 seconds\n",
      "\n",
      "Epoch 49/69\n",
      "----------\n",
      "train Loss: 1.1507 Acc: 0.6056\n",
      "val Loss: 1.1336 Acc: 0.6541\n",
      "Time taken is 502 seconds\n",
      "\n",
      "Epoch 50/69\n",
      "----------\n",
      "train Loss: 1.1539 Acc: 0.6046\n",
      "val Loss: 1.1353 Acc: 0.6501\n",
      "Time taken is 499 seconds\n",
      "\n",
      "Epoch 51/69\n",
      "----------\n",
      "train Loss: 1.1488 Acc: 0.6076\n",
      "val Loss: 1.1278 Acc: 0.6697\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 504 seconds\n",
      "\n",
      "Epoch 52/69\n",
      "----------\n",
      "train Loss: 1.1451 Acc: 0.6386\n",
      "val Loss: 1.1301 Acc: 0.6742\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 510 seconds\n",
      "\n",
      "Epoch 53/69\n",
      "----------\n",
      "train Loss: 1.1406 Acc: 0.6416\n",
      "val Loss: 1.1385 Acc: 0.6471\n",
      "Time taken is 502 seconds\n",
      "\n",
      "Epoch 54/69\n",
      "----------\n",
      "train Loss: 1.1369 Acc: 0.6336\n",
      "val Loss: 1.1246 Acc: 0.6682\n",
      "Time taken is 507 seconds\n",
      "\n",
      "Epoch 55/69\n",
      "----------\n",
      "train Loss: 1.1451 Acc: 0.6176\n",
      "val Loss: 1.1263 Acc: 0.6662\n",
      "Time taken is 512 seconds\n",
      "\n",
      "Epoch 56/69\n",
      "----------\n",
      "train Loss: 1.1275 Acc: 0.6592\n",
      "val Loss: 1.1399 Acc: 0.6632\n",
      "Time taken is 508 seconds\n",
      "\n",
      "Epoch 57/69\n",
      "----------\n",
      "train Loss: 1.1245 Acc: 0.6461\n",
      "val Loss: 1.1285 Acc: 0.6366\n",
      "Time taken is 499 seconds\n",
      "\n",
      "Epoch 58/69\n",
      "----------\n",
      "train Loss: 1.1472 Acc: 0.6266\n",
      "val Loss: 1.1321 Acc: 0.6506\n",
      "Time taken is 502 seconds\n",
      "\n",
      "Epoch 59/69\n",
      "----------\n",
      "train Loss: 1.1449 Acc: 0.6376\n",
      "val Loss: 1.1314 Acc: 0.6742\n",
      "Time taken is 504 seconds\n",
      "\n",
      "Epoch 60/69\n",
      "----------\n",
      "train Loss: 1.1396 Acc: 0.6512\n",
      "val Loss: 1.1370 Acc: 0.6576\n",
      "Time taken is 505 seconds\n",
      "\n",
      "Epoch 61/69\n",
      "----------\n",
      "train Loss: 1.1333 Acc: 0.6512\n",
      "val Loss: 1.1620 Acc: 0.6647\n",
      "Time taken is 497 seconds\n",
      "\n",
      "Epoch 62/69\n",
      "----------\n",
      "train Loss: 1.1343 Acc: 0.6657\n",
      "val Loss: 1.1266 Acc: 0.6702\n",
      "Time taken is 494 seconds\n",
      "\n",
      "Epoch 63/69\n",
      "----------\n",
      "train Loss: 1.1330 Acc: 0.6802\n",
      "val Loss: 1.1429 Acc: 0.6622\n",
      "Time taken is 495 seconds\n",
      "\n",
      "Epoch 64/69\n",
      "----------\n",
      "train Loss: 1.1414 Acc: 0.6236\n",
      "val Loss: 1.1337 Acc: 0.6747\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 498 seconds\n",
      "\n",
      "Epoch 65/69\n",
      "----------\n",
      "train Loss: 1.1394 Acc: 0.6537\n",
      "val Loss: 1.1440 Acc: 0.6727\n",
      "Time taken is 513 seconds\n",
      "\n",
      "Epoch 66/69\n",
      "----------\n",
      "train Loss: 1.1319 Acc: 0.6657\n",
      "val Loss: 1.1344 Acc: 0.6612\n",
      "Time taken is 510 seconds\n",
      "\n",
      "Epoch 67/69\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.1246 Acc: 0.6612\n",
      "val Loss: 1.1272 Acc: 0.6762\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 512 seconds\n",
      "\n",
      "Epoch 68/69\n",
      "----------\n",
      "train Loss: 1.1306 Acc: 0.6617\n",
      "val Loss: 1.1326 Acc: 0.6887\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 509 seconds\n",
      "\n",
      "Epoch 69/69\n",
      "----------\n",
      "train Loss: 1.1200 Acc: 0.6727\n",
      "val Loss: 1.1354 Acc: 0.6647\n",
      "Time taken is 507 seconds\n",
      "\n",
      "Training complete in 586m 7s\n",
      "Best val Acc: 0.688722\n"
     ]
    }
   ],
   "source": [
    "### Train\n",
    "\n",
    "epochs = 70\n",
    "# epochs = 50\n",
    "\n",
    "model_ft = MultiSiameseContrastiveClassifierNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr = 0.0001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# learning_rate_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "learning_rate_scheduler = lr_scheduler.CyclicLR(optimizer_ft, base_lr=0.0001, max_lr=0.001, cycle_momentum=False)   # 0.001 seems better\n",
    "\n",
    "\n",
    "### Train \n",
    "\n",
    "# Logger\n",
    "model_save_folder = os.path.join(models_folder, \"contrastive_encoder\")\n",
    "log_handler = ModelSaveAndLogHandler(model_save_folder, enable_model_saving=True, enable_logging=True)   # init\n",
    "model_def_src_file_path = os.path.join(r\"D:\\Desktop\\projects\\speaker_recognition_voxceleb1\\scripts\", \"model_definitions.py\")\n",
    "log_handler.save_model_definition_file(model_def_src_file_path)   # copy model def file\n",
    "print(log_handler.folder)\n",
    "\n",
    "# Description\n",
    "log_handler.print(\"Description: Candidates: 5, Encoding: 128, Projection: None\")\n",
    "log_handler.print(\"Base Model: densenet121\")\n",
    "\n",
    "# Train\n",
    "# train_model(model_ft, criterion, optimizer_ft, learning_rate_scheduler, epochs, num_batches, training_data_generator, log_handler)\n",
    "train_model(model_ft, criterion, optimizer_ft, learning_rate_scheduler, epochs, training_data_generator, validation_data, log_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_acc = 1 / CANDIDATE_SIZE\n",
    "random_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Overall\n",
    "* Contrastive classifier\n",
    "    * separate train and validate methods\n",
    "\n",
    "* (Done) Model saving / checkpointing\n",
    "* **Build binary classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
