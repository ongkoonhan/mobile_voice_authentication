{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from config import models_folder, output_data_folder\n",
    "from config import n_mels\n",
    "\n",
    "from model_definitions import SpectrogramEncoderNet, MultiSiameseContrastiveClassifierNet\n",
    "from data_generators import ContrastiveDataGenerator, BaseDataGenerator\n",
    "from project_utils import ModelSaveAndLogHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = n_mels\n",
    "CANDIDATE_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mobile net\n",
    "# model = models.mobilenet_v2(pretrained=False)\n",
    "# # Dense net\n",
    "# model = models.densenet121(pretrained=False)\n",
    "# summary(model, input_size=(3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mobile net classifier\n",
    "# model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             864\n",
      "       BatchNorm2d-2           [-1, 32, 64, 64]              64\n",
      "             ReLU6-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]             288\n",
      "       BatchNorm2d-5           [-1, 32, 64, 64]              64\n",
      "             ReLU6-6           [-1, 32, 64, 64]               0\n",
      "            Conv2d-7           [-1, 16, 64, 64]             512\n",
      "       BatchNorm2d-8           [-1, 16, 64, 64]              32\n",
      "  InvertedResidual-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 96, 64, 64]           1,536\n",
      "      BatchNorm2d-11           [-1, 96, 64, 64]             192\n",
      "            ReLU6-12           [-1, 96, 64, 64]               0\n",
      "           Conv2d-13           [-1, 96, 32, 32]             864\n",
      "      BatchNorm2d-14           [-1, 96, 32, 32]             192\n",
      "            ReLU6-15           [-1, 96, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 32, 32]             288\n",
      "            ReLU6-21          [-1, 144, 32, 32]               0\n",
      "           Conv2d-22          [-1, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 32, 32]             288\n",
      "            ReLU6-24          [-1, 144, 32, 32]               0\n",
      "           Conv2d-25           [-1, 24, 32, 32]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-27           [-1, 24, 32, 32]               0\n",
      "           Conv2d-28          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 32, 32]             288\n",
      "            ReLU6-30          [-1, 144, 32, 32]               0\n",
      "           Conv2d-31          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 16, 16]             288\n",
      "            ReLU6-33          [-1, 144, 16, 16]               0\n",
      "           Conv2d-34           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-36           [-1, 32, 16, 16]               0\n",
      "           Conv2d-37          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 16, 16]             384\n",
      "            ReLU6-39          [-1, 192, 16, 16]               0\n",
      "           Conv2d-40          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 16, 16]             384\n",
      "            ReLU6-42          [-1, 192, 16, 16]               0\n",
      "           Conv2d-43           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-45           [-1, 32, 16, 16]               0\n",
      "           Conv2d-46          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 16, 16]             384\n",
      "            ReLU6-48          [-1, 192, 16, 16]               0\n",
      "           Conv2d-49          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 16, 16]             384\n",
      "            ReLU6-51          [-1, 192, 16, 16]               0\n",
      "           Conv2d-52           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 16, 16]             384\n",
      "            ReLU6-57          [-1, 192, 16, 16]               0\n",
      "           Conv2d-58            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-59            [-1, 192, 8, 8]             384\n",
      "            ReLU6-60            [-1, 192, 8, 8]               0\n",
      "           Conv2d-61             [-1, 64, 8, 8]          12,288\n",
      "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-63             [-1, 64, 8, 8]               0\n",
      "           Conv2d-64            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-65            [-1, 384, 8, 8]             768\n",
      "            ReLU6-66            [-1, 384, 8, 8]               0\n",
      "           Conv2d-67            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-68            [-1, 384, 8, 8]             768\n",
      "            ReLU6-69            [-1, 384, 8, 8]               0\n",
      "           Conv2d-70             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-71             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-72             [-1, 64, 8, 8]               0\n",
      "           Conv2d-73            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-74            [-1, 384, 8, 8]             768\n",
      "            ReLU6-75            [-1, 384, 8, 8]               0\n",
      "           Conv2d-76            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-77            [-1, 384, 8, 8]             768\n",
      "            ReLU6-78            [-1, 384, 8, 8]               0\n",
      "           Conv2d-79             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-81             [-1, 64, 8, 8]               0\n",
      "           Conv2d-82            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-83            [-1, 384, 8, 8]             768\n",
      "            ReLU6-84            [-1, 384, 8, 8]               0\n",
      "           Conv2d-85            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-86            [-1, 384, 8, 8]             768\n",
      "            ReLU6-87            [-1, 384, 8, 8]               0\n",
      "           Conv2d-88             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-90             [-1, 64, 8, 8]               0\n",
      "           Conv2d-91            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-92            [-1, 384, 8, 8]             768\n",
      "            ReLU6-93            [-1, 384, 8, 8]               0\n",
      "           Conv2d-94            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-95            [-1, 384, 8, 8]             768\n",
      "            ReLU6-96            [-1, 384, 8, 8]               0\n",
      "           Conv2d-97             [-1, 96, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 96, 8, 8]             192\n",
      " InvertedResidual-99             [-1, 96, 8, 8]               0\n",
      "          Conv2d-100            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-101            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-102            [-1, 576, 8, 8]               0\n",
      "          Conv2d-103            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-104            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-105            [-1, 576, 8, 8]               0\n",
      "          Conv2d-106             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-107             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-108             [-1, 96, 8, 8]               0\n",
      "          Conv2d-109            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-110            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-111            [-1, 576, 8, 8]               0\n",
      "          Conv2d-112            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-113            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-114            [-1, 576, 8, 8]               0\n",
      "          Conv2d-115             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-116             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-117             [-1, 96, 8, 8]               0\n",
      "          Conv2d-118            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-119            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-120            [-1, 576, 8, 8]               0\n",
      "          Conv2d-121            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-123            [-1, 576, 4, 4]               0\n",
      "          Conv2d-124            [-1, 160, 4, 4]          92,160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-125            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-126            [-1, 160, 4, 4]               0\n",
      "          Conv2d-127            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-129            [-1, 960, 4, 4]               0\n",
      "          Conv2d-130            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-132            [-1, 960, 4, 4]               0\n",
      "          Conv2d-133            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-135            [-1, 160, 4, 4]               0\n",
      "          Conv2d-136            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-138            [-1, 960, 4, 4]               0\n",
      "          Conv2d-139            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-141            [-1, 960, 4, 4]               0\n",
      "          Conv2d-142            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-144            [-1, 160, 4, 4]               0\n",
      "          Conv2d-145            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-147            [-1, 960, 4, 4]               0\n",
      "          Conv2d-148            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-150            [-1, 960, 4, 4]               0\n",
      "          Conv2d-151            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-153            [-1, 320, 4, 4]               0\n",
      "          Conv2d-154           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-156           [-1, 1280, 4, 4]               0\n",
      "          Linear-157                  [-1, 128]         163,968\n",
      "     MobileNetV2-158                  [-1, 128]               0\n",
      "================================================================\n",
      "Total params: 2,387,840\n",
      "Trainable params: 2,387,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 49.91\n",
      "Params size (MB): 9.11\n",
      "Estimated Total Size (MB): 59.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(SpectrogramEncoderNet(), input_size=(3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             864\n",
      "       BatchNorm2d-2           [-1, 32, 64, 64]              64\n",
      "             ReLU6-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]             288\n",
      "       BatchNorm2d-5           [-1, 32, 64, 64]              64\n",
      "             ReLU6-6           [-1, 32, 64, 64]               0\n",
      "            Conv2d-7           [-1, 16, 64, 64]             512\n",
      "       BatchNorm2d-8           [-1, 16, 64, 64]              32\n",
      "  InvertedResidual-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 96, 64, 64]           1,536\n",
      "      BatchNorm2d-11           [-1, 96, 64, 64]             192\n",
      "            ReLU6-12           [-1, 96, 64, 64]               0\n",
      "           Conv2d-13           [-1, 96, 32, 32]             864\n",
      "      BatchNorm2d-14           [-1, 96, 32, 32]             192\n",
      "            ReLU6-15           [-1, 96, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 32, 32]             288\n",
      "            ReLU6-21          [-1, 144, 32, 32]               0\n",
      "           Conv2d-22          [-1, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 32, 32]             288\n",
      "            ReLU6-24          [-1, 144, 32, 32]               0\n",
      "           Conv2d-25           [-1, 24, 32, 32]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-27           [-1, 24, 32, 32]               0\n",
      "           Conv2d-28          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 32, 32]             288\n",
      "            ReLU6-30          [-1, 144, 32, 32]               0\n",
      "           Conv2d-31          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 16, 16]             288\n",
      "            ReLU6-33          [-1, 144, 16, 16]               0\n",
      "           Conv2d-34           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-36           [-1, 32, 16, 16]               0\n",
      "           Conv2d-37          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 16, 16]             384\n",
      "            ReLU6-39          [-1, 192, 16, 16]               0\n",
      "           Conv2d-40          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 16, 16]             384\n",
      "            ReLU6-42          [-1, 192, 16, 16]               0\n",
      "           Conv2d-43           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-45           [-1, 32, 16, 16]               0\n",
      "           Conv2d-46          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 16, 16]             384\n",
      "            ReLU6-48          [-1, 192, 16, 16]               0\n",
      "           Conv2d-49          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 16, 16]             384\n",
      "            ReLU6-51          [-1, 192, 16, 16]               0\n",
      "           Conv2d-52           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 16, 16]             384\n",
      "            ReLU6-57          [-1, 192, 16, 16]               0\n",
      "           Conv2d-58            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-59            [-1, 192, 8, 8]             384\n",
      "            ReLU6-60            [-1, 192, 8, 8]               0\n",
      "           Conv2d-61             [-1, 64, 8, 8]          12,288\n",
      "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-63             [-1, 64, 8, 8]               0\n",
      "           Conv2d-64            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-65            [-1, 384, 8, 8]             768\n",
      "            ReLU6-66            [-1, 384, 8, 8]               0\n",
      "           Conv2d-67            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-68            [-1, 384, 8, 8]             768\n",
      "            ReLU6-69            [-1, 384, 8, 8]               0\n",
      "           Conv2d-70             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-71             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-72             [-1, 64, 8, 8]               0\n",
      "           Conv2d-73            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-74            [-1, 384, 8, 8]             768\n",
      "            ReLU6-75            [-1, 384, 8, 8]               0\n",
      "           Conv2d-76            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-77            [-1, 384, 8, 8]             768\n",
      "            ReLU6-78            [-1, 384, 8, 8]               0\n",
      "           Conv2d-79             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-81             [-1, 64, 8, 8]               0\n",
      "           Conv2d-82            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-83            [-1, 384, 8, 8]             768\n",
      "            ReLU6-84            [-1, 384, 8, 8]               0\n",
      "           Conv2d-85            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-86            [-1, 384, 8, 8]             768\n",
      "            ReLU6-87            [-1, 384, 8, 8]               0\n",
      "           Conv2d-88             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-90             [-1, 64, 8, 8]               0\n",
      "           Conv2d-91            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-92            [-1, 384, 8, 8]             768\n",
      "            ReLU6-93            [-1, 384, 8, 8]               0\n",
      "           Conv2d-94            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-95            [-1, 384, 8, 8]             768\n",
      "            ReLU6-96            [-1, 384, 8, 8]               0\n",
      "           Conv2d-97             [-1, 96, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 96, 8, 8]             192\n",
      " InvertedResidual-99             [-1, 96, 8, 8]               0\n",
      "          Conv2d-100            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-101            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-102            [-1, 576, 8, 8]               0\n",
      "          Conv2d-103            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-104            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-105            [-1, 576, 8, 8]               0\n",
      "          Conv2d-106             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-107             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-108             [-1, 96, 8, 8]               0\n",
      "          Conv2d-109            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-110            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-111            [-1, 576, 8, 8]               0\n",
      "          Conv2d-112            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-113            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-114            [-1, 576, 8, 8]               0\n",
      "          Conv2d-115             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-116             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-117             [-1, 96, 8, 8]               0\n",
      "          Conv2d-118            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-119            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-120            [-1, 576, 8, 8]               0\n",
      "          Conv2d-121            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-123            [-1, 576, 4, 4]               0\n",
      "          Conv2d-124            [-1, 160, 4, 4]          92,160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-125            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-126            [-1, 160, 4, 4]               0\n",
      "          Conv2d-127            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-129            [-1, 960, 4, 4]               0\n",
      "          Conv2d-130            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-132            [-1, 960, 4, 4]               0\n",
      "          Conv2d-133            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-135            [-1, 160, 4, 4]               0\n",
      "          Conv2d-136            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-138            [-1, 960, 4, 4]               0\n",
      "          Conv2d-139            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-141            [-1, 960, 4, 4]               0\n",
      "          Conv2d-142            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-144            [-1, 160, 4, 4]               0\n",
      "          Conv2d-145            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-147            [-1, 960, 4, 4]               0\n",
      "          Conv2d-148            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-150            [-1, 960, 4, 4]               0\n",
      "          Conv2d-151            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-153            [-1, 320, 4, 4]               0\n",
      "          Conv2d-154           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-156           [-1, 1280, 4, 4]               0\n",
      "          Linear-157                  [-1, 128]         163,968\n",
      "     MobileNetV2-158                  [-1, 128]               0\n",
      "SpectrogramEncoderNet-159                  [-1, 128]               0\n",
      "        Identity-160                  [-1, 128]               0\n",
      "          Conv2d-161           [-1, 32, 64, 64]             864\n",
      "     BatchNorm2d-162           [-1, 32, 64, 64]              64\n",
      "           ReLU6-163           [-1, 32, 64, 64]               0\n",
      "          Conv2d-164           [-1, 32, 64, 64]             288\n",
      "     BatchNorm2d-165           [-1, 32, 64, 64]              64\n",
      "           ReLU6-166           [-1, 32, 64, 64]               0\n",
      "          Conv2d-167           [-1, 16, 64, 64]             512\n",
      "     BatchNorm2d-168           [-1, 16, 64, 64]              32\n",
      "InvertedResidual-169           [-1, 16, 64, 64]               0\n",
      "          Conv2d-170           [-1, 96, 64, 64]           1,536\n",
      "     BatchNorm2d-171           [-1, 96, 64, 64]             192\n",
      "           ReLU6-172           [-1, 96, 64, 64]               0\n",
      "          Conv2d-173           [-1, 96, 32, 32]             864\n",
      "     BatchNorm2d-174           [-1, 96, 32, 32]             192\n",
      "           ReLU6-175           [-1, 96, 32, 32]               0\n",
      "          Conv2d-176           [-1, 24, 32, 32]           2,304\n",
      "     BatchNorm2d-177           [-1, 24, 32, 32]              48\n",
      "InvertedResidual-178           [-1, 24, 32, 32]               0\n",
      "          Conv2d-179          [-1, 144, 32, 32]           3,456\n",
      "     BatchNorm2d-180          [-1, 144, 32, 32]             288\n",
      "           ReLU6-181          [-1, 144, 32, 32]               0\n",
      "          Conv2d-182          [-1, 144, 32, 32]           1,296\n",
      "     BatchNorm2d-183          [-1, 144, 32, 32]             288\n",
      "           ReLU6-184          [-1, 144, 32, 32]               0\n",
      "          Conv2d-185           [-1, 24, 32, 32]           3,456\n",
      "     BatchNorm2d-186           [-1, 24, 32, 32]              48\n",
      "InvertedResidual-187           [-1, 24, 32, 32]               0\n",
      "          Conv2d-188          [-1, 144, 32, 32]           3,456\n",
      "     BatchNorm2d-189          [-1, 144, 32, 32]             288\n",
      "           ReLU6-190          [-1, 144, 32, 32]               0\n",
      "          Conv2d-191          [-1, 144, 16, 16]           1,296\n",
      "     BatchNorm2d-192          [-1, 144, 16, 16]             288\n",
      "           ReLU6-193          [-1, 144, 16, 16]               0\n",
      "          Conv2d-194           [-1, 32, 16, 16]           4,608\n",
      "     BatchNorm2d-195           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-196           [-1, 32, 16, 16]               0\n",
      "          Conv2d-197          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-198          [-1, 192, 16, 16]             384\n",
      "           ReLU6-199          [-1, 192, 16, 16]               0\n",
      "          Conv2d-200          [-1, 192, 16, 16]           1,728\n",
      "     BatchNorm2d-201          [-1, 192, 16, 16]             384\n",
      "           ReLU6-202          [-1, 192, 16, 16]               0\n",
      "          Conv2d-203           [-1, 32, 16, 16]           6,144\n",
      "     BatchNorm2d-204           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-205           [-1, 32, 16, 16]               0\n",
      "          Conv2d-206          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-207          [-1, 192, 16, 16]             384\n",
      "           ReLU6-208          [-1, 192, 16, 16]               0\n",
      "          Conv2d-209          [-1, 192, 16, 16]           1,728\n",
      "     BatchNorm2d-210          [-1, 192, 16, 16]             384\n",
      "           ReLU6-211          [-1, 192, 16, 16]               0\n",
      "          Conv2d-212           [-1, 32, 16, 16]           6,144\n",
      "     BatchNorm2d-213           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-214           [-1, 32, 16, 16]               0\n",
      "          Conv2d-215          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-216          [-1, 192, 16, 16]             384\n",
      "           ReLU6-217          [-1, 192, 16, 16]               0\n",
      "          Conv2d-218            [-1, 192, 8, 8]           1,728\n",
      "     BatchNorm2d-219            [-1, 192, 8, 8]             384\n",
      "           ReLU6-220            [-1, 192, 8, 8]               0\n",
      "          Conv2d-221             [-1, 64, 8, 8]          12,288\n",
      "     BatchNorm2d-222             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-223             [-1, 64, 8, 8]               0\n",
      "          Conv2d-224            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-225            [-1, 384, 8, 8]             768\n",
      "           ReLU6-226            [-1, 384, 8, 8]               0\n",
      "          Conv2d-227            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-228            [-1, 384, 8, 8]             768\n",
      "           ReLU6-229            [-1, 384, 8, 8]               0\n",
      "          Conv2d-230             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-231             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-232             [-1, 64, 8, 8]               0\n",
      "          Conv2d-233            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-234            [-1, 384, 8, 8]             768\n",
      "           ReLU6-235            [-1, 384, 8, 8]               0\n",
      "          Conv2d-236            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-237            [-1, 384, 8, 8]             768\n",
      "           ReLU6-238            [-1, 384, 8, 8]               0\n",
      "          Conv2d-239             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-240             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-241             [-1, 64, 8, 8]               0\n",
      "          Conv2d-242            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-243            [-1, 384, 8, 8]             768\n",
      "           ReLU6-244            [-1, 384, 8, 8]               0\n",
      "          Conv2d-245            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-246            [-1, 384, 8, 8]             768\n",
      "           ReLU6-247            [-1, 384, 8, 8]               0\n",
      "          Conv2d-248             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-249             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-250             [-1, 64, 8, 8]               0\n",
      "          Conv2d-251            [-1, 384, 8, 8]          24,576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-252            [-1, 384, 8, 8]             768\n",
      "           ReLU6-253            [-1, 384, 8, 8]               0\n",
      "          Conv2d-254            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-255            [-1, 384, 8, 8]             768\n",
      "           ReLU6-256            [-1, 384, 8, 8]               0\n",
      "          Conv2d-257             [-1, 96, 8, 8]          36,864\n",
      "     BatchNorm2d-258             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-259             [-1, 96, 8, 8]               0\n",
      "          Conv2d-260            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-261            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-262            [-1, 576, 8, 8]               0\n",
      "          Conv2d-263            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-264            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-265            [-1, 576, 8, 8]               0\n",
      "          Conv2d-266             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-267             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-268             [-1, 96, 8, 8]               0\n",
      "          Conv2d-269            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-270            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-271            [-1, 576, 8, 8]               0\n",
      "          Conv2d-272            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-273            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-274            [-1, 576, 8, 8]               0\n",
      "          Conv2d-275             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-276             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-277             [-1, 96, 8, 8]               0\n",
      "          Conv2d-278            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-279            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-280            [-1, 576, 8, 8]               0\n",
      "          Conv2d-281            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-282            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-283            [-1, 576, 4, 4]               0\n",
      "          Conv2d-284            [-1, 160, 4, 4]          92,160\n",
      "     BatchNorm2d-285            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-286            [-1, 160, 4, 4]               0\n",
      "          Conv2d-287            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-288            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-289            [-1, 960, 4, 4]               0\n",
      "          Conv2d-290            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-291            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-292            [-1, 960, 4, 4]               0\n",
      "          Conv2d-293            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-294            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-295            [-1, 160, 4, 4]               0\n",
      "          Conv2d-296            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-297            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-298            [-1, 960, 4, 4]               0\n",
      "          Conv2d-299            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-300            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-301            [-1, 960, 4, 4]               0\n",
      "          Conv2d-302            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-303            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-304            [-1, 160, 4, 4]               0\n",
      "          Conv2d-305            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-306            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-307            [-1, 960, 4, 4]               0\n",
      "          Conv2d-308            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-309            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-310            [-1, 960, 4, 4]               0\n",
      "          Conv2d-311            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-312            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-313            [-1, 320, 4, 4]               0\n",
      "          Conv2d-314           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-315           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-316           [-1, 1280, 4, 4]               0\n",
      "          Linear-317                  [-1, 128]         163,968\n",
      "     MobileNetV2-318                  [-1, 128]               0\n",
      "SpectrogramEncoderNet-319                  [-1, 128]               0\n",
      "        Identity-320                  [-1, 128]               0\n",
      "================================================================\n",
      "Total params: 4,775,680\n",
      "Trainable params: 4,775,680\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.12\n",
      "Forward/backward pass size (MB): 99.83\n",
      "Params size (MB): 18.22\n",
      "Estimated Total Size (MB): 119.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(MultiSiameseContrastiveClassifierNet(), input_size=(CANDIDATE_SIZE+1, 3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training data\n",
    "training_folder = os.path.join(output_data_folder, \"training_dataset_full_spectrogram/vox1_dev_wav\")\n",
    "spectrogram_samples_files = [os.path.join(training_folder, file) for file in os.listdir(training_folder)]\n",
    "candidate_size = CANDIDATE_SIZE\n",
    "batch_size = 15   # mobilenet_v2\n",
    "# batch_size = 6   # densenet121\n",
    "num_batches = 2000 // batch_size\n",
    "# num_batches = 60 // batch_size\n",
    "num_sub_samples = 200\n",
    "# num_sub_samples = 70\n",
    "training_data_generator = ContrastiveDataGenerator(spectrogram_samples_files, candidate_size, batch_size, num_batches, num_sub_samples, IMG_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validation data\n",
    "validation_set_file = os.path.join(output_data_folder, \"validation_sets\", \"contrastive_validation_set.pickle\")\n",
    "with open(validation_set_file, 'rb') as f:\n",
    "    validation_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intra_class_variance_reduction(contrastive_model, contrastive_sub_samples, log_handler):   \n",
    "    num_classes = 5\n",
    "    samples_per_class = 10\n",
    "    \n",
    "    # prep for training\n",
    "    criterion = nn.MSELoss(reduction='mean')\n",
    "#     criterion = nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    # train\n",
    "    total_loss = 0.0\n",
    "    spectrogram_sub_samples = random.sample(contrastive_sub_samples, num_classes)  # sample classes\n",
    "    for spectrogram in spectrogram_sub_samples:   # treat one spectrogram/user as one class\n",
    "        input_imgs = [BaseDataGenerator.get_sliding_img_slice_from_spectrogram(spectrogram) for _ in range(samples_per_class)]\n",
    "        input_imgs = torch.tensor(input_imgs)\n",
    "        inputs = input_imgs.to(device)  \n",
    "        \n",
    "        encoded_outputs = contrastive_model.encoder(inputs)\n",
    "        mean = torch.mean(encoded_outputs, dim=0)   # get mean encoding vector of this class\n",
    "        mean = mean.repeat(samples_per_class, 1)   # mean vector\n",
    "        loss = criterion(encoded_outputs, mean)   # MSE against mean (variance)\n",
    "        total_loss += loss\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, training_data_generator, validation_data, log_handler):\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    # intra class variance reduction \n",
    "    run_variance_reduction_on_epoch = [*range(1, num_epochs)]\n",
    "#     run_variance_reduction_on_epoch = [*range(1, num_epochs, 2)]   # alternate\n",
    "    variance_reduction_frequency = 2   # every n batches\n",
    "#     loss_variance_scale = 0.20\n",
    "    loss_variance_scale = 1.0\n",
    "\n",
    "    t1 = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        log_handler.print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        log_handler.print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            \n",
    "            # intra class variance reduction\n",
    "            run_variance_reduction = phase == 'train' and epoch in run_variance_reduction_on_epoch\n",
    "            if run_variance_reduction: log_handler.print(\"-- variance reduction\")\n",
    "            \n",
    "            # Main training (contrastive training)\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Iterate over data.\n",
    "            batches_used = 0\n",
    "            data_generator = training_data_generator.generate_batches() if phase == 'train' else validation_data\n",
    "            for data in data_generator:\n",
    "                batches_used += 1                \n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):   # gradient only for train\n",
    "                    \n",
    "                    # intra class variance reduction\n",
    "                    loss_var = None\n",
    "                    if batches_used % variance_reduction_frequency == 0 and run_variance_reduction:\n",
    "                        loss_var = intra_class_variance_reduction(model, training_data_generator.sub_samples, log_handler)\n",
    "                        loss_var *= loss_variance_scale\n",
    "                        loss_var.backward()\n",
    "                    \n",
    "                    # Main training (contrastive training)\n",
    "                    input_imgs, labels = data\n",
    "                    inputs = [img.to(device) for img in input_imgs]\n",
    "                    labels = labels.to(device)\n",
    "                    \n",
    "                    outputs = model(inputs)      \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                if loss_var is not None: loss += loss_var   # Overall loss with variance reduction\n",
    "                running_loss += loss.item() * inputs[0].size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            epoch_loss = running_loss / (batches_used * inputs[0].size(0))\n",
    "            epoch_acc = running_corrects.double() / (batches_used * inputs[0].size(0))\n",
    "            log_handler.print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc and epoch > 0:\n",
    "                best_acc = epoch_acc\n",
    "                log_handler.save_pytorch_model(model, \"best_model_{}.pt\".format(model.__class__.__name__))\n",
    "                example = [torch.rand(1, 3, IMG_HEIGHT, IMG_HEIGHT), torch.rand(1, 3, IMG_HEIGHT, IMG_HEIGHT)]\n",
    "                log_handler.save_pytorch_model_as_torchscript(model, \"mobile_model.pt\", (example,))\n",
    "\n",
    "        # end of epoch\n",
    "        log_handler.print(\"Time taken is {} seconds\".format(int(time.time()-t1)))\n",
    "        t1 = time.time()\n",
    "        log_handler.print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    log_handler.print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    log_handler.print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Desktop\\projects\\speaker_recognition_voxceleb1\\output_data\\models\\contrastive_encoder\\2020-04-08_02-37-55\n",
      "Description: Candidates: 5, Encoding: 128, Projection: None\n",
      "Base Model: mobileNetV2\n",
      "With Intra Class Variance Reduction\n",
      "Epoch 0/69\n",
      "----------\n",
      "train Loss: 1.5229 Acc: 0.2962\n",
      "val Loss: 1.4878 Acc: 0.3253\n",
      "Time taken is 205 seconds\n",
      "\n",
      "Epoch 1/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.5531 Acc: 0.3143\n",
      "val Loss: 1.4971 Acc: 0.3368\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 258 seconds\n",
      "\n",
      "Epoch 2/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.5168 Acc: 0.3434\n",
      "val Loss: 1.4521 Acc: 0.3459\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 260 seconds\n",
      "\n",
      "Epoch 3/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.5327 Acc: 0.3268\n",
      "val Loss: 1.4436 Acc: 0.3679\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 260 seconds\n",
      "\n",
      "Epoch 4/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4882 Acc: 0.3539\n",
      "val Loss: 1.4430 Acc: 0.3554\n",
      "Time taken is 253 seconds\n",
      "\n",
      "Epoch 5/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4998 Acc: 0.3263\n",
      "val Loss: 1.4219 Acc: 0.3699\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 253 seconds\n",
      "\n",
      "Epoch 6/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4806 Acc: 0.3489\n",
      "val Loss: 1.3986 Acc: 0.4015\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 259 seconds\n",
      "\n",
      "Epoch 7/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4571 Acc: 0.3850\n",
      "val Loss: 1.3785 Acc: 0.4030\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 258 seconds\n",
      "\n",
      "Epoch 8/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4308 Acc: 0.3764\n",
      "val Loss: 1.3682 Acc: 0.4170\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 262 seconds\n",
      "\n",
      "Epoch 9/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4195 Acc: 0.4075\n",
      "val Loss: 1.3575 Acc: 0.4491\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 266 seconds\n",
      "\n",
      "Epoch 10/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4211 Acc: 0.4050\n",
      "val Loss: 1.3855 Acc: 0.4025\n",
      "Time taken is 258 seconds\n",
      "\n",
      "Epoch 11/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4161 Acc: 0.4010\n",
      "val Loss: 1.3595 Acc: 0.4251\n",
      "Time taken is 249 seconds\n",
      "\n",
      "Epoch 12/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4039 Acc: 0.4060\n",
      "val Loss: 1.3463 Acc: 0.4261\n",
      "Time taken is 255 seconds\n",
      "\n",
      "Epoch 13/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3942 Acc: 0.4115\n",
      "val Loss: 1.3491 Acc: 0.4296\n",
      "Time taken is 252 seconds\n",
      "\n",
      "Epoch 14/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3911 Acc: 0.4206\n",
      "val Loss: 1.3523 Acc: 0.4321\n",
      "Time taken is 246 seconds\n",
      "\n",
      "Epoch 15/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3997 Acc: 0.4045\n",
      "val Loss: 1.3708 Acc: 0.4226\n",
      "Time taken is 233 seconds\n",
      "\n",
      "Epoch 16/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4079 Acc: 0.3970\n",
      "val Loss: 1.3630 Acc: 0.4216\n",
      "Time taken is 233 seconds\n",
      "\n",
      "Epoch 17/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4371 Acc: 0.4025\n",
      "val Loss: 1.3453 Acc: 0.4316\n",
      "Time taken is 225 seconds\n",
      "\n",
      "Epoch 18/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3906 Acc: 0.4150\n",
      "val Loss: 1.3794 Acc: 0.4276\n",
      "Time taken is 226 seconds\n",
      "\n",
      "Epoch 19/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3908 Acc: 0.4120\n",
      "val Loss: 1.3352 Acc: 0.4441\n",
      "Time taken is 225 seconds\n",
      "\n",
      "Epoch 20/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3777 Acc: 0.4140\n",
      "val Loss: 1.3424 Acc: 0.4316\n",
      "Time taken is 221 seconds\n",
      "\n",
      "Epoch 21/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3853 Acc: 0.4261\n",
      "val Loss: 1.3460 Acc: 0.4276\n",
      "Time taken is 216 seconds\n",
      "\n",
      "Epoch 22/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3896 Acc: 0.4090\n",
      "val Loss: 1.3415 Acc: 0.4201\n",
      "Time taken is 218 seconds\n",
      "\n",
      "Epoch 23/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3999 Acc: 0.3980\n",
      "val Loss: 1.3454 Acc: 0.4246\n",
      "Time taken is 216 seconds\n",
      "\n",
      "Epoch 24/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4105 Acc: 0.3855\n",
      "val Loss: 1.3553 Acc: 0.4311\n",
      "Time taken is 214 seconds\n",
      "\n",
      "Epoch 25/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3961 Acc: 0.4125\n",
      "val Loss: 1.3587 Acc: 0.4206\n",
      "Time taken is 208 seconds\n",
      "\n",
      "Epoch 26/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3967 Acc: 0.3960\n",
      "val Loss: 1.3535 Acc: 0.4421\n",
      "Time taken is 210 seconds\n",
      "\n",
      "Epoch 27/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4120 Acc: 0.3779\n",
      "val Loss: 1.3799 Acc: 0.4216\n",
      "Time taken is 212 seconds\n",
      "\n",
      "Epoch 28/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3904 Acc: 0.4190\n",
      "val Loss: 1.3414 Acc: 0.4351\n",
      "Time taken is 207 seconds\n",
      "\n",
      "Epoch 29/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3732 Acc: 0.4291\n",
      "val Loss: 1.3507 Acc: 0.4271\n",
      "Time taken is 211 seconds\n",
      "\n",
      "Epoch 30/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3962 Acc: 0.4175\n",
      "val Loss: 1.3573 Acc: 0.4221\n",
      "Time taken is 204 seconds\n",
      "\n",
      "Epoch 31/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3958 Acc: 0.4085\n",
      "val Loss: 1.3474 Acc: 0.4246\n",
      "Time taken is 211 seconds\n",
      "\n",
      "Epoch 32/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4032 Acc: 0.3995\n",
      "val Loss: 1.3382 Acc: 0.4291\n",
      "Time taken is 211 seconds\n",
      "\n",
      "Epoch 33/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4169 Acc: 0.3940\n",
      "val Loss: 1.3440 Acc: 0.4241\n",
      "Time taken is 212 seconds\n",
      "\n",
      "Epoch 34/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3861 Acc: 0.4005\n",
      "val Loss: 1.3489 Acc: 0.4296\n",
      "Time taken is 212 seconds\n",
      "\n",
      "Epoch 35/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3847 Acc: 0.4025\n",
      "val Loss: 1.3480 Acc: 0.4311\n",
      "Time taken is 212 seconds\n",
      "\n",
      "Epoch 36/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3764 Acc: 0.3950\n",
      "val Loss: 1.3516 Acc: 0.4316\n",
      "Time taken is 212 seconds\n",
      "\n",
      "Epoch 37/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4021 Acc: 0.4020\n",
      "val Loss: 1.3423 Acc: 0.4381\n",
      "Time taken is 211 seconds\n",
      "\n",
      "Epoch 38/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3976 Acc: 0.4261\n",
      "val Loss: 1.3476 Acc: 0.4261\n",
      "Time taken is 210 seconds\n",
      "\n",
      "Epoch 39/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3827 Acc: 0.4165\n",
      "val Loss: 1.3401 Acc: 0.4291\n",
      "Time taken is 208 seconds\n",
      "\n",
      "Epoch 40/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3687 Acc: 0.4231\n",
      "val Loss: 1.3498 Acc: 0.4296\n",
      "Time taken is 210 seconds\n",
      "\n",
      "Epoch 41/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3904 Acc: 0.4115\n",
      "val Loss: 1.3575 Acc: 0.4201\n",
      "Time taken is 209 seconds\n",
      "\n",
      "Epoch 42/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3685 Acc: 0.4211\n",
      "val Loss: 1.3502 Acc: 0.4306\n",
      "Time taken is 205 seconds\n",
      "\n",
      "Epoch 43/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3810 Acc: 0.4045\n",
      "val Loss: 1.3453 Acc: 0.4266\n",
      "Time taken is 210 seconds\n",
      "\n",
      "Epoch 44/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3872 Acc: 0.4281\n",
      "val Loss: 1.3485 Acc: 0.4211\n",
      "Time taken is 206 seconds\n",
      "\n",
      "Epoch 45/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3896 Acc: 0.4055\n",
      "val Loss: 1.3718 Acc: 0.4221\n",
      "Time taken is 210 seconds\n",
      "\n",
      "Epoch 46/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3922 Acc: 0.4226\n",
      "val Loss: 1.3478 Acc: 0.4341\n",
      "Time taken is 209 seconds\n",
      "\n",
      "Epoch 47/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3831 Acc: 0.4115\n",
      "val Loss: 1.3619 Acc: 0.4221\n",
      "Time taken is 211 seconds\n",
      "\n",
      "Epoch 48/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3921 Acc: 0.4010\n",
      "val Loss: 1.3528 Acc: 0.4331\n",
      "Time taken is 211 seconds\n",
      "\n",
      "Epoch 49/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3740 Acc: 0.4030\n",
      "val Loss: 1.3684 Acc: 0.4216\n",
      "Time taken is 213 seconds\n",
      "\n",
      "Epoch 50/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3840 Acc: 0.4010\n",
      "val Loss: 1.3545 Acc: 0.4201\n",
      "Time taken is 212 seconds\n",
      "\n",
      "Epoch 51/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3795 Acc: 0.4110\n",
      "val Loss: 1.3692 Acc: 0.4221\n",
      "Time taken is 210 seconds\n",
      "\n",
      "Epoch 52/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4189 Acc: 0.4015\n",
      "val Loss: 1.3638 Acc: 0.4206\n",
      "Time taken is 210 seconds\n",
      "\n",
      "Epoch 53/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4265 Acc: 0.3965\n",
      "val Loss: 1.3557 Acc: 0.4301\n",
      "Time taken is 210 seconds\n",
      "\n",
      "Epoch 54/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4416 Acc: 0.3679\n",
      "val Loss: 1.3714 Acc: 0.4195\n",
      "Time taken is 213 seconds\n",
      "\n",
      "Epoch 55/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4268 Acc: 0.3850\n",
      "val Loss: 1.3580 Acc: 0.4396\n",
      "Time taken is 208 seconds\n",
      "\n",
      "Epoch 56/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4136 Acc: 0.3870\n",
      "val Loss: 1.3473 Acc: 0.4356\n",
      "Time taken is 207 seconds\n",
      "\n",
      "Epoch 57/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3791 Acc: 0.4155\n",
      "val Loss: 1.3811 Acc: 0.4236\n",
      "Time taken is 211 seconds\n",
      "\n",
      "Epoch 58/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4026 Acc: 0.4155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.3577 Acc: 0.4331\n",
      "Time taken is 210 seconds\n",
      "\n",
      "Epoch 59/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3962 Acc: 0.4095\n",
      "val Loss: 1.3561 Acc: 0.4371\n",
      "Time taken is 211 seconds\n",
      "\n",
      "Epoch 60/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4031 Acc: 0.3930\n",
      "val Loss: 1.3511 Acc: 0.4195\n",
      "Time taken is 211 seconds\n",
      "\n",
      "Epoch 61/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3845 Acc: 0.4301\n",
      "val Loss: 1.3485 Acc: 0.4286\n",
      "Time taken is 211 seconds\n",
      "\n",
      "Epoch 62/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3815 Acc: 0.3990\n",
      "val Loss: 1.3575 Acc: 0.4326\n",
      "Time taken is 213 seconds\n",
      "\n",
      "Epoch 63/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3787 Acc: 0.3935\n",
      "val Loss: 1.3550 Acc: 0.4311\n",
      "Time taken is 214 seconds\n",
      "\n",
      "Epoch 64/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4076 Acc: 0.3990\n",
      "val Loss: 1.3676 Acc: 0.4321\n",
      "Time taken is 212 seconds\n",
      "\n",
      "Epoch 65/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3689 Acc: 0.4241\n",
      "val Loss: 1.3601 Acc: 0.4276\n",
      "Time taken is 214 seconds\n",
      "\n",
      "Epoch 66/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4044 Acc: 0.4005\n",
      "val Loss: 1.3470 Acc: 0.4276\n",
      "Time taken is 212 seconds\n",
      "\n",
      "Epoch 67/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4107 Acc: 0.3845\n",
      "val Loss: 1.3526 Acc: 0.4341\n",
      "Time taken is 213 seconds\n",
      "\n",
      "Epoch 68/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.4051 Acc: 0.3960\n",
      "val Loss: 1.3549 Acc: 0.4321\n",
      "Time taken is 211 seconds\n",
      "\n",
      "Epoch 69/69\n",
      "----------\n",
      "-- variance reduction\n",
      "train Loss: 1.3835 Acc: 0.4195\n",
      "val Loss: 1.3571 Acc: 0.4331\n",
      "Time taken is 216 seconds\n",
      "\n",
      "Training complete in 258m 54s\n",
      "Best val Acc: 0.449123\n"
     ]
    }
   ],
   "source": [
    "### Train\n",
    "\n",
    "epochs = 70\n",
    "# epochs = 50\n",
    "\n",
    "model_ft = MultiSiameseContrastiveClassifierNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr = 0.0001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# learning_rate_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "learning_rate_scheduler = lr_scheduler.CyclicLR(optimizer_ft, base_lr=0.0001, max_lr=0.001, cycle_momentum=False)   # 0.001 seems better\n",
    "\n",
    "\n",
    "### Train \n",
    "\n",
    "# Logger\n",
    "model_save_folder = os.path.join(models_folder, \"contrastive_encoder\")\n",
    "log_handler = ModelSaveAndLogHandler(model_save_folder, enable_model_saving=True, enable_logging=True)   # init\n",
    "model_def_src_file_path = os.path.join(r\"D:\\Desktop\\projects\\speaker_recognition_voxceleb1\\scripts\", \"model_definitions.py\")\n",
    "log_handler.save_model_definition_file(model_def_src_file_path)   # copy model def file\n",
    "print(log_handler.folder)\n",
    "\n",
    "# Description\n",
    "log_handler.print(\"Description: Candidates: 5, Encoding: 128, Projection: None\")\n",
    "log_handler.print(\"Base Model: mobileNetV2\")\n",
    "# log_handler.print(\"Base Model: densenet121\")\n",
    "log_handler.print(\"With Intra Class Variance Reduction\")\n",
    "\n",
    "# Train\n",
    "# train_model(model_ft, criterion, optimizer_ft, learning_rate_scheduler, epochs, num_batches, training_data_generator, log_handler)\n",
    "train_model(model_ft, criterion, optimizer_ft, learning_rate_scheduler, epochs, training_data_generator, validation_data, log_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_acc = 1 / CANDIDATE_SIZE\n",
    "random_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Overall\n",
    "* Contrastive classifier\n",
    "    * separate train and validate methods\n",
    "\n",
    "* (Done) Model saving / checkpointing\n",
    "* **Build binary classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
