{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from config import models_folder, output_data_folder\n",
    "from config import n_mels\n",
    "\n",
    "from model_definitions import SpectrogramEncoderNet, MultiSiameseContrastiveClassifierNet\n",
    "from data_generators import ContrastiveDataGenerator\n",
    "from project_utils import ModelSaveAndLogHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = n_mels\n",
    "CANDIDATE_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mobile net\n",
    "# model = models.mobilenet_v2(pretrained=False)\n",
    "# summary(model, input_size=(3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mobile net classifier\n",
    "# model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             864\n",
      "       BatchNorm2d-2           [-1, 32, 64, 64]              64\n",
      "             ReLU6-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]             288\n",
      "       BatchNorm2d-5           [-1, 32, 64, 64]              64\n",
      "             ReLU6-6           [-1, 32, 64, 64]               0\n",
      "            Conv2d-7           [-1, 16, 64, 64]             512\n",
      "       BatchNorm2d-8           [-1, 16, 64, 64]              32\n",
      "  InvertedResidual-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 96, 64, 64]           1,536\n",
      "      BatchNorm2d-11           [-1, 96, 64, 64]             192\n",
      "            ReLU6-12           [-1, 96, 64, 64]               0\n",
      "           Conv2d-13           [-1, 96, 32, 32]             864\n",
      "      BatchNorm2d-14           [-1, 96, 32, 32]             192\n",
      "            ReLU6-15           [-1, 96, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 32, 32]             288\n",
      "            ReLU6-21          [-1, 144, 32, 32]               0\n",
      "           Conv2d-22          [-1, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 32, 32]             288\n",
      "            ReLU6-24          [-1, 144, 32, 32]               0\n",
      "           Conv2d-25           [-1, 24, 32, 32]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-27           [-1, 24, 32, 32]               0\n",
      "           Conv2d-28          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 32, 32]             288\n",
      "            ReLU6-30          [-1, 144, 32, 32]               0\n",
      "           Conv2d-31          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 16, 16]             288\n",
      "            ReLU6-33          [-1, 144, 16, 16]               0\n",
      "           Conv2d-34           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-36           [-1, 32, 16, 16]               0\n",
      "           Conv2d-37          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 16, 16]             384\n",
      "            ReLU6-39          [-1, 192, 16, 16]               0\n",
      "           Conv2d-40          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 16, 16]             384\n",
      "            ReLU6-42          [-1, 192, 16, 16]               0\n",
      "           Conv2d-43           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-45           [-1, 32, 16, 16]               0\n",
      "           Conv2d-46          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 16, 16]             384\n",
      "            ReLU6-48          [-1, 192, 16, 16]               0\n",
      "           Conv2d-49          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 16, 16]             384\n",
      "            ReLU6-51          [-1, 192, 16, 16]               0\n",
      "           Conv2d-52           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 16, 16]             384\n",
      "            ReLU6-57          [-1, 192, 16, 16]               0\n",
      "           Conv2d-58            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-59            [-1, 192, 8, 8]             384\n",
      "            ReLU6-60            [-1, 192, 8, 8]               0\n",
      "           Conv2d-61             [-1, 64, 8, 8]          12,288\n",
      "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-63             [-1, 64, 8, 8]               0\n",
      "           Conv2d-64            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-65            [-1, 384, 8, 8]             768\n",
      "            ReLU6-66            [-1, 384, 8, 8]               0\n",
      "           Conv2d-67            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-68            [-1, 384, 8, 8]             768\n",
      "            ReLU6-69            [-1, 384, 8, 8]               0\n",
      "           Conv2d-70             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-71             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-72             [-1, 64, 8, 8]               0\n",
      "           Conv2d-73            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-74            [-1, 384, 8, 8]             768\n",
      "            ReLU6-75            [-1, 384, 8, 8]               0\n",
      "           Conv2d-76            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-77            [-1, 384, 8, 8]             768\n",
      "            ReLU6-78            [-1, 384, 8, 8]               0\n",
      "           Conv2d-79             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-81             [-1, 64, 8, 8]               0\n",
      "           Conv2d-82            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-83            [-1, 384, 8, 8]             768\n",
      "            ReLU6-84            [-1, 384, 8, 8]               0\n",
      "           Conv2d-85            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-86            [-1, 384, 8, 8]             768\n",
      "            ReLU6-87            [-1, 384, 8, 8]               0\n",
      "           Conv2d-88             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-90             [-1, 64, 8, 8]               0\n",
      "           Conv2d-91            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-92            [-1, 384, 8, 8]             768\n",
      "            ReLU6-93            [-1, 384, 8, 8]               0\n",
      "           Conv2d-94            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-95            [-1, 384, 8, 8]             768\n",
      "            ReLU6-96            [-1, 384, 8, 8]               0\n",
      "           Conv2d-97             [-1, 96, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 96, 8, 8]             192\n",
      " InvertedResidual-99             [-1, 96, 8, 8]               0\n",
      "          Conv2d-100            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-101            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-102            [-1, 576, 8, 8]               0\n",
      "          Conv2d-103            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-104            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-105            [-1, 576, 8, 8]               0\n",
      "          Conv2d-106             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-107             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-108             [-1, 96, 8, 8]               0\n",
      "          Conv2d-109            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-110            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-111            [-1, 576, 8, 8]               0\n",
      "          Conv2d-112            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-113            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-114            [-1, 576, 8, 8]               0\n",
      "          Conv2d-115             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-116             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-117             [-1, 96, 8, 8]               0\n",
      "          Conv2d-118            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-119            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-120            [-1, 576, 8, 8]               0\n",
      "          Conv2d-121            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-123            [-1, 576, 4, 4]               0\n",
      "          Conv2d-124            [-1, 160, 4, 4]          92,160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-125            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-126            [-1, 160, 4, 4]               0\n",
      "          Conv2d-127            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-129            [-1, 960, 4, 4]               0\n",
      "          Conv2d-130            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-132            [-1, 960, 4, 4]               0\n",
      "          Conv2d-133            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-135            [-1, 160, 4, 4]               0\n",
      "          Conv2d-136            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-138            [-1, 960, 4, 4]               0\n",
      "          Conv2d-139            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-141            [-1, 960, 4, 4]               0\n",
      "          Conv2d-142            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-144            [-1, 160, 4, 4]               0\n",
      "          Conv2d-145            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-147            [-1, 960, 4, 4]               0\n",
      "          Conv2d-148            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-150            [-1, 960, 4, 4]               0\n",
      "          Conv2d-151            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-153            [-1, 320, 4, 4]               0\n",
      "          Conv2d-154           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-156           [-1, 1280, 4, 4]               0\n",
      "          Linear-157                  [-1, 128]         163,968\n",
      "     MobileNetV2-158                  [-1, 128]               0\n",
      "================================================================\n",
      "Total params: 2,387,840\n",
      "Trainable params: 2,387,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 49.91\n",
      "Params size (MB): 9.11\n",
      "Estimated Total Size (MB): 59.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(SpectrogramEncoderNet(), input_size=(3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             864\n",
      "       BatchNorm2d-2           [-1, 32, 64, 64]              64\n",
      "             ReLU6-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]             288\n",
      "       BatchNorm2d-5           [-1, 32, 64, 64]              64\n",
      "             ReLU6-6           [-1, 32, 64, 64]               0\n",
      "            Conv2d-7           [-1, 16, 64, 64]             512\n",
      "       BatchNorm2d-8           [-1, 16, 64, 64]              32\n",
      "  InvertedResidual-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 96, 64, 64]           1,536\n",
      "      BatchNorm2d-11           [-1, 96, 64, 64]             192\n",
      "            ReLU6-12           [-1, 96, 64, 64]               0\n",
      "           Conv2d-13           [-1, 96, 32, 32]             864\n",
      "      BatchNorm2d-14           [-1, 96, 32, 32]             192\n",
      "            ReLU6-15           [-1, 96, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 32, 32]             288\n",
      "            ReLU6-21          [-1, 144, 32, 32]               0\n",
      "           Conv2d-22          [-1, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 32, 32]             288\n",
      "            ReLU6-24          [-1, 144, 32, 32]               0\n",
      "           Conv2d-25           [-1, 24, 32, 32]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-27           [-1, 24, 32, 32]               0\n",
      "           Conv2d-28          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 32, 32]             288\n",
      "            ReLU6-30          [-1, 144, 32, 32]               0\n",
      "           Conv2d-31          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 16, 16]             288\n",
      "            ReLU6-33          [-1, 144, 16, 16]               0\n",
      "           Conv2d-34           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-36           [-1, 32, 16, 16]               0\n",
      "           Conv2d-37          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 16, 16]             384\n",
      "            ReLU6-39          [-1, 192, 16, 16]               0\n",
      "           Conv2d-40          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 16, 16]             384\n",
      "            ReLU6-42          [-1, 192, 16, 16]               0\n",
      "           Conv2d-43           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-45           [-1, 32, 16, 16]               0\n",
      "           Conv2d-46          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 16, 16]             384\n",
      "            ReLU6-48          [-1, 192, 16, 16]               0\n",
      "           Conv2d-49          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 16, 16]             384\n",
      "            ReLU6-51          [-1, 192, 16, 16]               0\n",
      "           Conv2d-52           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 16, 16]             384\n",
      "            ReLU6-57          [-1, 192, 16, 16]               0\n",
      "           Conv2d-58            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-59            [-1, 192, 8, 8]             384\n",
      "            ReLU6-60            [-1, 192, 8, 8]               0\n",
      "           Conv2d-61             [-1, 64, 8, 8]          12,288\n",
      "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-63             [-1, 64, 8, 8]               0\n",
      "           Conv2d-64            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-65            [-1, 384, 8, 8]             768\n",
      "            ReLU6-66            [-1, 384, 8, 8]               0\n",
      "           Conv2d-67            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-68            [-1, 384, 8, 8]             768\n",
      "            ReLU6-69            [-1, 384, 8, 8]               0\n",
      "           Conv2d-70             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-71             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-72             [-1, 64, 8, 8]               0\n",
      "           Conv2d-73            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-74            [-1, 384, 8, 8]             768\n",
      "            ReLU6-75            [-1, 384, 8, 8]               0\n",
      "           Conv2d-76            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-77            [-1, 384, 8, 8]             768\n",
      "            ReLU6-78            [-1, 384, 8, 8]               0\n",
      "           Conv2d-79             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-81             [-1, 64, 8, 8]               0\n",
      "           Conv2d-82            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-83            [-1, 384, 8, 8]             768\n",
      "            ReLU6-84            [-1, 384, 8, 8]               0\n",
      "           Conv2d-85            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-86            [-1, 384, 8, 8]             768\n",
      "            ReLU6-87            [-1, 384, 8, 8]               0\n",
      "           Conv2d-88             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-90             [-1, 64, 8, 8]               0\n",
      "           Conv2d-91            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-92            [-1, 384, 8, 8]             768\n",
      "            ReLU6-93            [-1, 384, 8, 8]               0\n",
      "           Conv2d-94            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-95            [-1, 384, 8, 8]             768\n",
      "            ReLU6-96            [-1, 384, 8, 8]               0\n",
      "           Conv2d-97             [-1, 96, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 96, 8, 8]             192\n",
      " InvertedResidual-99             [-1, 96, 8, 8]               0\n",
      "          Conv2d-100            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-101            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-102            [-1, 576, 8, 8]               0\n",
      "          Conv2d-103            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-104            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-105            [-1, 576, 8, 8]               0\n",
      "          Conv2d-106             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-107             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-108             [-1, 96, 8, 8]               0\n",
      "          Conv2d-109            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-110            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-111            [-1, 576, 8, 8]               0\n",
      "          Conv2d-112            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-113            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-114            [-1, 576, 8, 8]               0\n",
      "          Conv2d-115             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-116             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-117             [-1, 96, 8, 8]               0\n",
      "          Conv2d-118            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-119            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-120            [-1, 576, 8, 8]               0\n",
      "          Conv2d-121            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-123            [-1, 576, 4, 4]               0\n",
      "          Conv2d-124            [-1, 160, 4, 4]          92,160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-125            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-126            [-1, 160, 4, 4]               0\n",
      "          Conv2d-127            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-129            [-1, 960, 4, 4]               0\n",
      "          Conv2d-130            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-132            [-1, 960, 4, 4]               0\n",
      "          Conv2d-133            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-135            [-1, 160, 4, 4]               0\n",
      "          Conv2d-136            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-138            [-1, 960, 4, 4]               0\n",
      "          Conv2d-139            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-141            [-1, 960, 4, 4]               0\n",
      "          Conv2d-142            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-144            [-1, 160, 4, 4]               0\n",
      "          Conv2d-145            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-147            [-1, 960, 4, 4]               0\n",
      "          Conv2d-148            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-150            [-1, 960, 4, 4]               0\n",
      "          Conv2d-151            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-153            [-1, 320, 4, 4]               0\n",
      "          Conv2d-154           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-156           [-1, 1280, 4, 4]               0\n",
      "          Linear-157                  [-1, 128]         163,968\n",
      "     MobileNetV2-158                  [-1, 128]               0\n",
      "SpectrogramEncoderNet-159                  [-1, 128]               0\n",
      "        Identity-160                  [-1, 128]               0\n",
      "          Conv2d-161           [-1, 32, 64, 64]             864\n",
      "     BatchNorm2d-162           [-1, 32, 64, 64]              64\n",
      "           ReLU6-163           [-1, 32, 64, 64]               0\n",
      "          Conv2d-164           [-1, 32, 64, 64]             288\n",
      "     BatchNorm2d-165           [-1, 32, 64, 64]              64\n",
      "           ReLU6-166           [-1, 32, 64, 64]               0\n",
      "          Conv2d-167           [-1, 16, 64, 64]             512\n",
      "     BatchNorm2d-168           [-1, 16, 64, 64]              32\n",
      "InvertedResidual-169           [-1, 16, 64, 64]               0\n",
      "          Conv2d-170           [-1, 96, 64, 64]           1,536\n",
      "     BatchNorm2d-171           [-1, 96, 64, 64]             192\n",
      "           ReLU6-172           [-1, 96, 64, 64]               0\n",
      "          Conv2d-173           [-1, 96, 32, 32]             864\n",
      "     BatchNorm2d-174           [-1, 96, 32, 32]             192\n",
      "           ReLU6-175           [-1, 96, 32, 32]               0\n",
      "          Conv2d-176           [-1, 24, 32, 32]           2,304\n",
      "     BatchNorm2d-177           [-1, 24, 32, 32]              48\n",
      "InvertedResidual-178           [-1, 24, 32, 32]               0\n",
      "          Conv2d-179          [-1, 144, 32, 32]           3,456\n",
      "     BatchNorm2d-180          [-1, 144, 32, 32]             288\n",
      "           ReLU6-181          [-1, 144, 32, 32]               0\n",
      "          Conv2d-182          [-1, 144, 32, 32]           1,296\n",
      "     BatchNorm2d-183          [-1, 144, 32, 32]             288\n",
      "           ReLU6-184          [-1, 144, 32, 32]               0\n",
      "          Conv2d-185           [-1, 24, 32, 32]           3,456\n",
      "     BatchNorm2d-186           [-1, 24, 32, 32]              48\n",
      "InvertedResidual-187           [-1, 24, 32, 32]               0\n",
      "          Conv2d-188          [-1, 144, 32, 32]           3,456\n",
      "     BatchNorm2d-189          [-1, 144, 32, 32]             288\n",
      "           ReLU6-190          [-1, 144, 32, 32]               0\n",
      "          Conv2d-191          [-1, 144, 16, 16]           1,296\n",
      "     BatchNorm2d-192          [-1, 144, 16, 16]             288\n",
      "           ReLU6-193          [-1, 144, 16, 16]               0\n",
      "          Conv2d-194           [-1, 32, 16, 16]           4,608\n",
      "     BatchNorm2d-195           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-196           [-1, 32, 16, 16]               0\n",
      "          Conv2d-197          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-198          [-1, 192, 16, 16]             384\n",
      "           ReLU6-199          [-1, 192, 16, 16]               0\n",
      "          Conv2d-200          [-1, 192, 16, 16]           1,728\n",
      "     BatchNorm2d-201          [-1, 192, 16, 16]             384\n",
      "           ReLU6-202          [-1, 192, 16, 16]               0\n",
      "          Conv2d-203           [-1, 32, 16, 16]           6,144\n",
      "     BatchNorm2d-204           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-205           [-1, 32, 16, 16]               0\n",
      "          Conv2d-206          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-207          [-1, 192, 16, 16]             384\n",
      "           ReLU6-208          [-1, 192, 16, 16]               0\n",
      "          Conv2d-209          [-1, 192, 16, 16]           1,728\n",
      "     BatchNorm2d-210          [-1, 192, 16, 16]             384\n",
      "           ReLU6-211          [-1, 192, 16, 16]               0\n",
      "          Conv2d-212           [-1, 32, 16, 16]           6,144\n",
      "     BatchNorm2d-213           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-214           [-1, 32, 16, 16]               0\n",
      "          Conv2d-215          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-216          [-1, 192, 16, 16]             384\n",
      "           ReLU6-217          [-1, 192, 16, 16]               0\n",
      "          Conv2d-218            [-1, 192, 8, 8]           1,728\n",
      "     BatchNorm2d-219            [-1, 192, 8, 8]             384\n",
      "           ReLU6-220            [-1, 192, 8, 8]               0\n",
      "          Conv2d-221             [-1, 64, 8, 8]          12,288\n",
      "     BatchNorm2d-222             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-223             [-1, 64, 8, 8]               0\n",
      "          Conv2d-224            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-225            [-1, 384, 8, 8]             768\n",
      "           ReLU6-226            [-1, 384, 8, 8]               0\n",
      "          Conv2d-227            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-228            [-1, 384, 8, 8]             768\n",
      "           ReLU6-229            [-1, 384, 8, 8]               0\n",
      "          Conv2d-230             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-231             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-232             [-1, 64, 8, 8]               0\n",
      "          Conv2d-233            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-234            [-1, 384, 8, 8]             768\n",
      "           ReLU6-235            [-1, 384, 8, 8]               0\n",
      "          Conv2d-236            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-237            [-1, 384, 8, 8]             768\n",
      "           ReLU6-238            [-1, 384, 8, 8]               0\n",
      "          Conv2d-239             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-240             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-241             [-1, 64, 8, 8]               0\n",
      "          Conv2d-242            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-243            [-1, 384, 8, 8]             768\n",
      "           ReLU6-244            [-1, 384, 8, 8]               0\n",
      "          Conv2d-245            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-246            [-1, 384, 8, 8]             768\n",
      "           ReLU6-247            [-1, 384, 8, 8]               0\n",
      "          Conv2d-248             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-249             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-250             [-1, 64, 8, 8]               0\n",
      "          Conv2d-251            [-1, 384, 8, 8]          24,576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-252            [-1, 384, 8, 8]             768\n",
      "           ReLU6-253            [-1, 384, 8, 8]               0\n",
      "          Conv2d-254            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-255            [-1, 384, 8, 8]             768\n",
      "           ReLU6-256            [-1, 384, 8, 8]               0\n",
      "          Conv2d-257             [-1, 96, 8, 8]          36,864\n",
      "     BatchNorm2d-258             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-259             [-1, 96, 8, 8]               0\n",
      "          Conv2d-260            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-261            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-262            [-1, 576, 8, 8]               0\n",
      "          Conv2d-263            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-264            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-265            [-1, 576, 8, 8]               0\n",
      "          Conv2d-266             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-267             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-268             [-1, 96, 8, 8]               0\n",
      "          Conv2d-269            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-270            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-271            [-1, 576, 8, 8]               0\n",
      "          Conv2d-272            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-273            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-274            [-1, 576, 8, 8]               0\n",
      "          Conv2d-275             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-276             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-277             [-1, 96, 8, 8]               0\n",
      "          Conv2d-278            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-279            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-280            [-1, 576, 8, 8]               0\n",
      "          Conv2d-281            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-282            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-283            [-1, 576, 4, 4]               0\n",
      "          Conv2d-284            [-1, 160, 4, 4]          92,160\n",
      "     BatchNorm2d-285            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-286            [-1, 160, 4, 4]               0\n",
      "          Conv2d-287            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-288            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-289            [-1, 960, 4, 4]               0\n",
      "          Conv2d-290            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-291            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-292            [-1, 960, 4, 4]               0\n",
      "          Conv2d-293            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-294            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-295            [-1, 160, 4, 4]               0\n",
      "          Conv2d-296            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-297            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-298            [-1, 960, 4, 4]               0\n",
      "          Conv2d-299            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-300            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-301            [-1, 960, 4, 4]               0\n",
      "          Conv2d-302            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-303            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-304            [-1, 160, 4, 4]               0\n",
      "          Conv2d-305            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-306            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-307            [-1, 960, 4, 4]               0\n",
      "          Conv2d-308            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-309            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-310            [-1, 960, 4, 4]               0\n",
      "          Conv2d-311            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-312            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-313            [-1, 320, 4, 4]               0\n",
      "          Conv2d-314           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-315           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-316           [-1, 1280, 4, 4]               0\n",
      "          Linear-317                  [-1, 128]         163,968\n",
      "     MobileNetV2-318                  [-1, 128]               0\n",
      "SpectrogramEncoderNet-319                  [-1, 128]               0\n",
      "        Identity-320                  [-1, 128]               0\n",
      "================================================================\n",
      "Total params: 4,775,680\n",
      "Trainable params: 4,775,680\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.12\n",
      "Forward/backward pass size (MB): 99.83\n",
      "Params size (MB): 18.22\n",
      "Estimated Total Size (MB): 119.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(MultiSiameseContrastiveClassifierNet(), input_size=(CANDIDATE_SIZE+1, 3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataGenerator:\n",
    "    \n",
    "#     def __init__(self, spectrogram_samples_files, candidate_size, batch_size, num_batches, num_sub_samples, img_height):\n",
    "#         self.spectrogram_samples_files = spectrogram_samples_files   # list of filepaths\n",
    "#         self.candidate_size = candidate_size   # 1 positive, n-1 negatives\n",
    "#         self.batch_size = batch_size   # batch size\n",
    "#         self.num_batches = num_batches   # num batches per epoch\n",
    "#         self.num_sub_samples = num_sub_samples   # num sub-samples per epoch\n",
    "#         self.img_height = img_height   # height of square img to be generated in the batches\n",
    "#         self.sub_samples = []   # list of RGB converted spectrograms\n",
    "    \n",
    "#     def generate_batches(self):\n",
    "#         while True:\n",
    "#             self.create_sub_samples()\n",
    "#             # batches per epoch\n",
    "#             for _ in range(self.num_batches):\n",
    "#                 # create batch\n",
    "#                 labels = []\n",
    "#                 query_and_candidate_imgs = [[] for _ in range(self.candidate_size + 1)]\n",
    "#                 for _ in range(self.batch_size):\n",
    "#                     sample_spectrograms_indices = random.sample(range(self.num_sub_samples), self.candidate_size)   # sample candidates\n",
    "#                     pos_idx = sample_spectrograms_indices[0]   # positive sample\n",
    "#                     # Generate query image\n",
    "#                     query_img = self.get_sliding_img_slice_from_spectrogram(self.sub_samples[pos_idx])\n",
    "#                     # Generate batch images\n",
    "#                     random.shuffle(sample_spectrograms_indices)\n",
    "#                     candidate_imgs = [self.get_sliding_img_slice_from_spectrogram(self.sub_samples[idx]) for idx in sample_spectrograms_indices]\n",
    "#                     # get class label / idx of positive sample\n",
    "#                     pos_candidate_idx = sample_spectrograms_indices.index(pos_idx)   \n",
    "#                     labels.append(pos_candidate_idx)\n",
    "#                     # Normalize input imgs\n",
    "#                     for i, img in enumerate([query_img, *candidate_imgs]):\n",
    "#                         img = img / np.amax(np.absolute(img))   # normalize to range [-1, 1]\n",
    "#                         query_and_candidate_imgs[i].append(img)\n",
    "#                 # Convert to tensor\n",
    "#                 labels = torch.tensor(labels)\n",
    "#                 input_imgs = torch.tensor(query_and_candidate_imgs)\n",
    "#                 yield (input_imgs, labels)\n",
    "    \n",
    "#     def create_sub_samples(self):\n",
    "#         self.sub_samples = []   # reset\n",
    "#         files = random.sample(self.spectrogram_samples_files, self.num_sub_samples)   # sampling without replacement\n",
    "#         for file in files:\n",
    "# #             print(file)\n",
    "#             spectrogram = np.load(file)\n",
    "#             assert spectrogram.shape[0] == self.img_height, \"Input spectrogram height does not match img height\"\n",
    "#             self.sub_samples.append(spectrogram)\n",
    "    \n",
    "#     @classmethod\n",
    "#     def get_sliding_img_slice_from_spectrogram(cls, spectrogram, depth=3, sliding_ratio=2):\n",
    "#         ### Combine multiple sliding greyscale img slices into an n-depth image\n",
    "#         height = spectrogram.shape[0]\n",
    "#         slide_step = height//sliding_ratio\n",
    "#         img_slice = np.zeros((depth,height,height))   # initialize empty img (pytorch style)\n",
    "#         # Get random start idx\n",
    "#         slice_start = random.randint(0, spectrogram.shape[1] - (slide_step*(depth+1)) - 1)\n",
    "#         for i in range(depth):\n",
    "#             img_slice[i,:,:] = spectrogram[:, slice_start:slice_start+height]   # get slice (pytorch style)\n",
    "#             slice_start += slide_step   # slide\n",
    "#         img_slice = img_slice.astype(\"float32\")\n",
    "#         return img_slice\n",
    "    \n",
    "#     @classmethod\n",
    "#     def spectrogram_to_RGB(cls, spectrogram):\n",
    "#         assert len(spectrogram.shape) == 2, \"Spectrogram input should be a 2D array\"\n",
    "#         spectrogram_rgb = gray2rgb(spectrogram)\n",
    "#         return spectrogram_rgb\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training data\n",
    "training_folder = os.path.join(output_data_folder, \"training_dataset_full_spectrogram/vox1_dev_wav\")\n",
    "spectrogram_samples_files = [os.path.join(training_folder, file) for file in os.listdir(training_folder)]\n",
    "candidate_size = CANDIDATE_SIZE\n",
    "batch_size = 15\n",
    "num_batches = 2000 // batch_size\n",
    "# num_batches = 200 // batch_size\n",
    "num_sub_samples = 200\n",
    "# num_sub_samples = 20\n",
    "training_data_generator = ContrastiveDataGenerator(spectrogram_samples_files, candidate_size, batch_size, num_batches, num_sub_samples, IMG_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validation data\n",
    "validation_set_file = os.path.join(output_data_folder, \"validation_sets\", \"contrastive_validation_set.pickle\")\n",
    "with open(validation_set_file, 'rb') as f:\n",
    "    validation_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, training_data_generator, validation_data, log_handler):\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    t1 = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        log_handler.print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        log_handler.print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            batches_used = 0\n",
    "            data_generator = training_data_generator.generate_batches() if phase == 'train' else validation_data\n",
    "            for data in data_generator:\n",
    "                batches_used += 1\n",
    "                input_imgs, labels = data\n",
    "                inputs = [img.to(device) for img in input_imgs]\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):   # gradient only for train\n",
    "                    outputs = model(inputs)   \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs[0].size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            epoch_loss = running_loss / (batches_used * inputs[0].size(0))\n",
    "            epoch_acc = running_corrects.double() / (batches_used * inputs[0].size(0))\n",
    "            log_handler.print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                log_handler.save_pytorch_model(model, \"best_model_{}.pt\".format(model.__class__.__name__))\n",
    "                example = [torch.rand(1, 3, IMG_HEIGHT, IMG_HEIGHT), torch.rand(1, 3, IMG_HEIGHT, IMG_HEIGHT)]\n",
    "                log_handler.save_pytorch_model_as_torchscript(model, \"mobile_model.pt\", (example,))\n",
    "\n",
    "        # end of epoch\n",
    "        log_handler.print(\"Time taken is {} seconds\".format(int(time.time()-t1)))\n",
    "        t1 = time.time()\n",
    "        log_handler.print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    log_handler.print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    log_handler.print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Desktop\\projects\\speaker_recognition_voxceleb1\\output_data\\models\\contrastive_encoder\\2020-03-20_10-28-00\n",
      "Description: Candidates: 5, Encoding: 128, Projection: None\n",
      "Epoch 0/69\n",
      "----------\n",
      "train Loss: 1.5505 Acc: 0.2827\n",
      "val Loss: 1.5301 Acc: 0.3078\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 158 seconds\n",
      "\n",
      "Epoch 1/69\n",
      "----------\n",
      "train Loss: 1.5242 Acc: 0.3028\n",
      "val Loss: 1.5078 Acc: 0.3123\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 170 seconds\n",
      "\n",
      "Epoch 2/69\n",
      "----------\n",
      "train Loss: 1.5161 Acc: 0.3063\n",
      "val Loss: 1.4994 Acc: 0.3338\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 166 seconds\n",
      "\n",
      "Epoch 3/69\n",
      "----------\n",
      "train Loss: 1.5230 Acc: 0.3073\n",
      "val Loss: 1.4838 Acc: 0.3504\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 163 seconds\n",
      "\n",
      "Epoch 4/69\n",
      "----------\n",
      "train Loss: 1.5065 Acc: 0.2982\n",
      "val Loss: 1.4709 Acc: 0.3514\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 165 seconds\n",
      "\n",
      "Epoch 5/69\n",
      "----------\n",
      "train Loss: 1.4745 Acc: 0.3398\n",
      "val Loss: 1.4419 Acc: 0.3534\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 160 seconds\n",
      "\n",
      "Epoch 6/69\n",
      "----------\n",
      "train Loss: 1.4631 Acc: 0.3298\n",
      "val Loss: 1.4393 Acc: 0.3709\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 156 seconds\n",
      "\n",
      "Epoch 7/69\n",
      "----------\n",
      "train Loss: 1.4790 Acc: 0.3343\n",
      "val Loss: 1.4421 Acc: 0.3569\n",
      "Time taken is 165 seconds\n",
      "\n",
      "Epoch 8/69\n",
      "----------\n",
      "train Loss: 1.4552 Acc: 0.3519\n",
      "val Loss: 1.4416 Acc: 0.3589\n",
      "Time taken is 158 seconds\n",
      "\n",
      "Epoch 9/69\n",
      "----------\n",
      "train Loss: 1.4630 Acc: 0.3429\n",
      "val Loss: 1.4169 Acc: 0.3669\n",
      "Time taken is 163 seconds\n",
      "\n",
      "Epoch 10/69\n",
      "----------\n",
      "train Loss: 1.4589 Acc: 0.3388\n",
      "val Loss: 1.4048 Acc: 0.3694\n",
      "Time taken is 157 seconds\n",
      "\n",
      "Epoch 11/69\n",
      "----------\n",
      "train Loss: 1.4264 Acc: 0.3499\n",
      "val Loss: 1.3764 Acc: 0.3830\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 153 seconds\n",
      "\n",
      "Epoch 12/69\n",
      "----------\n",
      "train Loss: 1.4106 Acc: 0.3749\n",
      "val Loss: 1.3254 Acc: 0.4316\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 157 seconds\n",
      "\n",
      "Epoch 13/69\n",
      "----------\n",
      "train Loss: 1.3711 Acc: 0.4090\n",
      "val Loss: 1.3117 Acc: 0.4526\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 151 seconds\n",
      "\n",
      "Epoch 14/69\n",
      "----------\n",
      "train Loss: 1.3724 Acc: 0.3970\n",
      "val Loss: 1.3006 Acc: 0.4657\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 152 seconds\n",
      "\n",
      "Epoch 15/69\n",
      "----------\n",
      "train Loss: 1.3686 Acc: 0.4261\n",
      "val Loss: 1.2759 Acc: 0.4877\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 152 seconds\n",
      "\n",
      "Epoch 16/69\n",
      "----------\n",
      "train Loss: 1.2994 Acc: 0.4571\n",
      "val Loss: 1.2717 Acc: 0.4887\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 159 seconds\n",
      "\n",
      "Epoch 17/69\n",
      "----------\n",
      "train Loss: 1.3105 Acc: 0.4516\n",
      "val Loss: 1.2533 Acc: 0.5108\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 170 seconds\n",
      "\n",
      "Epoch 18/69\n",
      "----------\n",
      "train Loss: 1.3368 Acc: 0.4241\n",
      "val Loss: 1.2695 Acc: 0.4882\n",
      "Time taken is 171 seconds\n",
      "\n",
      "Epoch 19/69\n",
      "----------\n",
      "train Loss: 1.3268 Acc: 0.4526\n",
      "val Loss: 1.2705 Acc: 0.4907\n",
      "Time taken is 166 seconds\n",
      "\n",
      "Epoch 20/69\n",
      "----------\n",
      "train Loss: 1.3367 Acc: 0.4356\n",
      "val Loss: 1.2613 Acc: 0.4827\n",
      "Time taken is 164 seconds\n",
      "\n",
      "Epoch 21/69\n",
      "----------\n",
      "train Loss: 1.3331 Acc: 0.4266\n",
      "val Loss: 1.2730 Acc: 0.4927\n",
      "Time taken is 154 seconds\n",
      "\n",
      "Epoch 22/69\n",
      "----------\n",
      "train Loss: 1.2998 Acc: 0.4687\n",
      "val Loss: 1.2778 Acc: 0.4842\n",
      "Time taken is 155 seconds\n",
      "\n",
      "Epoch 23/69\n",
      "----------\n",
      "train Loss: 1.3321 Acc: 0.4496\n",
      "val Loss: 1.2759 Acc: 0.4847\n",
      "Time taken is 151 seconds\n",
      "\n",
      "Epoch 24/69\n",
      "----------\n",
      "train Loss: 1.3089 Acc: 0.4596\n",
      "val Loss: 1.2734 Acc: 0.4827\n",
      "Time taken is 162 seconds\n",
      "\n",
      "Epoch 25/69\n",
      "----------\n",
      "train Loss: 1.3358 Acc: 0.4301\n",
      "val Loss: 1.2724 Acc: 0.4987\n",
      "Time taken is 148 seconds\n",
      "\n",
      "Epoch 26/69\n",
      "----------\n",
      "train Loss: 1.3235 Acc: 0.4622\n",
      "val Loss: 1.2654 Acc: 0.4767\n",
      "Time taken is 146 seconds\n",
      "\n",
      "Epoch 27/69\n",
      "----------\n",
      "train Loss: 1.3145 Acc: 0.4596\n",
      "val Loss: 1.2580 Acc: 0.4847\n",
      "Time taken is 150 seconds\n",
      "\n",
      "Epoch 28/69\n",
      "----------\n",
      "train Loss: 1.3576 Acc: 0.4226\n",
      "val Loss: 1.2826 Acc: 0.4902\n",
      "Time taken is 152 seconds\n",
      "\n",
      "Epoch 29/69\n",
      "----------\n",
      "train Loss: 1.3068 Acc: 0.4506\n",
      "val Loss: 1.2708 Acc: 0.4852\n",
      "Time taken is 152 seconds\n",
      "\n",
      "Epoch 30/69\n",
      "----------\n",
      "train Loss: 1.3138 Acc: 0.4501\n",
      "val Loss: 1.2627 Acc: 0.4837\n",
      "Time taken is 147 seconds\n",
      "\n",
      "Epoch 31/69\n",
      "----------\n",
      "train Loss: 1.3099 Acc: 0.4471\n",
      "val Loss: 1.2647 Acc: 0.4922\n",
      "Time taken is 158 seconds\n",
      "\n",
      "Epoch 32/69\n",
      "----------\n",
      "train Loss: 1.3225 Acc: 0.4456\n",
      "val Loss: 1.2754 Acc: 0.4897\n",
      "Time taken is 161 seconds\n",
      "\n",
      "Epoch 33/69\n",
      "----------\n",
      "train Loss: 1.3163 Acc: 0.4586\n",
      "val Loss: 1.2798 Acc: 0.4852\n",
      "Time taken is 171 seconds\n",
      "\n",
      "Epoch 34/69\n",
      "----------\n",
      "train Loss: 1.2974 Acc: 0.4892\n",
      "val Loss: 1.2762 Acc: 0.4997\n",
      "Time taken is 151 seconds\n",
      "\n",
      "Epoch 35/69\n",
      "----------\n",
      "train Loss: 1.3229 Acc: 0.4511\n",
      "val Loss: 1.2747 Acc: 0.4897\n",
      "Time taken is 153 seconds\n",
      "\n",
      "Epoch 36/69\n",
      "----------\n",
      "train Loss: 1.3131 Acc: 0.4496\n",
      "val Loss: 1.2726 Acc: 0.4852\n",
      "Time taken is 150 seconds\n",
      "\n",
      "Epoch 37/69\n",
      "----------\n",
      "train Loss: 1.3115 Acc: 0.4431\n",
      "val Loss: 1.2634 Acc: 0.5083\n",
      "Time taken is 142 seconds\n",
      "\n",
      "Epoch 38/69\n",
      "----------\n",
      "train Loss: 1.3328 Acc: 0.4416\n",
      "val Loss: 1.2775 Acc: 0.5103\n",
      "Time taken is 153 seconds\n",
      "\n",
      "Epoch 39/69\n",
      "----------\n",
      "train Loss: 1.3112 Acc: 0.4446\n",
      "val Loss: 1.2798 Acc: 0.4907\n",
      "Time taken is 155 seconds\n",
      "\n",
      "Epoch 40/69\n",
      "----------\n",
      "train Loss: 1.3082 Acc: 0.4391\n",
      "val Loss: 1.2702 Acc: 0.5108\n",
      "Time taken is 153 seconds\n",
      "\n",
      "Epoch 41/69\n",
      "----------\n",
      "train Loss: 1.2889 Acc: 0.4777\n",
      "val Loss: 1.2559 Acc: 0.5063\n",
      "Time taken is 154 seconds\n",
      "\n",
      "Epoch 42/69\n",
      "----------\n",
      "train Loss: 1.3020 Acc: 0.4667\n",
      "val Loss: 1.2618 Acc: 0.4912\n",
      "Time taken is 151 seconds\n",
      "\n",
      "Epoch 43/69\n",
      "----------\n",
      "train Loss: 1.2993 Acc: 0.4762\n",
      "val Loss: 1.2658 Acc: 0.4917\n",
      "Time taken is 174 seconds\n",
      "\n",
      "Epoch 44/69\n",
      "----------\n",
      "train Loss: 1.2995 Acc: 0.4622\n",
      "val Loss: 1.2713 Acc: 0.4832\n",
      "Time taken is 176 seconds\n",
      "\n",
      "Epoch 45/69\n",
      "----------\n",
      "train Loss: 1.3261 Acc: 0.4481\n",
      "val Loss: 1.2725 Acc: 0.4972\n",
      "Time taken is 193 seconds\n",
      "\n",
      "Epoch 46/69\n",
      "----------\n",
      "train Loss: 1.2967 Acc: 0.4612\n",
      "val Loss: 1.2717 Acc: 0.4927\n",
      "Time taken is 186 seconds\n",
      "\n",
      "Epoch 47/69\n",
      "----------\n",
      "train Loss: 1.3053 Acc: 0.4787\n",
      "val Loss: 1.2657 Acc: 0.4962\n",
      "Time taken is 167 seconds\n",
      "\n",
      "Epoch 48/69\n",
      "----------\n",
      "train Loss: 1.3059 Acc: 0.4596\n",
      "val Loss: 1.2758 Acc: 0.4887\n",
      "Time taken is 160 seconds\n",
      "\n",
      "Epoch 49/69\n",
      "----------\n",
      "train Loss: 1.3103 Acc: 0.4727\n",
      "val Loss: 1.2758 Acc: 0.4917\n",
      "Time taken is 178 seconds\n",
      "\n",
      "Epoch 50/69\n",
      "----------\n",
      "train Loss: 1.3208 Acc: 0.4607\n",
      "val Loss: 1.2693 Acc: 0.4932\n",
      "Time taken is 165 seconds\n",
      "\n",
      "Epoch 51/69\n",
      "----------\n",
      "train Loss: 1.3102 Acc: 0.4551\n",
      "val Loss: 1.2677 Acc: 0.4932\n",
      "Time taken is 157 seconds\n",
      "\n",
      "Epoch 52/69\n",
      "----------\n",
      "train Loss: 1.3137 Acc: 0.4667\n",
      "val Loss: 1.2726 Acc: 0.4987\n",
      "Time taken is 156 seconds\n",
      "\n",
      "Epoch 53/69\n",
      "----------\n",
      "train Loss: 1.3191 Acc: 0.4461\n",
      "val Loss: 1.2795 Acc: 0.5083\n",
      "Time taken is 183 seconds\n",
      "\n",
      "Epoch 54/69\n",
      "----------\n",
      "train Loss: 1.3114 Acc: 0.4561\n",
      "val Loss: 1.2599 Acc: 0.5038\n",
      "Time taken is 155 seconds\n",
      "\n",
      "Epoch 55/69\n",
      "----------\n",
      "train Loss: 1.3135 Acc: 0.4622\n",
      "val Loss: 1.2656 Acc: 0.4927\n",
      "Time taken is 154 seconds\n",
      "\n",
      "Epoch 56/69\n",
      "----------\n",
      "train Loss: 1.3090 Acc: 0.4541\n",
      "val Loss: 1.2723 Acc: 0.5038\n",
      "Time taken is 160 seconds\n",
      "\n",
      "Epoch 57/69\n",
      "----------\n",
      "train Loss: 1.3017 Acc: 0.4632\n",
      "val Loss: 1.2705 Acc: 0.5038\n",
      "Time taken is 160 seconds\n",
      "\n",
      "Epoch 58/69\n",
      "----------\n",
      "train Loss: 1.3002 Acc: 0.4767\n",
      "val Loss: 1.2676 Acc: 0.5008\n",
      "Time taken is 158 seconds\n",
      "\n",
      "Epoch 59/69\n",
      "----------\n",
      "train Loss: 1.2899 Acc: 0.4722\n",
      "val Loss: 1.2706 Acc: 0.4922\n",
      "Time taken is 159 seconds\n",
      "\n",
      "Epoch 60/69\n",
      "----------\n",
      "train Loss: 1.3311 Acc: 0.4356\n",
      "val Loss: 1.2750 Acc: 0.4932\n",
      "Time taken is 162 seconds\n",
      "\n",
      "Epoch 61/69\n",
      "----------\n",
      "train Loss: 1.3175 Acc: 0.4627\n",
      "val Loss: 1.2734 Acc: 0.5018\n",
      "Time taken is 154 seconds\n",
      "\n",
      "Epoch 62/69\n",
      "----------\n",
      "train Loss: 1.3206 Acc: 0.4596\n",
      "val Loss: 1.2638 Acc: 0.5023\n",
      "Time taken is 161 seconds\n",
      "\n",
      "Epoch 63/69\n",
      "----------\n",
      "train Loss: 1.3229 Acc: 0.4561\n",
      "val Loss: 1.2687 Acc: 0.5013\n",
      "Time taken is 165 seconds\n",
      "\n",
      "Epoch 64/69\n",
      "----------\n",
      "train Loss: 1.3253 Acc: 0.4391\n",
      "val Loss: 1.2763 Acc: 0.5023\n",
      "Time taken is 166 seconds\n",
      "\n",
      "Epoch 65/69\n",
      "----------\n",
      "train Loss: 1.2933 Acc: 0.4707\n",
      "val Loss: 1.2581 Acc: 0.5058\n",
      "Time taken is 164 seconds\n",
      "\n",
      "Epoch 66/69\n",
      "----------\n",
      "train Loss: 1.3040 Acc: 0.4541\n",
      "val Loss: 1.2605 Acc: 0.5038\n",
      "Time taken is 162 seconds\n",
      "\n",
      "Epoch 67/69\n",
      "----------\n",
      "train Loss: 1.3373 Acc: 0.4536\n",
      "val Loss: 1.2603 Acc: 0.5043\n",
      "Time taken is 173 seconds\n",
      "\n",
      "Epoch 68/69\n",
      "----------\n",
      "train Loss: 1.3151 Acc: 0.4757\n",
      "val Loss: 1.2631 Acc: 0.5068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken is 154 seconds\n",
      "\n",
      "Epoch 69/69\n",
      "----------\n",
      "train Loss: 1.2970 Acc: 0.4657\n",
      "val Loss: 1.2710 Acc: 0.4967\n",
      "Time taken is 152 seconds\n",
      "\n",
      "Training complete in 187m 13s\n",
      "Best val Acc: 0.510777\n",
      "Val Acc >= 0.70: 0\n"
     ]
    }
   ],
   "source": [
    "### Train\n",
    "\n",
    "epochs = 70\n",
    "# epochs = 50\n",
    "\n",
    "model_ft = MultiSiameseContrastiveClassifierNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr = 0.0001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# learning_rate_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "learning_rate_scheduler = lr_scheduler.CyclicLR(optimizer_ft, base_lr=0.0001, max_lr=0.001, cycle_momentum=False)   # 0.001 seems better\n",
    "\n",
    "\n",
    "### Train \n",
    "\n",
    "# Logger\n",
    "model_save_folder = os.path.join(models_folder, \"contrastive_encoder\")\n",
    "log_handler = ModelSaveAndLogHandler(model_save_folder, enable_model_saving=True, enable_logging=True)   # init\n",
    "model_def_src_file_path = os.path.join(r\"D:\\Desktop\\projects\\speaker_recognition_voxceleb1\\scripts\", \"model_definitions.py\")\n",
    "log_handler.save_model_definition_file(model_def_src_file_path)   # copy model def file\n",
    "print(log_handler.folder)\n",
    "\n",
    "# Description\n",
    "log_handler.print(\"Description: Candidates: 5, Encoding: 128, Projection: None\")\n",
    "\n",
    "# Train\n",
    "# train_model(model_ft, criterion, optimizer_ft, learning_rate_scheduler, epochs, num_batches, training_data_generator, log_handler)\n",
    "train_model(model_ft, criterion, optimizer_ft, learning_rate_scheduler, epochs, training_data_generator, validation_data, log_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_acc = 1 / CANDIDATE_SIZE\n",
    "random_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Overall\n",
    "* Contrastive classifier\n",
    "    * separate train and validate methods\n",
    "\n",
    "* (Done) Model saving / checkpointing\n",
    "* **Build binary classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
