{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from config import models_folder, output_data_folder\n",
    "from config import n_mels\n",
    "\n",
    "from model_definitions import VerificationBinaryClassifierNet\n",
    "from data_generators import VerificationDataGenerator\n",
    "from project_utils import ModelSaveAndLogHandler, load_module_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = n_mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model_folder = os.path.join(models_folder, \"contrastive_encoder\", \"good_models\", \"2020-03-20_03-25-22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from contrastive training\n",
    "def load_pretrained_encoder_model():\n",
    "    module_file = os.path.join(encoder_model_folder, \"model_definitions.py\")\n",
    "    module_name = \"MultiSiameseContrastiveClassifierNet\"\n",
    "    module = load_module_from_file(module_file, module_name)\n",
    "    # load model\n",
    "    model = module.MultiSiameseContrastiveClassifierNet()\n",
    "    state_dict_file = os.path.join(encoder_model_folder, \"best_model_MultiSiameseContrastiveClassifierNet.pt\")\n",
    "    model.load_state_dict(torch.load(state_dict_file, map_location=\"cpu\"))\n",
    "    return model.encoder   # return pretrained encoder only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             864\n",
      "       BatchNorm2d-2           [-1, 32, 64, 64]              64\n",
      "             ReLU6-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]             288\n",
      "       BatchNorm2d-5           [-1, 32, 64, 64]              64\n",
      "             ReLU6-6           [-1, 32, 64, 64]               0\n",
      "            Conv2d-7           [-1, 16, 64, 64]             512\n",
      "       BatchNorm2d-8           [-1, 16, 64, 64]              32\n",
      "  InvertedResidual-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 96, 64, 64]           1,536\n",
      "      BatchNorm2d-11           [-1, 96, 64, 64]             192\n",
      "            ReLU6-12           [-1, 96, 64, 64]               0\n",
      "           Conv2d-13           [-1, 96, 32, 32]             864\n",
      "      BatchNorm2d-14           [-1, 96, 32, 32]             192\n",
      "            ReLU6-15           [-1, 96, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 32, 32]             288\n",
      "            ReLU6-21          [-1, 144, 32, 32]               0\n",
      "           Conv2d-22          [-1, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 32, 32]             288\n",
      "            ReLU6-24          [-1, 144, 32, 32]               0\n",
      "           Conv2d-25           [-1, 24, 32, 32]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-27           [-1, 24, 32, 32]               0\n",
      "           Conv2d-28          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 32, 32]             288\n",
      "            ReLU6-30          [-1, 144, 32, 32]               0\n",
      "           Conv2d-31          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 16, 16]             288\n",
      "            ReLU6-33          [-1, 144, 16, 16]               0\n",
      "           Conv2d-34           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-36           [-1, 32, 16, 16]               0\n",
      "           Conv2d-37          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 16, 16]             384\n",
      "            ReLU6-39          [-1, 192, 16, 16]               0\n",
      "           Conv2d-40          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 16, 16]             384\n",
      "            ReLU6-42          [-1, 192, 16, 16]               0\n",
      "           Conv2d-43           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-45           [-1, 32, 16, 16]               0\n",
      "           Conv2d-46          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 16, 16]             384\n",
      "            ReLU6-48          [-1, 192, 16, 16]               0\n",
      "           Conv2d-49          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 16, 16]             384\n",
      "            ReLU6-51          [-1, 192, 16, 16]               0\n",
      "           Conv2d-52           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 16, 16]             384\n",
      "            ReLU6-57          [-1, 192, 16, 16]               0\n",
      "           Conv2d-58            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-59            [-1, 192, 8, 8]             384\n",
      "            ReLU6-60            [-1, 192, 8, 8]               0\n",
      "           Conv2d-61             [-1, 64, 8, 8]          12,288\n",
      "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-63             [-1, 64, 8, 8]               0\n",
      "           Conv2d-64            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-65            [-1, 384, 8, 8]             768\n",
      "            ReLU6-66            [-1, 384, 8, 8]               0\n",
      "           Conv2d-67            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-68            [-1, 384, 8, 8]             768\n",
      "            ReLU6-69            [-1, 384, 8, 8]               0\n",
      "           Conv2d-70             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-71             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-72             [-1, 64, 8, 8]               0\n",
      "           Conv2d-73            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-74            [-1, 384, 8, 8]             768\n",
      "            ReLU6-75            [-1, 384, 8, 8]               0\n",
      "           Conv2d-76            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-77            [-1, 384, 8, 8]             768\n",
      "            ReLU6-78            [-1, 384, 8, 8]               0\n",
      "           Conv2d-79             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-81             [-1, 64, 8, 8]               0\n",
      "           Conv2d-82            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-83            [-1, 384, 8, 8]             768\n",
      "            ReLU6-84            [-1, 384, 8, 8]               0\n",
      "           Conv2d-85            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-86            [-1, 384, 8, 8]             768\n",
      "            ReLU6-87            [-1, 384, 8, 8]               0\n",
      "           Conv2d-88             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-90             [-1, 64, 8, 8]               0\n",
      "           Conv2d-91            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-92            [-1, 384, 8, 8]             768\n",
      "            ReLU6-93            [-1, 384, 8, 8]               0\n",
      "           Conv2d-94            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-95            [-1, 384, 8, 8]             768\n",
      "            ReLU6-96            [-1, 384, 8, 8]               0\n",
      "           Conv2d-97             [-1, 96, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 96, 8, 8]             192\n",
      " InvertedResidual-99             [-1, 96, 8, 8]               0\n",
      "          Conv2d-100            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-101            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-102            [-1, 576, 8, 8]               0\n",
      "          Conv2d-103            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-104            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-105            [-1, 576, 8, 8]               0\n",
      "          Conv2d-106             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-107             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-108             [-1, 96, 8, 8]               0\n",
      "          Conv2d-109            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-110            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-111            [-1, 576, 8, 8]               0\n",
      "          Conv2d-112            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-113            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-114            [-1, 576, 8, 8]               0\n",
      "          Conv2d-115             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-116             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-117             [-1, 96, 8, 8]               0\n",
      "          Conv2d-118            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-119            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-120            [-1, 576, 8, 8]               0\n",
      "          Conv2d-121            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-123            [-1, 576, 4, 4]               0\n",
      "          Conv2d-124            [-1, 160, 4, 4]          92,160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-125            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-126            [-1, 160, 4, 4]               0\n",
      "          Conv2d-127            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-129            [-1, 960, 4, 4]               0\n",
      "          Conv2d-130            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-132            [-1, 960, 4, 4]               0\n",
      "          Conv2d-133            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-135            [-1, 160, 4, 4]               0\n",
      "          Conv2d-136            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-138            [-1, 960, 4, 4]               0\n",
      "          Conv2d-139            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-141            [-1, 960, 4, 4]               0\n",
      "          Conv2d-142            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-144            [-1, 160, 4, 4]               0\n",
      "          Conv2d-145            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-147            [-1, 960, 4, 4]               0\n",
      "          Conv2d-148            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-150            [-1, 960, 4, 4]               0\n",
      "          Conv2d-151            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-153            [-1, 320, 4, 4]               0\n",
      "          Conv2d-154           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-156           [-1, 1280, 4, 4]               0\n",
      "          Linear-157                  [-1, 128]         163,968\n",
      "     MobileNetV2-158                  [-1, 128]               0\n",
      "================================================================\n",
      "Total params: 2,387,840\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,387,840\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 49.91\n",
      "Params size (MB): 9.11\n",
      "Estimated Total Size (MB): 59.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Encoder model\n",
    "encoder_model = load_pretrained_encoder_model()\n",
    "for param in encoder_model.parameters(): param.requires_grad = False   # freeze encoder layers\n",
    "summary(encoder_model, input_size=(3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             864\n",
      "       BatchNorm2d-2           [-1, 32, 64, 64]              64\n",
      "             ReLU6-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]             288\n",
      "       BatchNorm2d-5           [-1, 32, 64, 64]              64\n",
      "             ReLU6-6           [-1, 32, 64, 64]               0\n",
      "            Conv2d-7           [-1, 16, 64, 64]             512\n",
      "       BatchNorm2d-8           [-1, 16, 64, 64]              32\n",
      "  InvertedResidual-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 96, 64, 64]           1,536\n",
      "      BatchNorm2d-11           [-1, 96, 64, 64]             192\n",
      "            ReLU6-12           [-1, 96, 64, 64]               0\n",
      "           Conv2d-13           [-1, 96, 32, 32]             864\n",
      "      BatchNorm2d-14           [-1, 96, 32, 32]             192\n",
      "            ReLU6-15           [-1, 96, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 32, 32]             288\n",
      "            ReLU6-21          [-1, 144, 32, 32]               0\n",
      "           Conv2d-22          [-1, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 32, 32]             288\n",
      "            ReLU6-24          [-1, 144, 32, 32]               0\n",
      "           Conv2d-25           [-1, 24, 32, 32]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-27           [-1, 24, 32, 32]               0\n",
      "           Conv2d-28          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 32, 32]             288\n",
      "            ReLU6-30          [-1, 144, 32, 32]               0\n",
      "           Conv2d-31          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 16, 16]             288\n",
      "            ReLU6-33          [-1, 144, 16, 16]               0\n",
      "           Conv2d-34           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-36           [-1, 32, 16, 16]               0\n",
      "           Conv2d-37          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 16, 16]             384\n",
      "            ReLU6-39          [-1, 192, 16, 16]               0\n",
      "           Conv2d-40          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 16, 16]             384\n",
      "            ReLU6-42          [-1, 192, 16, 16]               0\n",
      "           Conv2d-43           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-45           [-1, 32, 16, 16]               0\n",
      "           Conv2d-46          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 16, 16]             384\n",
      "            ReLU6-48          [-1, 192, 16, 16]               0\n",
      "           Conv2d-49          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 16, 16]             384\n",
      "            ReLU6-51          [-1, 192, 16, 16]               0\n",
      "           Conv2d-52           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 16, 16]             384\n",
      "            ReLU6-57          [-1, 192, 16, 16]               0\n",
      "           Conv2d-58            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-59            [-1, 192, 8, 8]             384\n",
      "            ReLU6-60            [-1, 192, 8, 8]               0\n",
      "           Conv2d-61             [-1, 64, 8, 8]          12,288\n",
      "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-63             [-1, 64, 8, 8]               0\n",
      "           Conv2d-64            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-65            [-1, 384, 8, 8]             768\n",
      "            ReLU6-66            [-1, 384, 8, 8]               0\n",
      "           Conv2d-67            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-68            [-1, 384, 8, 8]             768\n",
      "            ReLU6-69            [-1, 384, 8, 8]               0\n",
      "           Conv2d-70             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-71             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-72             [-1, 64, 8, 8]               0\n",
      "           Conv2d-73            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-74            [-1, 384, 8, 8]             768\n",
      "            ReLU6-75            [-1, 384, 8, 8]               0\n",
      "           Conv2d-76            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-77            [-1, 384, 8, 8]             768\n",
      "            ReLU6-78            [-1, 384, 8, 8]               0\n",
      "           Conv2d-79             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-81             [-1, 64, 8, 8]               0\n",
      "           Conv2d-82            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-83            [-1, 384, 8, 8]             768\n",
      "            ReLU6-84            [-1, 384, 8, 8]               0\n",
      "           Conv2d-85            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-86            [-1, 384, 8, 8]             768\n",
      "            ReLU6-87            [-1, 384, 8, 8]               0\n",
      "           Conv2d-88             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-90             [-1, 64, 8, 8]               0\n",
      "           Conv2d-91            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-92            [-1, 384, 8, 8]             768\n",
      "            ReLU6-93            [-1, 384, 8, 8]               0\n",
      "           Conv2d-94            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-95            [-1, 384, 8, 8]             768\n",
      "            ReLU6-96            [-1, 384, 8, 8]               0\n",
      "           Conv2d-97             [-1, 96, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 96, 8, 8]             192\n",
      " InvertedResidual-99             [-1, 96, 8, 8]               0\n",
      "          Conv2d-100            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-101            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-102            [-1, 576, 8, 8]               0\n",
      "          Conv2d-103            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-104            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-105            [-1, 576, 8, 8]               0\n",
      "          Conv2d-106             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-107             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-108             [-1, 96, 8, 8]               0\n",
      "          Conv2d-109            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-110            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-111            [-1, 576, 8, 8]               0\n",
      "          Conv2d-112            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-113            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-114            [-1, 576, 8, 8]               0\n",
      "          Conv2d-115             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-116             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-117             [-1, 96, 8, 8]               0\n",
      "          Conv2d-118            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-119            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-120            [-1, 576, 8, 8]               0\n",
      "          Conv2d-121            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-123            [-1, 576, 4, 4]               0\n",
      "          Conv2d-124            [-1, 160, 4, 4]          92,160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-125            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-126            [-1, 160, 4, 4]               0\n",
      "          Conv2d-127            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-129            [-1, 960, 4, 4]               0\n",
      "          Conv2d-130            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-132            [-1, 960, 4, 4]               0\n",
      "          Conv2d-133            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-135            [-1, 160, 4, 4]               0\n",
      "          Conv2d-136            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-138            [-1, 960, 4, 4]               0\n",
      "          Conv2d-139            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-141            [-1, 960, 4, 4]               0\n",
      "          Conv2d-142            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-144            [-1, 160, 4, 4]               0\n",
      "          Conv2d-145            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-147            [-1, 960, 4, 4]               0\n",
      "          Conv2d-148            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-150            [-1, 960, 4, 4]               0\n",
      "          Conv2d-151            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-153            [-1, 320, 4, 4]               0\n",
      "          Conv2d-154           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-156           [-1, 1280, 4, 4]               0\n",
      "          Linear-157                  [-1, 128]         163,968\n",
      "     MobileNetV2-158                  [-1, 128]               0\n",
      "SpectrogramEncoderNet-159                  [-1, 128]               0\n",
      "          Conv2d-160           [-1, 32, 64, 64]             864\n",
      "     BatchNorm2d-161           [-1, 32, 64, 64]              64\n",
      "           ReLU6-162           [-1, 32, 64, 64]               0\n",
      "          Conv2d-163           [-1, 32, 64, 64]             288\n",
      "     BatchNorm2d-164           [-1, 32, 64, 64]              64\n",
      "           ReLU6-165           [-1, 32, 64, 64]               0\n",
      "          Conv2d-166           [-1, 16, 64, 64]             512\n",
      "     BatchNorm2d-167           [-1, 16, 64, 64]              32\n",
      "InvertedResidual-168           [-1, 16, 64, 64]               0\n",
      "          Conv2d-169           [-1, 96, 64, 64]           1,536\n",
      "     BatchNorm2d-170           [-1, 96, 64, 64]             192\n",
      "           ReLU6-171           [-1, 96, 64, 64]               0\n",
      "          Conv2d-172           [-1, 96, 32, 32]             864\n",
      "     BatchNorm2d-173           [-1, 96, 32, 32]             192\n",
      "           ReLU6-174           [-1, 96, 32, 32]               0\n",
      "          Conv2d-175           [-1, 24, 32, 32]           2,304\n",
      "     BatchNorm2d-176           [-1, 24, 32, 32]              48\n",
      "InvertedResidual-177           [-1, 24, 32, 32]               0\n",
      "          Conv2d-178          [-1, 144, 32, 32]           3,456\n",
      "     BatchNorm2d-179          [-1, 144, 32, 32]             288\n",
      "           ReLU6-180          [-1, 144, 32, 32]               0\n",
      "          Conv2d-181          [-1, 144, 32, 32]           1,296\n",
      "     BatchNorm2d-182          [-1, 144, 32, 32]             288\n",
      "           ReLU6-183          [-1, 144, 32, 32]               0\n",
      "          Conv2d-184           [-1, 24, 32, 32]           3,456\n",
      "     BatchNorm2d-185           [-1, 24, 32, 32]              48\n",
      "InvertedResidual-186           [-1, 24, 32, 32]               0\n",
      "          Conv2d-187          [-1, 144, 32, 32]           3,456\n",
      "     BatchNorm2d-188          [-1, 144, 32, 32]             288\n",
      "           ReLU6-189          [-1, 144, 32, 32]               0\n",
      "          Conv2d-190          [-1, 144, 16, 16]           1,296\n",
      "     BatchNorm2d-191          [-1, 144, 16, 16]             288\n",
      "           ReLU6-192          [-1, 144, 16, 16]               0\n",
      "          Conv2d-193           [-1, 32, 16, 16]           4,608\n",
      "     BatchNorm2d-194           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-195           [-1, 32, 16, 16]               0\n",
      "          Conv2d-196          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-197          [-1, 192, 16, 16]             384\n",
      "           ReLU6-198          [-1, 192, 16, 16]               0\n",
      "          Conv2d-199          [-1, 192, 16, 16]           1,728\n",
      "     BatchNorm2d-200          [-1, 192, 16, 16]             384\n",
      "           ReLU6-201          [-1, 192, 16, 16]               0\n",
      "          Conv2d-202           [-1, 32, 16, 16]           6,144\n",
      "     BatchNorm2d-203           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-204           [-1, 32, 16, 16]               0\n",
      "          Conv2d-205          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-206          [-1, 192, 16, 16]             384\n",
      "           ReLU6-207          [-1, 192, 16, 16]               0\n",
      "          Conv2d-208          [-1, 192, 16, 16]           1,728\n",
      "     BatchNorm2d-209          [-1, 192, 16, 16]             384\n",
      "           ReLU6-210          [-1, 192, 16, 16]               0\n",
      "          Conv2d-211           [-1, 32, 16, 16]           6,144\n",
      "     BatchNorm2d-212           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-213           [-1, 32, 16, 16]               0\n",
      "          Conv2d-214          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-215          [-1, 192, 16, 16]             384\n",
      "           ReLU6-216          [-1, 192, 16, 16]               0\n",
      "          Conv2d-217            [-1, 192, 8, 8]           1,728\n",
      "     BatchNorm2d-218            [-1, 192, 8, 8]             384\n",
      "           ReLU6-219            [-1, 192, 8, 8]               0\n",
      "          Conv2d-220             [-1, 64, 8, 8]          12,288\n",
      "     BatchNorm2d-221             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-222             [-1, 64, 8, 8]               0\n",
      "          Conv2d-223            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-224            [-1, 384, 8, 8]             768\n",
      "           ReLU6-225            [-1, 384, 8, 8]               0\n",
      "          Conv2d-226            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-227            [-1, 384, 8, 8]             768\n",
      "           ReLU6-228            [-1, 384, 8, 8]               0\n",
      "          Conv2d-229             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-230             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-231             [-1, 64, 8, 8]               0\n",
      "          Conv2d-232            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-233            [-1, 384, 8, 8]             768\n",
      "           ReLU6-234            [-1, 384, 8, 8]               0\n",
      "          Conv2d-235            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-236            [-1, 384, 8, 8]             768\n",
      "           ReLU6-237            [-1, 384, 8, 8]               0\n",
      "          Conv2d-238             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-239             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-240             [-1, 64, 8, 8]               0\n",
      "          Conv2d-241            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-242            [-1, 384, 8, 8]             768\n",
      "           ReLU6-243            [-1, 384, 8, 8]               0\n",
      "          Conv2d-244            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-245            [-1, 384, 8, 8]             768\n",
      "           ReLU6-246            [-1, 384, 8, 8]               0\n",
      "          Conv2d-247             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-248             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-249             [-1, 64, 8, 8]               0\n",
      "          Conv2d-250            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-251            [-1, 384, 8, 8]             768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ReLU6-252            [-1, 384, 8, 8]               0\n",
      "          Conv2d-253            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-254            [-1, 384, 8, 8]             768\n",
      "           ReLU6-255            [-1, 384, 8, 8]               0\n",
      "          Conv2d-256             [-1, 96, 8, 8]          36,864\n",
      "     BatchNorm2d-257             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-258             [-1, 96, 8, 8]               0\n",
      "          Conv2d-259            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-260            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-261            [-1, 576, 8, 8]               0\n",
      "          Conv2d-262            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-263            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-264            [-1, 576, 8, 8]               0\n",
      "          Conv2d-265             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-266             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-267             [-1, 96, 8, 8]               0\n",
      "          Conv2d-268            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-269            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-270            [-1, 576, 8, 8]               0\n",
      "          Conv2d-271            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-272            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-273            [-1, 576, 8, 8]               0\n",
      "          Conv2d-274             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-275             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-276             [-1, 96, 8, 8]               0\n",
      "          Conv2d-277            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-278            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-279            [-1, 576, 8, 8]               0\n",
      "          Conv2d-280            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-281            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-282            [-1, 576, 4, 4]               0\n",
      "          Conv2d-283            [-1, 160, 4, 4]          92,160\n",
      "     BatchNorm2d-284            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-285            [-1, 160, 4, 4]               0\n",
      "          Conv2d-286            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-287            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-288            [-1, 960, 4, 4]               0\n",
      "          Conv2d-289            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-290            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-291            [-1, 960, 4, 4]               0\n",
      "          Conv2d-292            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-293            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-294            [-1, 160, 4, 4]               0\n",
      "          Conv2d-295            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-296            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-297            [-1, 960, 4, 4]               0\n",
      "          Conv2d-298            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-299            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-300            [-1, 960, 4, 4]               0\n",
      "          Conv2d-301            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-302            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-303            [-1, 160, 4, 4]               0\n",
      "          Conv2d-304            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-305            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-306            [-1, 960, 4, 4]               0\n",
      "          Conv2d-307            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-308            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-309            [-1, 960, 4, 4]               0\n",
      "          Conv2d-310            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-311            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-312            [-1, 320, 4, 4]               0\n",
      "          Conv2d-313           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-314           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-315           [-1, 1280, 4, 4]               0\n",
      "          Linear-316                  [-1, 128]         163,968\n",
      "     MobileNetV2-317                  [-1, 128]               0\n",
      "SpectrogramEncoderNet-318                  [-1, 128]               0\n",
      "            Tanh-319                  [-1, 128]               0\n",
      "          Linear-320                  [-1, 128]          16,512\n",
      "            ReLU-321                  [-1, 128]               0\n",
      "          Linear-322                  [-1, 128]          16,512\n",
      "            ReLU-323                  [-1, 128]               0\n",
      "          Linear-324                  [-1, 128]          16,512\n",
      "            ReLU-325                  [-1, 128]               0\n",
      "          Linear-326                  [-1, 128]          16,512\n",
      "            ReLU-327                  [-1, 128]               0\n",
      "          Linear-328                    [-1, 2]             258\n",
      "================================================================\n",
      "Total params: 4,841,986\n",
      "Trainable params: 66,306\n",
      "Non-trainable params: 4,775,680\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.38\n",
      "Forward/backward pass size (MB): 99.83\n",
      "Params size (MB): 18.47\n",
      "Estimated Total Size (MB): 118.68\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Verification Binary classifier\n",
    "summary(VerificationBinaryClassifierNet(encoder_model), input_size=(2, 3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training data\n",
    "training_folder = os.path.join(output_data_folder, \"training_dataset_full_spectrogram/vox1_dev_wav\")\n",
    "spectrogram_samples_files = [os.path.join(training_folder, file) for file in os.listdir(training_folder)]\n",
    "batch_size = 160\n",
    "# num_batches = 1000 // batch_size\n",
    "num_batches = 2000 // batch_size\n",
    "# num_batches = 400 // batch_size\n",
    "# num_sub_samples = 100\n",
    "num_sub_samples = 200\n",
    "# num_sub_samples = 20\n",
    "training_data_generator = VerificationDataGenerator(spectrogram_samples_files, batch_size, num_batches, num_sub_samples, IMG_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validation data\n",
    "validation_set_file = os.path.join(output_data_folder, \"validation_sets\", \"verification_validation_set.pickle\")\n",
    "with open(validation_set_file, 'rb') as f:\n",
    "    validation_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, training_data_generator, validation_data, log_handler):\n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "    count_more_than_70 = 0\n",
    "\n",
    "    t1 = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        log_handler.print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        log_handler.print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            batches_used = 0\n",
    "            data_generator = training_data_generator.generate_batches() if phase == 'train' else validation_data\n",
    "            for data in data_generator:\n",
    "                batches_used += 1\n",
    "                input_imgs, labels = data\n",
    "                inputs = [img.to(device) for img in input_imgs]\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):   # gradient only for train\n",
    "                    outputs = model(inputs)   \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs[0].size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            \n",
    "            epoch_loss = running_loss / (batches_used * inputs[0].size(0))\n",
    "            epoch_acc = running_corrects.double() / (batches_used * inputs[0].size(0))\n",
    "            log_handler.print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                log_handler.save_pytorch_model(model, \"best_model_{}.pt\".format(model.__class__.__name__))\n",
    "                example = [torch.rand(1, 3, IMG_HEIGHT, IMG_HEIGHT), torch.rand(1, 3, IMG_HEIGHT, IMG_HEIGHT)]\n",
    "                log_handler.save_pytorch_model_as_torchscript(model, \"mobile_model.pt\", (example,))\n",
    "            # Track val acc >= 70%\n",
    "            if phase == 'val' and epoch_acc >= 0.70: count_more_than_70 += 1\n",
    "\n",
    "        # end of epoch\n",
    "        log_handler.print(\"Time taken is {} seconds\".format(int(time.time()-t1)))\n",
    "        t1 = time.time()\n",
    "        log_handler.print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    log_handler.print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    log_handler.print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    log_handler.print('Val Acc >= 0.70: {}'.format(count_more_than_70))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Desktop\\projects\\speaker_recognition_voxceleb1\\output_data\\models\\verification_classifier\\2020-03-20_12-20-57\n",
      "Encoder: D:\\Desktop\\projects\\speaker_recognition_voxceleb1\\output_data\\models\\contrastive_encoder\\good_models\\2020-03-20_03-25-22\n",
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 0.6906 Acc: 0.5000\n",
      "val Loss: 0.6881 Acc: 0.5000\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 96 seconds\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.6865 Acc: 0.5000\n",
      "val Loss: 0.6831 Acc: 0.5000\n",
      "Time taken is 78 seconds\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.6807 Acc: 0.5036\n",
      "val Loss: 0.6769 Acc: 0.5143\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 100 seconds\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.6748 Acc: 0.5310\n",
      "val Loss: 0.6681 Acc: 0.5602\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 78 seconds\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.6650 Acc: 0.5716\n",
      "val Loss: 0.6556 Acc: 0.6018\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 109 seconds\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.6504 Acc: 0.6232\n",
      "val Loss: 0.6373 Acc: 0.6529\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 85 seconds\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.6305 Acc: 0.6659\n",
      "val Loss: 0.6122 Acc: 0.6849\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 106 seconds\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.5962 Acc: 0.7044\n",
      "val Loss: 0.5846 Acc: 0.6924\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 87 seconds\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.5700 Acc: 0.7091\n",
      "val Loss: 0.5553 Acc: 0.7224\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 86 seconds\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.5449 Acc: 0.7302\n",
      "val Loss: 0.5336 Acc: 0.7346\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 81 seconds\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.5242 Acc: 0.7383\n",
      "val Loss: 0.5170 Acc: 0.7510\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 83 seconds\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.5240 Acc: 0.7375\n",
      "val Loss: 0.5139 Acc: 0.7526\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 81 seconds\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.5269 Acc: 0.7323\n",
      "val Loss: 0.5080 Acc: 0.7471\n",
      "Time taken is 95 seconds\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.5227 Acc: 0.7339\n",
      "val Loss: 0.5049 Acc: 0.7573\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 86 seconds\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.5138 Acc: 0.7424\n",
      "val Loss: 0.5024 Acc: 0.7560\n",
      "Time taken is 81 seconds\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.5213 Acc: 0.7422\n",
      "val Loss: 0.5017 Acc: 0.7565\n",
      "Time taken is 87 seconds\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.5217 Acc: 0.7385\n",
      "val Loss: 0.4975 Acc: 0.7560\n",
      "Time taken is 78 seconds\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.5102 Acc: 0.7526\n",
      "val Loss: 0.5013 Acc: 0.7648\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 81 seconds\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.5204 Acc: 0.7362\n",
      "val Loss: 0.5064 Acc: 0.7622\n",
      "Time taken is 76 seconds\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.5014 Acc: 0.7513\n",
      "val Loss: 0.4974 Acc: 0.7560\n",
      "Time taken is 74 seconds\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.5045 Acc: 0.7516\n",
      "val Loss: 0.4944 Acc: 0.7646\n",
      "Time taken is 99 seconds\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.5240 Acc: 0.7307\n",
      "val Loss: 0.4938 Acc: 0.7549\n",
      "Time taken is 78 seconds\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.4932 Acc: 0.7633\n",
      "val Loss: 0.4917 Acc: 0.7607\n",
      "Time taken is 78 seconds\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.5232 Acc: 0.7357\n",
      "val Loss: 0.4943 Acc: 0.7654\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 81 seconds\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.5169 Acc: 0.7385\n",
      "val Loss: 0.4975 Acc: 0.7633\n",
      "Time taken is 74 seconds\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.5081 Acc: 0.7430\n",
      "val Loss: 0.4925 Acc: 0.7622\n",
      "Time taken is 75 seconds\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.5148 Acc: 0.7427\n",
      "val Loss: 0.4950 Acc: 0.7651\n",
      "Time taken is 79 seconds\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.5149 Acc: 0.7383\n",
      "val Loss: 0.4906 Acc: 0.7612\n",
      "Time taken is 78 seconds\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.5132 Acc: 0.7385\n",
      "val Loss: 0.4900 Acc: 0.7622\n",
      "Time taken is 78 seconds\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.5028 Acc: 0.7484\n",
      "val Loss: 0.4878 Acc: 0.7625\n",
      "Time taken is 74 seconds\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.5215 Acc: 0.7349\n",
      "val Loss: 0.4883 Acc: 0.7622\n",
      "Time taken is 83 seconds\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.5260 Acc: 0.7292\n",
      "val Loss: 0.4890 Acc: 0.7667\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 78 seconds\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.4944 Acc: 0.7607\n",
      "val Loss: 0.4888 Acc: 0.7609\n",
      "Time taken is 78 seconds\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.5064 Acc: 0.7458\n",
      "val Loss: 0.4862 Acc: 0.7625\n",
      "Time taken is 75 seconds\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.4949 Acc: 0.7536\n",
      "val Loss: 0.4873 Acc: 0.7635\n",
      "Time taken is 90 seconds\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.5110 Acc: 0.7448\n",
      "val Loss: 0.4915 Acc: 0.7664\n",
      "Time taken is 78 seconds\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.5157 Acc: 0.7333\n",
      "val Loss: 0.4882 Acc: 0.7667\n",
      "Time taken is 79 seconds\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.5009 Acc: 0.7440\n",
      "val Loss: 0.4917 Acc: 0.7633\n",
      "Time taken is 73 seconds\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.4943 Acc: 0.7510\n",
      "val Loss: 0.4882 Acc: 0.7641\n",
      "Time taken is 84 seconds\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.5124 Acc: 0.7456\n",
      "val Loss: 0.4863 Acc: 0.7620\n",
      "Time taken is 74 seconds\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.4934 Acc: 0.7565\n",
      "val Loss: 0.4853 Acc: 0.7672\n",
      "MODEL SAVED\n",
      "MODEL SAVED (MOBILE)\n",
      "Time taken is 88 seconds\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.5041 Acc: 0.7456\n",
      "val Loss: 0.4864 Acc: 0.7630\n",
      "Time taken is 76 seconds\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.5056 Acc: 0.7482\n",
      "val Loss: 0.4869 Acc: 0.7635\n",
      "Time taken is 88 seconds\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.4978 Acc: 0.7490\n",
      "val Loss: 0.5009 Acc: 0.7549\n",
      "Time taken is 74 seconds\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.5168 Acc: 0.7424\n",
      "val Loss: 0.4876 Acc: 0.7615\n",
      "Time taken is 87 seconds\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.5049 Acc: 0.7474\n",
      "val Loss: 0.4903 Acc: 0.7651\n",
      "Time taken is 75 seconds\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.5119 Acc: 0.7430\n",
      "val Loss: 0.4917 Acc: 0.7539\n",
      "Time taken is 85 seconds\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.5023 Acc: 0.7375\n",
      "val Loss: 0.4935 Acc: 0.7620\n",
      "Time taken is 76 seconds\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.5059 Acc: 0.7427\n",
      "val Loss: 0.4845 Acc: 0.7672\n",
      "Time taken is 90 seconds\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.4981 Acc: 0.7539\n",
      "val Loss: 0.4863 Acc: 0.7620\n",
      "Time taken is 72 seconds\n",
      "\n",
      "Training complete in 69m 8s\n",
      "Best val Acc: 0.767188\n",
      "Val Acc >= 0.70: 42\n"
     ]
    }
   ],
   "source": [
    "### Train\n",
    "\n",
    "# epochs = 70\n",
    "epochs = 50\n",
    "\n",
    "model_ft = VerificationBinaryClassifierNet(encoder_model).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr = 0.0001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# learning_rate_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "learning_rate_scheduler = lr_scheduler.CyclicLR(optimizer_ft, base_lr=0.0001, max_lr=0.01, cycle_momentum=False)   # 0.01 seems better\n",
    "\n",
    "### Train \n",
    "\n",
    "# Logger\n",
    "model_save_folder = os.path.join(models_folder, \"verification_classifier\")\n",
    "log_handler = ModelSaveAndLogHandler(model_save_folder, enable_model_saving=True, enable_logging=True)   # init\n",
    "model_def_src_file_path = os.path.join(r\"D:\\Desktop\\projects\\speaker_recognition_voxceleb1\\scripts\", \"model_definitions.py\")\n",
    "log_handler.save_model_definition_file(model_def_src_file_path)   # copy model def file\n",
    "print(log_handler.folder)\n",
    "\n",
    "# Description\n",
    "log_handler.print(\"Encoder: {}\".format(encoder_model_folder))\n",
    "\n",
    "# Train\n",
    "train_model(model_ft, criterion, optimizer_ft, learning_rate_scheduler, epochs, training_data_generator, validation_data, log_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log_handler.print(\"Encoder weights not frozen\")\n",
    "random_acc = 1 / 2\n",
    "random_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Overall\n",
    "* **Change spectrogram size?**\n",
    "* **Contrastive classifier**\n",
    "    * Implement intraclass variance reduction\n",
    "* **Verification binary classifier**\n",
    "    * Implement EER metric\n",
    "    * Build 2nd validation set? (accent dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
