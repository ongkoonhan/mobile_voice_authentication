{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "from project_utils import ModelSaveAndLogHandler\n",
    "from config import models_folder, output_data_folder\n",
    "from config import n_mels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = n_mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model_folder = os.path.join(models_folder, \"contrastive_encoder\", \"2020-03-15_16-49-51\")\n",
    "encoder_model_file = os.path.join(encoder_model_folder, \"best_model_MultiSiameseEncoderNet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             864\n",
      "       BatchNorm2d-2           [-1, 32, 64, 64]              64\n",
      "             ReLU6-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]             288\n",
      "       BatchNorm2d-5           [-1, 32, 64, 64]              64\n",
      "             ReLU6-6           [-1, 32, 64, 64]               0\n",
      "            Conv2d-7           [-1, 16, 64, 64]             512\n",
      "       BatchNorm2d-8           [-1, 16, 64, 64]              32\n",
      "  InvertedResidual-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 96, 64, 64]           1,536\n",
      "      BatchNorm2d-11           [-1, 96, 64, 64]             192\n",
      "            ReLU6-12           [-1, 96, 64, 64]               0\n",
      "           Conv2d-13           [-1, 96, 32, 32]             864\n",
      "      BatchNorm2d-14           [-1, 96, 32, 32]             192\n",
      "            ReLU6-15           [-1, 96, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 32, 32]             288\n",
      "            ReLU6-21          [-1, 144, 32, 32]               0\n",
      "           Conv2d-22          [-1, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 32, 32]             288\n",
      "            ReLU6-24          [-1, 144, 32, 32]               0\n",
      "           Conv2d-25           [-1, 24, 32, 32]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-27           [-1, 24, 32, 32]               0\n",
      "           Conv2d-28          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 32, 32]             288\n",
      "            ReLU6-30          [-1, 144, 32, 32]               0\n",
      "           Conv2d-31          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 16, 16]             288\n",
      "            ReLU6-33          [-1, 144, 16, 16]               0\n",
      "           Conv2d-34           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-36           [-1, 32, 16, 16]               0\n",
      "           Conv2d-37          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 16, 16]             384\n",
      "            ReLU6-39          [-1, 192, 16, 16]               0\n",
      "           Conv2d-40          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 16, 16]             384\n",
      "            ReLU6-42          [-1, 192, 16, 16]               0\n",
      "           Conv2d-43           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-45           [-1, 32, 16, 16]               0\n",
      "           Conv2d-46          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 16, 16]             384\n",
      "            ReLU6-48          [-1, 192, 16, 16]               0\n",
      "           Conv2d-49          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 16, 16]             384\n",
      "            ReLU6-51          [-1, 192, 16, 16]               0\n",
      "           Conv2d-52           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 16, 16]             384\n",
      "            ReLU6-57          [-1, 192, 16, 16]               0\n",
      "           Conv2d-58            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-59            [-1, 192, 8, 8]             384\n",
      "            ReLU6-60            [-1, 192, 8, 8]               0\n",
      "           Conv2d-61             [-1, 64, 8, 8]          12,288\n",
      "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-63             [-1, 64, 8, 8]               0\n",
      "           Conv2d-64            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-65            [-1, 384, 8, 8]             768\n",
      "            ReLU6-66            [-1, 384, 8, 8]               0\n",
      "           Conv2d-67            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-68            [-1, 384, 8, 8]             768\n",
      "            ReLU6-69            [-1, 384, 8, 8]               0\n",
      "           Conv2d-70             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-71             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-72             [-1, 64, 8, 8]               0\n",
      "           Conv2d-73            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-74            [-1, 384, 8, 8]             768\n",
      "            ReLU6-75            [-1, 384, 8, 8]               0\n",
      "           Conv2d-76            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-77            [-1, 384, 8, 8]             768\n",
      "            ReLU6-78            [-1, 384, 8, 8]               0\n",
      "           Conv2d-79             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-81             [-1, 64, 8, 8]               0\n",
      "           Conv2d-82            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-83            [-1, 384, 8, 8]             768\n",
      "            ReLU6-84            [-1, 384, 8, 8]               0\n",
      "           Conv2d-85            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-86            [-1, 384, 8, 8]             768\n",
      "            ReLU6-87            [-1, 384, 8, 8]               0\n",
      "           Conv2d-88             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-90             [-1, 64, 8, 8]               0\n",
      "           Conv2d-91            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-92            [-1, 384, 8, 8]             768\n",
      "            ReLU6-93            [-1, 384, 8, 8]               0\n",
      "           Conv2d-94            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-95            [-1, 384, 8, 8]             768\n",
      "            ReLU6-96            [-1, 384, 8, 8]               0\n",
      "           Conv2d-97             [-1, 96, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 96, 8, 8]             192\n",
      " InvertedResidual-99             [-1, 96, 8, 8]               0\n",
      "          Conv2d-100            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-101            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-102            [-1, 576, 8, 8]               0\n",
      "          Conv2d-103            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-104            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-105            [-1, 576, 8, 8]               0\n",
      "          Conv2d-106             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-107             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-108             [-1, 96, 8, 8]               0\n",
      "          Conv2d-109            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-110            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-111            [-1, 576, 8, 8]               0\n",
      "          Conv2d-112            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-113            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-114            [-1, 576, 8, 8]               0\n",
      "          Conv2d-115             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-116             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-117             [-1, 96, 8, 8]               0\n",
      "          Conv2d-118            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-119            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-120            [-1, 576, 8, 8]               0\n",
      "          Conv2d-121            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-123            [-1, 576, 4, 4]               0\n",
      "          Conv2d-124            [-1, 160, 4, 4]          92,160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-125            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-126            [-1, 160, 4, 4]               0\n",
      "          Conv2d-127            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-129            [-1, 960, 4, 4]               0\n",
      "          Conv2d-130            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-132            [-1, 960, 4, 4]               0\n",
      "          Conv2d-133            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-135            [-1, 160, 4, 4]               0\n",
      "          Conv2d-136            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-138            [-1, 960, 4, 4]               0\n",
      "          Conv2d-139            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-141            [-1, 960, 4, 4]               0\n",
      "          Conv2d-142            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-144            [-1, 160, 4, 4]               0\n",
      "          Conv2d-145            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-147            [-1, 960, 4, 4]               0\n",
      "          Conv2d-148            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-150            [-1, 960, 4, 4]               0\n",
      "          Conv2d-151            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-153            [-1, 320, 4, 4]               0\n",
      "          Conv2d-154           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-156           [-1, 1280, 4, 4]               0\n",
      "          Linear-157                  [-1, 512]         655,872\n",
      "     MobileNetV2-158                  [-1, 512]               0\n",
      "================================================================\n",
      "Total params: 2,879,744\n",
      "Trainable params: 2,879,744\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 49.92\n",
      "Params size (MB): 10.99\n",
      "Estimated Total Size (MB): 61.09\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             864\n",
      "       BatchNorm2d-2           [-1, 32, 64, 64]              64\n",
      "             ReLU6-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]             288\n",
      "       BatchNorm2d-5           [-1, 32, 64, 64]              64\n",
      "             ReLU6-6           [-1, 32, 64, 64]               0\n",
      "            Conv2d-7           [-1, 16, 64, 64]             512\n",
      "       BatchNorm2d-8           [-1, 16, 64, 64]              32\n",
      "  InvertedResidual-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 96, 64, 64]           1,536\n",
      "      BatchNorm2d-11           [-1, 96, 64, 64]             192\n",
      "            ReLU6-12           [-1, 96, 64, 64]               0\n",
      "           Conv2d-13           [-1, 96, 32, 32]             864\n",
      "      BatchNorm2d-14           [-1, 96, 32, 32]             192\n",
      "            ReLU6-15           [-1, 96, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 32, 32]             288\n",
      "            ReLU6-21          [-1, 144, 32, 32]               0\n",
      "           Conv2d-22          [-1, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 32, 32]             288\n",
      "            ReLU6-24          [-1, 144, 32, 32]               0\n",
      "           Conv2d-25           [-1, 24, 32, 32]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-27           [-1, 24, 32, 32]               0\n",
      "           Conv2d-28          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 32, 32]             288\n",
      "            ReLU6-30          [-1, 144, 32, 32]               0\n",
      "           Conv2d-31          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 16, 16]             288\n",
      "            ReLU6-33          [-1, 144, 16, 16]               0\n",
      "           Conv2d-34           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-36           [-1, 32, 16, 16]               0\n",
      "           Conv2d-37          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 16, 16]             384\n",
      "            ReLU6-39          [-1, 192, 16, 16]               0\n",
      "           Conv2d-40          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 16, 16]             384\n",
      "            ReLU6-42          [-1, 192, 16, 16]               0\n",
      "           Conv2d-43           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-45           [-1, 32, 16, 16]               0\n",
      "           Conv2d-46          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 16, 16]             384\n",
      "            ReLU6-48          [-1, 192, 16, 16]               0\n",
      "           Conv2d-49          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 16, 16]             384\n",
      "            ReLU6-51          [-1, 192, 16, 16]               0\n",
      "           Conv2d-52           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 16, 16]             384\n",
      "            ReLU6-57          [-1, 192, 16, 16]               0\n",
      "           Conv2d-58            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-59            [-1, 192, 8, 8]             384\n",
      "            ReLU6-60            [-1, 192, 8, 8]               0\n",
      "           Conv2d-61             [-1, 64, 8, 8]          12,288\n",
      "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-63             [-1, 64, 8, 8]               0\n",
      "           Conv2d-64            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-65            [-1, 384, 8, 8]             768\n",
      "            ReLU6-66            [-1, 384, 8, 8]               0\n",
      "           Conv2d-67            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-68            [-1, 384, 8, 8]             768\n",
      "            ReLU6-69            [-1, 384, 8, 8]               0\n",
      "           Conv2d-70             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-71             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-72             [-1, 64, 8, 8]               0\n",
      "           Conv2d-73            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-74            [-1, 384, 8, 8]             768\n",
      "            ReLU6-75            [-1, 384, 8, 8]               0\n",
      "           Conv2d-76            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-77            [-1, 384, 8, 8]             768\n",
      "            ReLU6-78            [-1, 384, 8, 8]               0\n",
      "           Conv2d-79             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-81             [-1, 64, 8, 8]               0\n",
      "           Conv2d-82            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-83            [-1, 384, 8, 8]             768\n",
      "            ReLU6-84            [-1, 384, 8, 8]               0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Conv2d-85            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-86            [-1, 384, 8, 8]             768\n",
      "            ReLU6-87            [-1, 384, 8, 8]               0\n",
      "           Conv2d-88             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-90             [-1, 64, 8, 8]               0\n",
      "           Conv2d-91            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-92            [-1, 384, 8, 8]             768\n",
      "            ReLU6-93            [-1, 384, 8, 8]               0\n",
      "           Conv2d-94            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-95            [-1, 384, 8, 8]             768\n",
      "            ReLU6-96            [-1, 384, 8, 8]               0\n",
      "           Conv2d-97             [-1, 96, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 96, 8, 8]             192\n",
      " InvertedResidual-99             [-1, 96, 8, 8]               0\n",
      "          Conv2d-100            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-101            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-102            [-1, 576, 8, 8]               0\n",
      "          Conv2d-103            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-104            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-105            [-1, 576, 8, 8]               0\n",
      "          Conv2d-106             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-107             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-108             [-1, 96, 8, 8]               0\n",
      "          Conv2d-109            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-110            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-111            [-1, 576, 8, 8]               0\n",
      "          Conv2d-112            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-113            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-114            [-1, 576, 8, 8]               0\n",
      "          Conv2d-115             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-116             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-117             [-1, 96, 8, 8]               0\n",
      "          Conv2d-118            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-119            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-120            [-1, 576, 8, 8]               0\n",
      "          Conv2d-121            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-123            [-1, 576, 4, 4]               0\n",
      "          Conv2d-124            [-1, 160, 4, 4]          92,160\n",
      "     BatchNorm2d-125            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-126            [-1, 160, 4, 4]               0\n",
      "          Conv2d-127            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-129            [-1, 960, 4, 4]               0\n",
      "          Conv2d-130            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-132            [-1, 960, 4, 4]               0\n",
      "          Conv2d-133            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-135            [-1, 160, 4, 4]               0\n",
      "          Conv2d-136            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-138            [-1, 960, 4, 4]               0\n",
      "          Conv2d-139            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-141            [-1, 960, 4, 4]               0\n",
      "          Conv2d-142            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-144            [-1, 160, 4, 4]               0\n",
      "          Conv2d-145            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-147            [-1, 960, 4, 4]               0\n",
      "          Conv2d-148            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-150            [-1, 960, 4, 4]               0\n",
      "          Conv2d-151            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-153            [-1, 320, 4, 4]               0\n",
      "          Conv2d-154           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-156           [-1, 1280, 4, 4]               0\n",
      "          Linear-157                  [-1, 512]         655,872\n",
      "     MobileNetV2-158                  [-1, 512]               0\n",
      "      EncoderNet-159                  [-1, 512]               0\n",
      "        Identity-160                  [-1, 512]               0\n",
      "          Conv2d-161           [-1, 32, 64, 64]             864\n",
      "     BatchNorm2d-162           [-1, 32, 64, 64]              64\n",
      "           ReLU6-163           [-1, 32, 64, 64]               0\n",
      "          Conv2d-164           [-1, 32, 64, 64]             288\n",
      "     BatchNorm2d-165           [-1, 32, 64, 64]              64\n",
      "           ReLU6-166           [-1, 32, 64, 64]               0\n",
      "          Conv2d-167           [-1, 16, 64, 64]             512\n",
      "     BatchNorm2d-168           [-1, 16, 64, 64]              32\n",
      "InvertedResidual-169           [-1, 16, 64, 64]               0\n",
      "          Conv2d-170           [-1, 96, 64, 64]           1,536\n",
      "     BatchNorm2d-171           [-1, 96, 64, 64]             192\n",
      "           ReLU6-172           [-1, 96, 64, 64]               0\n",
      "          Conv2d-173           [-1, 96, 32, 32]             864\n",
      "     BatchNorm2d-174           [-1, 96, 32, 32]             192\n",
      "           ReLU6-175           [-1, 96, 32, 32]               0\n",
      "          Conv2d-176           [-1, 24, 32, 32]           2,304\n",
      "     BatchNorm2d-177           [-1, 24, 32, 32]              48\n",
      "InvertedResidual-178           [-1, 24, 32, 32]               0\n",
      "          Conv2d-179          [-1, 144, 32, 32]           3,456\n",
      "     BatchNorm2d-180          [-1, 144, 32, 32]             288\n",
      "           ReLU6-181          [-1, 144, 32, 32]               0\n",
      "          Conv2d-182          [-1, 144, 32, 32]           1,296\n",
      "     BatchNorm2d-183          [-1, 144, 32, 32]             288\n",
      "           ReLU6-184          [-1, 144, 32, 32]               0\n",
      "          Conv2d-185           [-1, 24, 32, 32]           3,456\n",
      "     BatchNorm2d-186           [-1, 24, 32, 32]              48\n",
      "InvertedResidual-187           [-1, 24, 32, 32]               0\n",
      "          Conv2d-188          [-1, 144, 32, 32]           3,456\n",
      "     BatchNorm2d-189          [-1, 144, 32, 32]             288\n",
      "           ReLU6-190          [-1, 144, 32, 32]               0\n",
      "          Conv2d-191          [-1, 144, 16, 16]           1,296\n",
      "     BatchNorm2d-192          [-1, 144, 16, 16]             288\n",
      "           ReLU6-193          [-1, 144, 16, 16]               0\n",
      "          Conv2d-194           [-1, 32, 16, 16]           4,608\n",
      "     BatchNorm2d-195           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-196           [-1, 32, 16, 16]               0\n",
      "          Conv2d-197          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-198          [-1, 192, 16, 16]             384\n",
      "           ReLU6-199          [-1, 192, 16, 16]               0\n",
      "          Conv2d-200          [-1, 192, 16, 16]           1,728\n",
      "     BatchNorm2d-201          [-1, 192, 16, 16]             384\n",
      "           ReLU6-202          [-1, 192, 16, 16]               0\n",
      "          Conv2d-203           [-1, 32, 16, 16]           6,144\n",
      "     BatchNorm2d-204           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-205           [-1, 32, 16, 16]               0\n",
      "          Conv2d-206          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-207          [-1, 192, 16, 16]             384\n",
      "           ReLU6-208          [-1, 192, 16, 16]               0\n",
      "          Conv2d-209          [-1, 192, 16, 16]           1,728\n",
      "     BatchNorm2d-210          [-1, 192, 16, 16]             384\n",
      "           ReLU6-211          [-1, 192, 16, 16]               0\n",
      "          Conv2d-212           [-1, 32, 16, 16]           6,144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-213           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-214           [-1, 32, 16, 16]               0\n",
      "          Conv2d-215          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-216          [-1, 192, 16, 16]             384\n",
      "           ReLU6-217          [-1, 192, 16, 16]               0\n",
      "          Conv2d-218            [-1, 192, 8, 8]           1,728\n",
      "     BatchNorm2d-219            [-1, 192, 8, 8]             384\n",
      "           ReLU6-220            [-1, 192, 8, 8]               0\n",
      "          Conv2d-221             [-1, 64, 8, 8]          12,288\n",
      "     BatchNorm2d-222             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-223             [-1, 64, 8, 8]               0\n",
      "          Conv2d-224            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-225            [-1, 384, 8, 8]             768\n",
      "           ReLU6-226            [-1, 384, 8, 8]               0\n",
      "          Conv2d-227            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-228            [-1, 384, 8, 8]             768\n",
      "           ReLU6-229            [-1, 384, 8, 8]               0\n",
      "          Conv2d-230             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-231             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-232             [-1, 64, 8, 8]               0\n",
      "          Conv2d-233            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-234            [-1, 384, 8, 8]             768\n",
      "           ReLU6-235            [-1, 384, 8, 8]               0\n",
      "          Conv2d-236            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-237            [-1, 384, 8, 8]             768\n",
      "           ReLU6-238            [-1, 384, 8, 8]               0\n",
      "          Conv2d-239             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-240             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-241             [-1, 64, 8, 8]               0\n",
      "          Conv2d-242            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-243            [-1, 384, 8, 8]             768\n",
      "           ReLU6-244            [-1, 384, 8, 8]               0\n",
      "          Conv2d-245            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-246            [-1, 384, 8, 8]             768\n",
      "           ReLU6-247            [-1, 384, 8, 8]               0\n",
      "          Conv2d-248             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-249             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-250             [-1, 64, 8, 8]               0\n",
      "          Conv2d-251            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-252            [-1, 384, 8, 8]             768\n",
      "           ReLU6-253            [-1, 384, 8, 8]               0\n",
      "          Conv2d-254            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-255            [-1, 384, 8, 8]             768\n",
      "           ReLU6-256            [-1, 384, 8, 8]               0\n",
      "          Conv2d-257             [-1, 96, 8, 8]          36,864\n",
      "     BatchNorm2d-258             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-259             [-1, 96, 8, 8]               0\n",
      "          Conv2d-260            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-261            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-262            [-1, 576, 8, 8]               0\n",
      "          Conv2d-263            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-264            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-265            [-1, 576, 8, 8]               0\n",
      "          Conv2d-266             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-267             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-268             [-1, 96, 8, 8]               0\n",
      "          Conv2d-269            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-270            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-271            [-1, 576, 8, 8]               0\n",
      "          Conv2d-272            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-273            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-274            [-1, 576, 8, 8]               0\n",
      "          Conv2d-275             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-276             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-277             [-1, 96, 8, 8]               0\n",
      "          Conv2d-278            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-279            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-280            [-1, 576, 8, 8]               0\n",
      "          Conv2d-281            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-282            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-283            [-1, 576, 4, 4]               0\n",
      "          Conv2d-284            [-1, 160, 4, 4]          92,160\n",
      "     BatchNorm2d-285            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-286            [-1, 160, 4, 4]               0\n",
      "          Conv2d-287            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-288            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-289            [-1, 960, 4, 4]               0\n",
      "          Conv2d-290            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-291            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-292            [-1, 960, 4, 4]               0\n",
      "          Conv2d-293            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-294            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-295            [-1, 160, 4, 4]               0\n",
      "          Conv2d-296            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-297            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-298            [-1, 960, 4, 4]               0\n",
      "          Conv2d-299            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-300            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-301            [-1, 960, 4, 4]               0\n",
      "          Conv2d-302            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-303            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-304            [-1, 160, 4, 4]               0\n",
      "          Conv2d-305            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-306            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-307            [-1, 960, 4, 4]               0\n",
      "          Conv2d-308            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-309            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-310            [-1, 960, 4, 4]               0\n",
      "          Conv2d-311            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-312            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-313            [-1, 320, 4, 4]               0\n",
      "          Conv2d-314           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-315           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-316           [-1, 1280, 4, 4]               0\n",
      "          Linear-317                  [-1, 512]         655,872\n",
      "     MobileNetV2-318                  [-1, 512]               0\n",
      "      EncoderNet-319                  [-1, 512]               0\n",
      "        Identity-320                  [-1, 512]               0\n",
      "================================================================\n",
      "Total params: 5,759,488\n",
      "Trainable params: 5,759,488\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.12\n",
      "Forward/backward pass size (MB): 99.85\n",
      "Params size (MB): 21.97\n",
      "Estimated Total Size (MB): 122.95\n",
      "----------------------------------------------------------------\n",
      "D:\\Desktop\\projects\\speaker_recognition_voxceleb1\\output_data\\models\\contrastive_encoder\\2020-03-15_19-59-23\n",
      "Description: Candidates: 5, Encoding: 512, Projection: None\n",
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 1.5215 Acc: 0.3354\n",
      "val Loss: 1.5177 Acc: 0.2444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type MultiSiameseEncoderNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type EncoderNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL SAVED\n",
      "Time taken is 69 seconds\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Test load model from contrastive training\n",
    "from ipynb.fs.full.contrastive_encoder_training_depth3_pytorch import MultiSiameseEncoderNet\n",
    "\n",
    "model = torch.load(encoder_model_file, map_location=\"cpu\")\n",
    "model = model.encoder\n",
    "summary(model, input_size=(3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             864\n",
      "       BatchNorm2d-2           [-1, 32, 64, 64]              64\n",
      "             ReLU6-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]             288\n",
      "       BatchNorm2d-5           [-1, 32, 64, 64]              64\n",
      "             ReLU6-6           [-1, 32, 64, 64]               0\n",
      "            Conv2d-7           [-1, 16, 64, 64]             512\n",
      "       BatchNorm2d-8           [-1, 16, 64, 64]              32\n",
      "  InvertedResidual-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 96, 64, 64]           1,536\n",
      "      BatchNorm2d-11           [-1, 96, 64, 64]             192\n",
      "            ReLU6-12           [-1, 96, 64, 64]               0\n",
      "           Conv2d-13           [-1, 96, 32, 32]             864\n",
      "      BatchNorm2d-14           [-1, 96, 32, 32]             192\n",
      "            ReLU6-15           [-1, 96, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 32, 32]             288\n",
      "            ReLU6-21          [-1, 144, 32, 32]               0\n",
      "           Conv2d-22          [-1, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 32, 32]             288\n",
      "            ReLU6-24          [-1, 144, 32, 32]               0\n",
      "           Conv2d-25           [-1, 24, 32, 32]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-27           [-1, 24, 32, 32]               0\n",
      "           Conv2d-28          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 32, 32]             288\n",
      "            ReLU6-30          [-1, 144, 32, 32]               0\n",
      "           Conv2d-31          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 16, 16]             288\n",
      "            ReLU6-33          [-1, 144, 16, 16]               0\n",
      "           Conv2d-34           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-36           [-1, 32, 16, 16]               0\n",
      "           Conv2d-37          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 16, 16]             384\n",
      "            ReLU6-39          [-1, 192, 16, 16]               0\n",
      "           Conv2d-40          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 16, 16]             384\n",
      "            ReLU6-42          [-1, 192, 16, 16]               0\n",
      "           Conv2d-43           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-45           [-1, 32, 16, 16]               0\n",
      "           Conv2d-46          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 16, 16]             384\n",
      "            ReLU6-48          [-1, 192, 16, 16]               0\n",
      "           Conv2d-49          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 16, 16]             384\n",
      "            ReLU6-51          [-1, 192, 16, 16]               0\n",
      "           Conv2d-52           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 16, 16]             384\n",
      "            ReLU6-57          [-1, 192, 16, 16]               0\n",
      "           Conv2d-58            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-59            [-1, 192, 8, 8]             384\n",
      "            ReLU6-60            [-1, 192, 8, 8]               0\n",
      "           Conv2d-61             [-1, 64, 8, 8]          12,288\n",
      "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-63             [-1, 64, 8, 8]               0\n",
      "           Conv2d-64            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-65            [-1, 384, 8, 8]             768\n",
      "            ReLU6-66            [-1, 384, 8, 8]               0\n",
      "           Conv2d-67            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-68            [-1, 384, 8, 8]             768\n",
      "            ReLU6-69            [-1, 384, 8, 8]               0\n",
      "           Conv2d-70             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-71             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-72             [-1, 64, 8, 8]               0\n",
      "           Conv2d-73            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-74            [-1, 384, 8, 8]             768\n",
      "            ReLU6-75            [-1, 384, 8, 8]               0\n",
      "           Conv2d-76            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-77            [-1, 384, 8, 8]             768\n",
      "            ReLU6-78            [-1, 384, 8, 8]               0\n",
      "           Conv2d-79             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-81             [-1, 64, 8, 8]               0\n",
      "           Conv2d-82            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-83            [-1, 384, 8, 8]             768\n",
      "            ReLU6-84            [-1, 384, 8, 8]               0\n",
      "           Conv2d-85            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-86            [-1, 384, 8, 8]             768\n",
      "            ReLU6-87            [-1, 384, 8, 8]               0\n",
      "           Conv2d-88             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-90             [-1, 64, 8, 8]               0\n",
      "           Conv2d-91            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-92            [-1, 384, 8, 8]             768\n",
      "            ReLU6-93            [-1, 384, 8, 8]               0\n",
      "           Conv2d-94            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-95            [-1, 384, 8, 8]             768\n",
      "            ReLU6-96            [-1, 384, 8, 8]               0\n",
      "           Conv2d-97             [-1, 96, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 96, 8, 8]             192\n",
      " InvertedResidual-99             [-1, 96, 8, 8]               0\n",
      "          Conv2d-100            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-101            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-102            [-1, 576, 8, 8]               0\n",
      "          Conv2d-103            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-104            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-105            [-1, 576, 8, 8]               0\n",
      "          Conv2d-106             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-107             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-108             [-1, 96, 8, 8]               0\n",
      "          Conv2d-109            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-110            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-111            [-1, 576, 8, 8]               0\n",
      "          Conv2d-112            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-113            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-114            [-1, 576, 8, 8]               0\n",
      "          Conv2d-115             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-116             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-117             [-1, 96, 8, 8]               0\n",
      "          Conv2d-118            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-119            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-120            [-1, 576, 8, 8]               0\n",
      "          Conv2d-121            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-123            [-1, 576, 4, 4]               0\n",
      "          Conv2d-124            [-1, 160, 4, 4]          92,160\n",
      "     BatchNorm2d-125            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-126            [-1, 160, 4, 4]               0\n",
      "          Conv2d-127            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-129            [-1, 960, 4, 4]               0\n",
      "          Conv2d-130            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-132            [-1, 960, 4, 4]               0\n",
      "          Conv2d-133            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-135            [-1, 160, 4, 4]               0\n",
      "          Conv2d-136            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-138            [-1, 960, 4, 4]               0\n",
      "          Conv2d-139            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-141            [-1, 960, 4, 4]               0\n",
      "          Conv2d-142            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-144            [-1, 160, 4, 4]               0\n",
      "          Conv2d-145            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-147            [-1, 960, 4, 4]               0\n",
      "          Conv2d-148            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-150            [-1, 960, 4, 4]               0\n",
      "          Conv2d-151            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-153            [-1, 320, 4, 4]               0\n",
      "          Conv2d-154           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-156           [-1, 1280, 4, 4]               0\n",
      "          Linear-157                  [-1, 512]         655,872\n",
      "     MobileNetV2-158                  [-1, 512]               0\n",
      "================================================================\n",
      "Total params: 2,879,744\n",
      "Trainable params: 2,879,744\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 49.92\n",
      "Params size (MB): 10.99\n",
      "Estimated Total Size (MB): 61.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class EncoderNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderNet, self).__init__()\n",
    "        self.encoder = models.mobilenet_v2(pretrained=False)   # base model (transfer learning)\n",
    "        self.encoder.classifier = nn.Sequential(\n",
    "            nn.Linear(1280, 512),   # encoding layer, mobile_netV2 output: 1280 \n",
    "        )      \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)  \n",
    "        \n",
    "summary(EncoderNet(), input_size=(3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 64, 64]             864\n",
      "       BatchNorm2d-2           [-1, 32, 64, 64]              64\n",
      "             ReLU6-3           [-1, 32, 64, 64]               0\n",
      "            Conv2d-4           [-1, 32, 64, 64]             288\n",
      "       BatchNorm2d-5           [-1, 32, 64, 64]              64\n",
      "             ReLU6-6           [-1, 32, 64, 64]               0\n",
      "            Conv2d-7           [-1, 16, 64, 64]             512\n",
      "       BatchNorm2d-8           [-1, 16, 64, 64]              32\n",
      "  InvertedResidual-9           [-1, 16, 64, 64]               0\n",
      "           Conv2d-10           [-1, 96, 64, 64]           1,536\n",
      "      BatchNorm2d-11           [-1, 96, 64, 64]             192\n",
      "            ReLU6-12           [-1, 96, 64, 64]               0\n",
      "           Conv2d-13           [-1, 96, 32, 32]             864\n",
      "      BatchNorm2d-14           [-1, 96, 32, 32]             192\n",
      "            ReLU6-15           [-1, 96, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 32, 32]             288\n",
      "            ReLU6-21          [-1, 144, 32, 32]               0\n",
      "           Conv2d-22          [-1, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 32, 32]             288\n",
      "            ReLU6-24          [-1, 144, 32, 32]               0\n",
      "           Conv2d-25           [-1, 24, 32, 32]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 32, 32]              48\n",
      " InvertedResidual-27           [-1, 24, 32, 32]               0\n",
      "           Conv2d-28          [-1, 144, 32, 32]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 32, 32]             288\n",
      "            ReLU6-30          [-1, 144, 32, 32]               0\n",
      "           Conv2d-31          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 16, 16]             288\n",
      "            ReLU6-33          [-1, 144, 16, 16]               0\n",
      "           Conv2d-34           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-36           [-1, 32, 16, 16]               0\n",
      "           Conv2d-37          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 16, 16]             384\n",
      "            ReLU6-39          [-1, 192, 16, 16]               0\n",
      "           Conv2d-40          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 16, 16]             384\n",
      "            ReLU6-42          [-1, 192, 16, 16]               0\n",
      "           Conv2d-43           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-45           [-1, 32, 16, 16]               0\n",
      "           Conv2d-46          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 16, 16]             384\n",
      "            ReLU6-48          [-1, 192, 16, 16]               0\n",
      "           Conv2d-49          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 16, 16]             384\n",
      "            ReLU6-51          [-1, 192, 16, 16]               0\n",
      "           Conv2d-52           [-1, 32, 16, 16]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 16, 16]              64\n",
      " InvertedResidual-54           [-1, 32, 16, 16]               0\n",
      "           Conv2d-55          [-1, 192, 16, 16]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 16, 16]             384\n",
      "            ReLU6-57          [-1, 192, 16, 16]               0\n",
      "           Conv2d-58            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-59            [-1, 192, 8, 8]             384\n",
      "            ReLU6-60            [-1, 192, 8, 8]               0\n",
      "           Conv2d-61             [-1, 64, 8, 8]          12,288\n",
      "      BatchNorm2d-62             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-63             [-1, 64, 8, 8]               0\n",
      "           Conv2d-64            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-65            [-1, 384, 8, 8]             768\n",
      "            ReLU6-66            [-1, 384, 8, 8]               0\n",
      "           Conv2d-67            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-68            [-1, 384, 8, 8]             768\n",
      "            ReLU6-69            [-1, 384, 8, 8]               0\n",
      "           Conv2d-70             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-71             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-72             [-1, 64, 8, 8]               0\n",
      "           Conv2d-73            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-74            [-1, 384, 8, 8]             768\n",
      "            ReLU6-75            [-1, 384, 8, 8]               0\n",
      "           Conv2d-76            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-77            [-1, 384, 8, 8]             768\n",
      "            ReLU6-78            [-1, 384, 8, 8]               0\n",
      "           Conv2d-79             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-80             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-81             [-1, 64, 8, 8]               0\n",
      "           Conv2d-82            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-83            [-1, 384, 8, 8]             768\n",
      "            ReLU6-84            [-1, 384, 8, 8]               0\n",
      "           Conv2d-85            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-86            [-1, 384, 8, 8]             768\n",
      "            ReLU6-87            [-1, 384, 8, 8]               0\n",
      "           Conv2d-88             [-1, 64, 8, 8]          24,576\n",
      "      BatchNorm2d-89             [-1, 64, 8, 8]             128\n",
      " InvertedResidual-90             [-1, 64, 8, 8]               0\n",
      "           Conv2d-91            [-1, 384, 8, 8]          24,576\n",
      "      BatchNorm2d-92            [-1, 384, 8, 8]             768\n",
      "            ReLU6-93            [-1, 384, 8, 8]               0\n",
      "           Conv2d-94            [-1, 384, 8, 8]           3,456\n",
      "      BatchNorm2d-95            [-1, 384, 8, 8]             768\n",
      "            ReLU6-96            [-1, 384, 8, 8]               0\n",
      "           Conv2d-97             [-1, 96, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 96, 8, 8]             192\n",
      " InvertedResidual-99             [-1, 96, 8, 8]               0\n",
      "          Conv2d-100            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-101            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-102            [-1, 576, 8, 8]               0\n",
      "          Conv2d-103            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-104            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-105            [-1, 576, 8, 8]               0\n",
      "          Conv2d-106             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-107             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-108             [-1, 96, 8, 8]               0\n",
      "          Conv2d-109            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-110            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-111            [-1, 576, 8, 8]               0\n",
      "          Conv2d-112            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-113            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-114            [-1, 576, 8, 8]               0\n",
      "          Conv2d-115             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-116             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-117             [-1, 96, 8, 8]               0\n",
      "          Conv2d-118            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-119            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-120            [-1, 576, 8, 8]               0\n",
      "          Conv2d-121            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-123            [-1, 576, 4, 4]               0\n",
      "          Conv2d-124            [-1, 160, 4, 4]          92,160\n",
      "     BatchNorm2d-125            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-126            [-1, 160, 4, 4]               0\n",
      "          Conv2d-127            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-129            [-1, 960, 4, 4]               0\n",
      "          Conv2d-130            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-132            [-1, 960, 4, 4]               0\n",
      "          Conv2d-133            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-135            [-1, 160, 4, 4]               0\n",
      "          Conv2d-136            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-138            [-1, 960, 4, 4]               0\n",
      "          Conv2d-139            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-141            [-1, 960, 4, 4]               0\n",
      "          Conv2d-142            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-144            [-1, 160, 4, 4]               0\n",
      "          Conv2d-145            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-147            [-1, 960, 4, 4]               0\n",
      "          Conv2d-148            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-150            [-1, 960, 4, 4]               0\n",
      "          Conv2d-151            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-153            [-1, 320, 4, 4]               0\n",
      "          Conv2d-154           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-156           [-1, 1280, 4, 4]               0\n",
      "          Linear-157                  [-1, 512]         655,872\n",
      "     MobileNetV2-158                  [-1, 512]               0\n",
      "      EncoderNet-159                  [-1, 512]               0\n",
      "            Tanh-160                  [-1, 512]               0\n",
      "          Linear-161                  [-1, 512]         262,656\n",
      "            Tanh-162                  [-1, 512]               0\n",
      "          Linear-163                  [-1, 512]         262,656\n",
      "          Conv2d-164           [-1, 32, 64, 64]             864\n",
      "     BatchNorm2d-165           [-1, 32, 64, 64]              64\n",
      "           ReLU6-166           [-1, 32, 64, 64]               0\n",
      "          Conv2d-167           [-1, 32, 64, 64]             288\n",
      "     BatchNorm2d-168           [-1, 32, 64, 64]              64\n",
      "           ReLU6-169           [-1, 32, 64, 64]               0\n",
      "          Conv2d-170           [-1, 16, 64, 64]             512\n",
      "     BatchNorm2d-171           [-1, 16, 64, 64]              32\n",
      "InvertedResidual-172           [-1, 16, 64, 64]               0\n",
      "          Conv2d-173           [-1, 96, 64, 64]           1,536\n",
      "     BatchNorm2d-174           [-1, 96, 64, 64]             192\n",
      "           ReLU6-175           [-1, 96, 64, 64]               0\n",
      "          Conv2d-176           [-1, 96, 32, 32]             864\n",
      "     BatchNorm2d-177           [-1, 96, 32, 32]             192\n",
      "           ReLU6-178           [-1, 96, 32, 32]               0\n",
      "          Conv2d-179           [-1, 24, 32, 32]           2,304\n",
      "     BatchNorm2d-180           [-1, 24, 32, 32]              48\n",
      "InvertedResidual-181           [-1, 24, 32, 32]               0\n",
      "          Conv2d-182          [-1, 144, 32, 32]           3,456\n",
      "     BatchNorm2d-183          [-1, 144, 32, 32]             288\n",
      "           ReLU6-184          [-1, 144, 32, 32]               0\n",
      "          Conv2d-185          [-1, 144, 32, 32]           1,296\n",
      "     BatchNorm2d-186          [-1, 144, 32, 32]             288\n",
      "           ReLU6-187          [-1, 144, 32, 32]               0\n",
      "          Conv2d-188           [-1, 24, 32, 32]           3,456\n",
      "     BatchNorm2d-189           [-1, 24, 32, 32]              48\n",
      "InvertedResidual-190           [-1, 24, 32, 32]               0\n",
      "          Conv2d-191          [-1, 144, 32, 32]           3,456\n",
      "     BatchNorm2d-192          [-1, 144, 32, 32]             288\n",
      "           ReLU6-193          [-1, 144, 32, 32]               0\n",
      "          Conv2d-194          [-1, 144, 16, 16]           1,296\n",
      "     BatchNorm2d-195          [-1, 144, 16, 16]             288\n",
      "           ReLU6-196          [-1, 144, 16, 16]               0\n",
      "          Conv2d-197           [-1, 32, 16, 16]           4,608\n",
      "     BatchNorm2d-198           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-199           [-1, 32, 16, 16]               0\n",
      "          Conv2d-200          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-201          [-1, 192, 16, 16]             384\n",
      "           ReLU6-202          [-1, 192, 16, 16]               0\n",
      "          Conv2d-203          [-1, 192, 16, 16]           1,728\n",
      "     BatchNorm2d-204          [-1, 192, 16, 16]             384\n",
      "           ReLU6-205          [-1, 192, 16, 16]               0\n",
      "          Conv2d-206           [-1, 32, 16, 16]           6,144\n",
      "     BatchNorm2d-207           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-208           [-1, 32, 16, 16]               0\n",
      "          Conv2d-209          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-210          [-1, 192, 16, 16]             384\n",
      "           ReLU6-211          [-1, 192, 16, 16]               0\n",
      "          Conv2d-212          [-1, 192, 16, 16]           1,728\n",
      "     BatchNorm2d-213          [-1, 192, 16, 16]             384\n",
      "           ReLU6-214          [-1, 192, 16, 16]               0\n",
      "          Conv2d-215           [-1, 32, 16, 16]           6,144\n",
      "     BatchNorm2d-216           [-1, 32, 16, 16]              64\n",
      "InvertedResidual-217           [-1, 32, 16, 16]               0\n",
      "          Conv2d-218          [-1, 192, 16, 16]           6,144\n",
      "     BatchNorm2d-219          [-1, 192, 16, 16]             384\n",
      "           ReLU6-220          [-1, 192, 16, 16]               0\n",
      "          Conv2d-221            [-1, 192, 8, 8]           1,728\n",
      "     BatchNorm2d-222            [-1, 192, 8, 8]             384\n",
      "           ReLU6-223            [-1, 192, 8, 8]               0\n",
      "          Conv2d-224             [-1, 64, 8, 8]          12,288\n",
      "     BatchNorm2d-225             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-226             [-1, 64, 8, 8]               0\n",
      "          Conv2d-227            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-228            [-1, 384, 8, 8]             768\n",
      "           ReLU6-229            [-1, 384, 8, 8]               0\n",
      "          Conv2d-230            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-231            [-1, 384, 8, 8]             768\n",
      "           ReLU6-232            [-1, 384, 8, 8]               0\n",
      "          Conv2d-233             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-234             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-235             [-1, 64, 8, 8]               0\n",
      "          Conv2d-236            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-237            [-1, 384, 8, 8]             768\n",
      "           ReLU6-238            [-1, 384, 8, 8]               0\n",
      "          Conv2d-239            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-240            [-1, 384, 8, 8]             768\n",
      "           ReLU6-241            [-1, 384, 8, 8]               0\n",
      "          Conv2d-242             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-243             [-1, 64, 8, 8]             128\n",
      "InvertedResidual-244             [-1, 64, 8, 8]               0\n",
      "          Conv2d-245            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-246            [-1, 384, 8, 8]             768\n",
      "           ReLU6-247            [-1, 384, 8, 8]               0\n",
      "          Conv2d-248            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-249            [-1, 384, 8, 8]             768\n",
      "           ReLU6-250            [-1, 384, 8, 8]               0\n",
      "          Conv2d-251             [-1, 64, 8, 8]          24,576\n",
      "     BatchNorm2d-252             [-1, 64, 8, 8]             128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvertedResidual-253             [-1, 64, 8, 8]               0\n",
      "          Conv2d-254            [-1, 384, 8, 8]          24,576\n",
      "     BatchNorm2d-255            [-1, 384, 8, 8]             768\n",
      "           ReLU6-256            [-1, 384, 8, 8]               0\n",
      "          Conv2d-257            [-1, 384, 8, 8]           3,456\n",
      "     BatchNorm2d-258            [-1, 384, 8, 8]             768\n",
      "           ReLU6-259            [-1, 384, 8, 8]               0\n",
      "          Conv2d-260             [-1, 96, 8, 8]          36,864\n",
      "     BatchNorm2d-261             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-262             [-1, 96, 8, 8]               0\n",
      "          Conv2d-263            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-264            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-265            [-1, 576, 8, 8]               0\n",
      "          Conv2d-266            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-267            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-268            [-1, 576, 8, 8]               0\n",
      "          Conv2d-269             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-270             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-271             [-1, 96, 8, 8]               0\n",
      "          Conv2d-272            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-273            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-274            [-1, 576, 8, 8]               0\n",
      "          Conv2d-275            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-276            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-277            [-1, 576, 8, 8]               0\n",
      "          Conv2d-278             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-279             [-1, 96, 8, 8]             192\n",
      "InvertedResidual-280             [-1, 96, 8, 8]               0\n",
      "          Conv2d-281            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-282            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-283            [-1, 576, 8, 8]               0\n",
      "          Conv2d-284            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-285            [-1, 576, 4, 4]           1,152\n",
      "           ReLU6-286            [-1, 576, 4, 4]               0\n",
      "          Conv2d-287            [-1, 160, 4, 4]          92,160\n",
      "     BatchNorm2d-288            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-289            [-1, 160, 4, 4]               0\n",
      "          Conv2d-290            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-291            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-292            [-1, 960, 4, 4]               0\n",
      "          Conv2d-293            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-294            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-295            [-1, 960, 4, 4]               0\n",
      "          Conv2d-296            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-297            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-298            [-1, 160, 4, 4]               0\n",
      "          Conv2d-299            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-300            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-301            [-1, 960, 4, 4]               0\n",
      "          Conv2d-302            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-303            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-304            [-1, 960, 4, 4]               0\n",
      "          Conv2d-305            [-1, 160, 4, 4]         153,600\n",
      "     BatchNorm2d-306            [-1, 160, 4, 4]             320\n",
      "InvertedResidual-307            [-1, 160, 4, 4]               0\n",
      "          Conv2d-308            [-1, 960, 4, 4]         153,600\n",
      "     BatchNorm2d-309            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-310            [-1, 960, 4, 4]               0\n",
      "          Conv2d-311            [-1, 960, 4, 4]           8,640\n",
      "     BatchNorm2d-312            [-1, 960, 4, 4]           1,920\n",
      "           ReLU6-313            [-1, 960, 4, 4]               0\n",
      "          Conv2d-314            [-1, 320, 4, 4]         307,200\n",
      "     BatchNorm2d-315            [-1, 320, 4, 4]             640\n",
      "InvertedResidual-316            [-1, 320, 4, 4]               0\n",
      "          Conv2d-317           [-1, 1280, 4, 4]         409,600\n",
      "     BatchNorm2d-318           [-1, 1280, 4, 4]           2,560\n",
      "           ReLU6-319           [-1, 1280, 4, 4]               0\n",
      "          Linear-320                  [-1, 512]         655,872\n",
      "     MobileNetV2-321                  [-1, 512]               0\n",
      "      EncoderNet-322                  [-1, 512]               0\n",
      "            Tanh-323                  [-1, 512]               0\n",
      "          Linear-324                  [-1, 512]         262,656\n",
      "            Tanh-325                  [-1, 512]               0\n",
      "          Linear-326                  [-1, 512]         262,656\n",
      "================================================================\n",
      "Total params: 6,810,112\n",
      "Trainable params: 6,810,112\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.12\n",
      "Forward/backward pass size (MB): 99.88\n",
      "Params size (MB): 25.98\n",
      "Estimated Total Size (MB): 126.98\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class MultiSiameseEncoderNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiSiameseEncoderNet, self).__init__()\n",
    "        self.encoder = EncoderNet()\n",
    "        self.encoding_projection = nn.Sequential(\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 512),   # projection layer\n",
    "            nn.Tanh(),\n",
    "#             nn.ReLU(),\n",
    "            nn.Linear(512, 512),   # projection layer\n",
    "        )\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.encoding_projection(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, input_imgs):\n",
    "        # cosine sim of query img against each batch img\n",
    "        query_img_encoding = self.encode(input_imgs[0])   # 1st img is the query img\n",
    "        cosine_sims = []\n",
    "        for i in range(1, len(input_imgs)):   # batch imgs\n",
    "            batch_img_encoding = self.encode(input_imgs[i])\n",
    "            cosine_sims.append(F.cosine_similarity(query_img_encoding, batch_img_encoding))\n",
    "        return torch.stack(cosine_sims, dim=1)   # concat cosine sims\n",
    "    \n",
    "summary(MultiSiameseEncoderNet(), input_size=(CANDIDATE_SIZE+1, 3, IMG_HEIGHT, IMG_HEIGHT), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    \n",
    "    def __init__(self, spectrogram_samples_files, candidate_size, batch_size, num_batches, num_sub_samples, img_height):\n",
    "        self.spectrogram_samples_files = spectrogram_samples_files   # list of filepaths\n",
    "        self.candidate_size = candidate_size   # 1 positive, n-1 negatives\n",
    "        self.batch_size = batch_size   # batch size\n",
    "        self.num_batches = num_batches   # num batches per epoch\n",
    "        self.num_sub_samples = num_sub_samples   # num sub-samples per epoch\n",
    "        self.img_height = img_height   # height of square img to be generated in the batches\n",
    "        self.sub_samples = []   # list of RGB converted spectrograms\n",
    "    \n",
    "    def generate_batches(self):\n",
    "        while True:\n",
    "            self.create_sub_samples()\n",
    "            # batches per epoch\n",
    "            for _ in range(self.num_batches):\n",
    "                # create batch\n",
    "                labels = []\n",
    "                query_and_candidate_imgs = [[] for _ in range(self.candidate_size + 1)]\n",
    "                for _ in range(self.batch_size):\n",
    "                    sample_spectrograms_indices = random.sample(range(self.num_sub_samples), self.candidate_size)   # sample candidates\n",
    "                    pos_idx = sample_spectrograms_indices[0]   # positive sample\n",
    "                    # Generate query image\n",
    "                    query_img = self.get_sliding_img_slice_from_spectrogram(self.sub_samples[pos_idx])\n",
    "                    # Generate batch images\n",
    "                    random.shuffle(sample_spectrograms_indices)\n",
    "                    candidate_imgs = [self.get_sliding_img_slice_from_spectrogram(self.sub_samples[idx]) for idx in sample_spectrograms_indices]\n",
    "                    # get class label / idx of positive sample\n",
    "                    pos_candidate_idx = sample_spectrograms_indices.index(pos_idx)   \n",
    "                    labels.append(pos_candidate_idx)\n",
    "                    # Normalize input imgs\n",
    "                    for i, img in enumerate([query_img, *candidate_imgs]):\n",
    "                        img = img / np.amax(np.absolute(img))   # normalize to range [-1, 1]\n",
    "                        query_and_candidate_imgs[i].append(img)\n",
    "                # Convert to tensor\n",
    "                labels = torch.tensor(labels)\n",
    "                input_imgs = torch.tensor(query_and_candidate_imgs)\n",
    "                yield (input_imgs, labels)\n",
    "    \n",
    "    def create_sub_samples(self):\n",
    "        self.sub_samples = []   # reset\n",
    "        files = random.sample(self.spectrogram_samples_files, self.num_sub_samples)   # sampling without replacement\n",
    "        for file in files:\n",
    "#             print(file)\n",
    "            spectrogram = np.load(file)\n",
    "            assert spectrogram.shape[0] == self.img_height, \"Input spectrogram height does not match img height\"\n",
    "            self.sub_samples.append(spectrogram)\n",
    "    \n",
    "    @classmethod\n",
    "    def get_sliding_img_slice_from_spectrogram(cls, spectrogram, depth=3, sliding_ratio=2):\n",
    "        ### Combine multiple sliding greyscale img slices into an n-depth image\n",
    "        height = spectrogram.shape[0]\n",
    "        slide_step = height//sliding_ratio\n",
    "        img_slice = np.zeros((depth,height,height))   # initialize empty img (pytorch style)\n",
    "        # Get random start idx\n",
    "        slice_start = random.randint(0, spectrogram.shape[1] - (slide_step*(depth+1)) - 1)\n",
    "        for i in range(depth):\n",
    "            img_slice[i,:,:] = spectrogram[:, slice_start:slice_start+height]   # get slice (pytorch style)\n",
    "            slice_start += slide_step   # slide\n",
    "        img_slice = img_slice.astype(\"float32\")\n",
    "        return img_slice\n",
    "    \n",
    "    @classmethod\n",
    "    def spectrogram_to_RGB(cls, spectrogram):\n",
    "        assert len(spectrogram.shape) == 2, \"Spectrogram input should be a 2D array\"\n",
    "        spectrogram_rgb = gray2rgb(spectrogram)\n",
    "        return spectrogram_rgb\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folder = os.path.join(output_data_folder, \"training_dataset_full_spectrogram/vox1_dev_wav\")\n",
    "spectrogram_samples_files = [os.path.join(training_folder, file) for file in os.listdir(training_folder)]\n",
    "candidate_size = CANDIDATE_SIZE\n",
    "batch_size = 15\n",
    "num_batches = 1000 // batch_size\n",
    "# num_batches = 200 // batch_size\n",
    "# num_batches = 100\n",
    "num_sub_samples = 100\n",
    "# num_sub_samples = 20\n",
    "training_data_generator = DataGenerator(spectrogram_samples_files, candidate_size, batch_size, num_batches, num_sub_samples, IMG_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, num_batches, training_data_generator, log_handler):\n",
    "    since = time.time()\n",
    "\n",
    "#     best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    t1 = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        log_handler.print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        log_handler.print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            num_batch_modified = num_batches if phase == 'train' else num_batches // 20\n",
    "            for i, data in zip(range(num_batch_modified), training_data_generator.generate_batches()):               \n",
    "                input_imgs, labels = data\n",
    "                inputs = [img.to(device) for img in input_imgs]\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):   # gradient only for train\n",
    "                    outputs = model(inputs)   \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs[0].size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / (num_batch_modified * inputs[0].size(0))\n",
    "            epoch_acc = running_corrects.double() / (num_batch_modified * inputs[0].size(0))\n",
    "\n",
    "            log_handler.print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                log_handler.save_pytorch_model(model, \"best_model_{}.pt\".format(model.__class__.__name__))\n",
    "\n",
    "        # end of epoch\n",
    "        log_handler.print(\"Time taken is {} seconds\".format(int(time.time()-t1)))\n",
    "        t1 = time.time()\n",
    "        log_handler.print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    log_handler.print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    log_handler.print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Desktop\\projects\\speaker_recognition_voxceleb1\\output_data\\models\\contrastive_encoder\\2020-03-15_01-30-24\n",
      "Description: Candidates: 5, Encoding: 512, Projection: Tanh\n",
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 1.6088 Acc: 0.2404\n",
      "val Loss: 1.6084 Acc: 0.4444\n",
      "Time taken is 72 seconds\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 1.5905 Acc: 0.2535\n",
      "val Loss: 1.5737 Acc: 0.2222\n",
      "Time taken is 67 seconds\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 1.5581 Acc: 0.2717\n",
      "val Loss: 1.5172 Acc: 0.2889\n",
      "Time taken is 68 seconds\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 1.5597 Acc: 0.2798\n",
      "val Loss: 1.3993 Acc: 0.5333\n",
      "Time taken is 70 seconds\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 1.5272 Acc: 0.2919\n",
      "val Loss: 1.5392 Acc: 0.2667\n",
      "Time taken is 69 seconds\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 1.5443 Acc: 0.2859\n",
      "val Loss: 1.5909 Acc: 0.2889\n",
      "Time taken is 73 seconds\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 1.5759 Acc: 0.2939\n",
      "val Loss: 1.5299 Acc: 0.5111\n",
      "Time taken is 68 seconds\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 1.5676 Acc: 0.2798\n",
      "val Loss: 1.6410 Acc: 0.1333\n",
      "Time taken is 69 seconds\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 1.5554 Acc: 0.2515\n",
      "val Loss: 1.4957 Acc: 0.2889\n",
      "Time taken is 72 seconds\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 1.5444 Acc: 0.3010\n",
      "val Loss: 1.5425 Acc: 0.4000\n",
      "Time taken is 67 seconds\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 1.5275 Acc: 0.3030\n",
      "val Loss: 1.5020 Acc: 0.3111\n",
      "Time taken is 73 seconds\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 1.5243 Acc: 0.3020\n",
      "val Loss: 1.5503 Acc: 0.2222\n",
      "Time taken is 69 seconds\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 1.5151 Acc: 0.2949\n",
      "val Loss: 1.5587 Acc: 0.2667\n",
      "Time taken is 71 seconds\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 1.5389 Acc: 0.2869\n",
      "val Loss: 1.4834 Acc: 0.3333\n",
      "Time taken is 66 seconds\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 1.5084 Acc: 0.3273\n",
      "val Loss: 1.4262 Acc: 0.4444\n",
      "Time taken is 70 seconds\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 1.5129 Acc: 0.3141\n",
      "val Loss: 1.5024 Acc: 0.3778\n",
      "Time taken is 68 seconds\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 1.5008 Acc: 0.3202\n",
      "val Loss: 1.5818 Acc: 0.2889\n",
      "Time taken is 69 seconds\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 1.5225 Acc: 0.2869\n",
      "val Loss: 1.4618 Acc: 0.2444\n",
      "Time taken is 67 seconds\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 1.5141 Acc: 0.3192\n",
      "val Loss: 1.4837 Acc: 0.2889\n",
      "Time taken is 69 seconds\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 1.5048 Acc: 0.3040\n",
      "val Loss: 1.5626 Acc: 0.2444\n",
      "Time taken is 68 seconds\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 1.5050 Acc: 0.3051\n",
      "val Loss: 1.5149 Acc: 0.3778\n",
      "Time taken is 71 seconds\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 1.4876 Acc: 0.3333\n",
      "val Loss: 1.5159 Acc: 0.2889\n",
      "Time taken is 74 seconds\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 1.5247 Acc: 0.3071\n",
      "val Loss: 1.5999 Acc: 0.2444\n",
      "Time taken is 67 seconds\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 1.5094 Acc: 0.3273\n",
      "val Loss: 1.4431 Acc: 0.4444\n",
      "Time taken is 70 seconds\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 1.5033 Acc: 0.2990\n",
      "val Loss: 1.4927 Acc: 0.2889\n",
      "Time taken is 68 seconds\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 1.5153 Acc: 0.3141\n",
      "val Loss: 1.5885 Acc: 0.2222\n",
      "Time taken is 70 seconds\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 1.5098 Acc: 0.2990\n",
      "val Loss: 1.4114 Acc: 0.3778\n",
      "Time taken is 70 seconds\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 1.5295 Acc: 0.3030\n",
      "val Loss: 1.5043 Acc: 0.1778\n",
      "Time taken is 70 seconds\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 1.4888 Acc: 0.3242\n",
      "val Loss: 1.5014 Acc: 0.3778\n",
      "Time taken is 71 seconds\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 1.4811 Acc: 0.3283\n",
      "val Loss: 1.4599 Acc: 0.3333\n",
      "Time taken is 70 seconds\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 1.5223 Acc: 0.3071\n",
      "val Loss: 1.5352 Acc: 0.2667\n",
      "Time taken is 69 seconds\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 1.5172 Acc: 0.3081\n",
      "val Loss: 1.4276 Acc: 0.3111\n",
      "Time taken is 70 seconds\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 1.5149 Acc: 0.3172\n",
      "val Loss: 1.4804 Acc: 0.2444\n",
      "Time taken is 66 seconds\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 1.5040 Acc: 0.2899\n",
      "val Loss: 1.4987 Acc: 0.2667\n",
      "Time taken is 73 seconds\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 1.4856 Acc: 0.3323\n",
      "val Loss: 1.4528 Acc: 0.4222\n",
      "Time taken is 67 seconds\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 1.5140 Acc: 0.2980\n",
      "val Loss: 1.5359 Acc: 0.2667\n",
      "Time taken is 72 seconds\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 1.5315 Acc: 0.3000\n",
      "val Loss: 1.4982 Acc: 0.3778\n",
      "Time taken is 70 seconds\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 1.5092 Acc: 0.3162\n",
      "val Loss: 1.5821 Acc: 0.3556\n",
      "Time taken is 67 seconds\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 1.4710 Acc: 0.3455\n",
      "val Loss: 1.6375 Acc: 0.2000\n",
      "Time taken is 67 seconds\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 1.5169 Acc: 0.3202\n",
      "val Loss: 1.4999 Acc: 0.3111\n",
      "Time taken is 68 seconds\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 1.5294 Acc: 0.2737\n",
      "val Loss: 1.6266 Acc: 0.2444\n",
      "Time taken is 66 seconds\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 1.5519 Acc: 0.2707\n",
      "val Loss: 1.4469 Acc: 0.3556\n",
      "Time taken is 65 seconds\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 1.5318 Acc: 0.2949\n",
      "val Loss: 1.5406 Acc: 0.3556\n",
      "Time taken is 69 seconds\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 1.4917 Acc: 0.3152\n",
      "val Loss: 1.4534 Acc: 0.4000\n",
      "Time taken is 66 seconds\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 1.5290 Acc: 0.3000\n",
      "val Loss: 1.4788 Acc: 0.4222\n",
      "Time taken is 66 seconds\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 1.5230 Acc: 0.3152\n",
      "val Loss: 1.5364 Acc: 0.3333\n",
      "Time taken is 66 seconds\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 1.4999 Acc: 0.2970\n",
      "val Loss: 1.4864 Acc: 0.3333\n",
      "Time taken is 69 seconds\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 1.5411 Acc: 0.2808\n",
      "val Loss: 1.5633 Acc: 0.2667\n",
      "Time taken is 68 seconds\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 1.5143 Acc: 0.3121\n",
      "val Loss: 1.4754 Acc: 0.3111\n",
      "Time taken is 70 seconds\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 1.5263 Acc: 0.3263\n",
      "val Loss: 1.4886 Acc: 0.3778\n",
      "Time taken is 68 seconds\n",
      "\n",
      "Training complete in 57m 55s\n",
      "Best val Acc: 0.533333\n"
     ]
    }
   ],
   "source": [
    "### Train\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "model_ft = MultiSiameseEncoderNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr = 0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "### Train \n",
    "\n",
    "# Logger\n",
    "model_save_folder = os.path.join(models_folder, \"contrastive_encoder\")\n",
    "log_handler = ModelSaveAndLogHandler(model_save_folder, enable_model_saving=True, enable_logging=True)\n",
    "print(log_handler.folder)\n",
    "\n",
    "# Description\n",
    "log_handler.print(\"Description: Candidates: 5, Encoding: 512, Projection: Tanh\")\n",
    "\n",
    "# Train\n",
    "train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, epochs, num_batches, training_data_generator, log_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_acc = 1 / CANDIDATE_SIZE\n",
    "random_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Overall\n",
    "* Contrastive classifier\n",
    "    * separate train and validate methods\n",
    "\n",
    "* (Done) Model saving / checkpointing\n",
    "* **Build binary classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
